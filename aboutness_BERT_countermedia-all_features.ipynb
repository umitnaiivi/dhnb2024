{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "262Td2bPGm8L",
    "outputId": "314b538b-3919-4da5-df83-acdac9ea4f31"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers.file_utils import is_tf_available, is_torch_available\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "\n",
    "import mlflow\n",
    "import torch\n",
    "mlflow.end_run()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# containers for misclassified articles\n",
    "\n",
    "bin_topics = list()\n",
    "bin_features = list()\n",
    "bin_embeds = list()\n",
    "bin_topics_features = list()\n",
    "bin_topics_embeds = list()\n",
    "bin_features_embeds = list()\n",
    "\n",
    "multi_topics = list()\n",
    "multi_features = list()\n",
    "multi_embeds = list()\n",
    "multi_topics_features = list()\n",
    "multi_topics_embeds = list()\n",
    "multi_features_embeds = list()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    \"\"\"\n",
    "    Helper function for reproducible behavior to set the seed in ``random``, ``numpy``, ``torch`` and/or ``tf`` (if\n",
    "    installed). Taken from https://www.thepythoncode.com/article/finetuning-bert-using-huggingface-transformers-python \n",
    " \n",
    "    Args:\n",
    "        seed (:obj:`int`): The seed to set.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if is_torch_available():\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        # ^^ safe to call this function even if cuda is not available\n",
    "    if is_tf_available():\n",
    "        import tensorflow as tf\n",
    " \n",
    "        tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HWtlkkVKXHc0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in /users/beum/.local/lib/python3.8/site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /users/beum/.local/lib/python3.8/site-packages (from bs4) (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /users/beum/.local/lib/python3.8/site-packages (from beautifulsoup4->bs4) (2.3.1)\n",
      "Verkkouuutiset uutisoi tänään, että Perussuomalaisten Teuvo Hakkarainen puhui tiistaina eduskunnassa ulkomaalaislain käsittelyssä.\n",
      "Hakkaraisen mielestä esityksen sisältämät asiat ovat positiivisia askelia, mutta eivät riittäviä.\n",
      "Teuvo Hakkarainen.\n",
      "Teuvo Hakkarainen sanoi:\n",
      "”Valtaosa turvapaikkaturisteista on tullut ainakin kymmenen turvallisen maan läpi Suomeen, eikä heillä kotimaassakaan ole ollut konkreettista henkeen ja terveyteen kohdistuvaa uhkaa, vaikka kaikenlaisia tarinoita he ovatkin oppineet kertomaan.\n",
      "Enimmäkseen he ovat ilmaisen sosiaaliturvan perässä reissaavia nuoria miehiä, joita ei kiinnosta rakentaa omaa isänmaataan. Heitä kiinnostaa siivestäminen.”\n",
      "”Koska alun alkaenkaan he eivät täytä kansainvälistä suojelua koskevia kriteereitä, en tiedä, miksi heillä ylipäänsä pitäisi olla valitusoikeudet.\n",
      "Valitusoikeus kuormittaa oikeuslaitostamme kohtuuttomasti. Se ensimmäinenkin hakemus pitäisi tehdä pikapäätöksenä rajalla.\n",
      "Jos asiallisia henkilöpapereita ei ole, hakemusta ei pitäisi käsitellä lainkaan vaan suorittaa saman tien pikakäännytys ja sellainen leima takapuoleen, ettei takaisin tule.”\n",
      "Hakkarainen kysyi, mihin oikeuslaitoksemme joutuu, jos tänne tulee vielä kymmenkertainen määrä tulijoita.\n",
      "Hakkarainen totesi:\n",
      "”Minä arvioin, että todellisia hädänalaisia on meille tullut jokunen kymmenen, ehkä sata. Heitä meidän tulee auttaa, mikäli heidän tarinansa on aukottomasti todettavissa. Kaikkien muiden suhteen pikakäännytykset ovat ainoa oikeudenmukainen ratkaisu.”\n",
      "Hakkarainen viittasi puheessaan Australiaan, joka:\n",
      "”ei salli turvapaikkaturisteja kuljettavien veneiden rantautua ollenkaan maaperälleen. Australian laivasto saattaa veneet lähimmälle saarelle, joka ei kuulu Australialle.”\n",
      "\n",
      "Hakkarainen sanoi lopuksi:\n",
      "”Naurusaaret ja Papua-Uusi-Guinea ovat kohdemaat, jonne perustettuihin leireihin tulijat pistetään odottamaan. Siellä täytetään hakemukset ja siellä myös odotellaan päätöksiä niistä.\n",
      "EU:n tulisi ottaa mallia Australiasta. Koska EU:n päätöksiä ja jäsenmaiden yhtenäistä päätösten täytäntöönpanoa saamme ilmeisesti odottaa hamaan hautaan asti, tulisi meidän kyetä itsenäiseen päätöksentekoon. Suomi ei ole mikään maailman sosiaalitoimisto.”\n",
      "Lähde: verkkouutiset.fi (Juha-Pekka Tikka 5.4. 2016)\n",
      "T3/MV\n",
      "toimitus3mv@gmail.com\n",
      "\n",
      "<class 'numpy.float32'>\n",
      "feature vec = [1.8000000e+01 1.8000000e+01 1.0000000e+00 1.6411500e+05 1.4359950e+05\n",
      " 4.1033067e-03 0.0000000e+00 5.3200000e+02 9.0266669e+02 2.2210000e+03\n",
      " 2.2210000e+03 4.1322714e-01 1.2940000e+03 8.5600000e+02 0.0000000e+00\n",
      " 0.0000000e+00 9.0000002e+12 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 9.0000002e+12 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 9.0000002e+12 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 3.5900000e+02 3.5900000e+02 3.5900000e+02\n",
      " 5.0591362e-01 1.1260000e+03 1.0480000e+03 0.0000000e+00 0.0000000e+00\n",
      " 9.0000002e+12 0.0000000e+00 0.0000000e+00 0.0000000e+00 5.9533331e+02\n",
      " 1.3620000e+03 1.3300000e+02 4.3808833e-01 1.0470000e+03 4.5375000e+02\n",
      " 0.0000000e+00 0.0000000e+00 9.0000002e+12 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 9.0000002e+12 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 9.0000002e+12\n",
      " 5.4501569e-01 2.2580000e+03 2.2580000e+03 0.0000000e+00 0.0000000e+00\n",
      " 9.0000002e+12 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 9.0000002e+12 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      "feature vec_clean = <class 'numpy.ndarray'>\n",
      "feature vec_clean = <class 'numpy.float32'>\n",
      "feature vec_clean = [6.6666665e-13 6.6666665e-13 3.7037037e-14 6.0783334e-09 5.3184999e-09\n",
      " 1.5197432e-16 0.0000000e+00 1.9703704e-11 3.3432097e-11 8.2259255e-11\n",
      " 8.2259255e-11 1.5304708e-14 4.7925924e-11 3.1703702e-11 0.0000000e+00\n",
      " 0.0000000e+00 3.3333334e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 3.3333334e-01 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.3333334e-01 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 1.3296296e-11 1.3296296e-11 1.3296296e-11\n",
      " 1.8737541e-14 4.1703703e-11 3.8814812e-11 0.0000000e+00 0.0000000e+00\n",
      " 3.3333334e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.2049381e-11\n",
      " 5.0444444e-11 4.9259260e-12 1.6225494e-14 3.8777776e-11 1.6805555e-11\n",
      " 0.0000000e+00 0.0000000e+00 3.3333334e-01 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.3333334e-01 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.3333334e-01\n",
      " 2.0185766e-14 8.3629631e-11 8.3629631e-11 0.0000000e+00 0.0000000e+00\n",
      " 3.3333334e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 3.3333334e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      "80\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([ 81, 770, 146]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed(42)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "!pip install bs4 --user\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def clean_vector(v):\n",
    "        v = np.where(v > 900000000, 0, v)\n",
    "        return v\n",
    "    \n",
    "def normalize(v):\n",
    "    unit_vector = np.sqrt(sum(x ** 2 for x in v))\n",
    "    v = [x / unit_vector for x in v]\n",
    "    return np.array(v).astype(np.float32)\n",
    "\n",
    "def read_data():\n",
    "  dataset = pd.read_csv(\"MV_data_final_features_topics.csv\")\n",
    "  dataset['content'] =  dataset['content'].apply(lambda x: BeautifulSoup(x).get_text())\n",
    "  print(list(dataset['content'])[0])\n",
    "\n",
    "\n",
    "\n",
    "  #print(type(dataset[\"topic_vector\"][0]))\n",
    "  #print(dataset[\"topic_vector\"][0], end = \"\\n\\n\")\n",
    "\n",
    "  topic_vectors_prep = [vector.strip(\"[\").strip(\"]\") for vector in list(dataset[\"topic_vector\"])]\n",
    "  topic_vectors = [np.fromstring(vector, dtype=float, sep=',').astype(np.float32) for vector in topic_vectors_prep]\n",
    "  print(type(topic_vectors[0][0]))\n",
    "\n",
    "\n",
    "  feature_vectors_prep = [np.fromstring(vector, dtype=float, sep=\",\").astype(np.float32) for vector in list(dataset[\"feature_vector\"])]\n",
    "  print(f\"feature vec = {feature_vectors_prep[0]}\")\n",
    "  \n",
    "    \n",
    "  feature_vectors = [normalize(v) for v in feature_vectors_prep]\n",
    "  print(f\"feature vec_clean = {type(feature_vectors[0])}\")\n",
    "  print(f\"feature vec_clean = {type(feature_vectors[0][0])}\")\n",
    "  print(f\"feature vec_clean = {feature_vectors[0]}\")\n",
    "  print(len(feature_vectors[0]))\n",
    "\n",
    "\n",
    "  new_labels = []\n",
    "  for c in list(dataset['class']):\n",
    "    if c == 1: # kritiikki\n",
    "      new_labels.append(0)\n",
    "    elif c == 2: # kopiointi\n",
    "      new_labels.append(1)\n",
    "    elif c == 4: # oma narratiivi\n",
    "      new_labels.append(2)\n",
    "  documents = list(dataset['content'])\n",
    "  return train_test_split(documents, new_labels, topic_vectors, feature_vectors, random_state=42)\n",
    "  \n",
    "# call the function\n",
    "(train_texts, valid_texts, train_labels, valid_labels, train_topics, valid_topics, train_features, valid_features) = read_data()\n",
    "class_labels = [\"kritiikki\",\"kopiointi\",\"oma narratiivi\"]\n",
    "\n",
    "(train_classes, train_class_counts) = np.unique(train_labels,return_counts=True)\n",
    "(valid_classes, valid_class_counts) = np.unique(valid_labels,return_counts=True)\n",
    "(all_classes, all_class_counts) = np.unique(np.concatenate((train_labels,valid_labels)),return_counts=True)\n",
    "(all_classes,all_class_counts)\n",
    "\n",
    "##print(f\"len train: {len(train_topics)}\")\n",
    "##print(f\"len valid: {len(valid_topics)}\")\n",
    "\n",
    "##print(train_texts[0])\n",
    "\n",
    "##print(train_labels[0])\n",
    "\n",
    "##print(type(train_topics[0]))\n",
    "\n",
    "##print(len(train_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "E_r0ECJaXO-y"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (954 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(747, 1144, 250, 367, array([0, 1, 2]), array([ 137, 1040,  334]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed(42)\n",
    "def split_encodings(labels, topics, features, encodings, max_length):\n",
    "    new_labels = []\n",
    "    new_input_ids = []\n",
    "    new_token_type_ids = []\n",
    "    new_attention_mask = []\n",
    "    new_topic_vectors = []\n",
    "    new_feature_vectors = []\n",
    "    \n",
    "    input_ids = encodings['input_ids']\n",
    "    token_type_ids = encodings['token_type_ids']\n",
    "    attention_mask = encodings['attention_mask']\n",
    "    \n",
    "    for index,label in enumerate(labels):\n",
    "        cur_input_ids = input_ids[index]\n",
    "        cur_token_type_ids = token_type_ids[index]\n",
    "        cur_attention_mask = attention_mask[index]\n",
    "\n",
    "        while len(cur_input_ids)>max_length:\n",
    "            new_input_ids.append(cur_input_ids[0:max_length])\n",
    "            new_token_type_ids.append(cur_token_type_ids[0:max_length])\n",
    "            new_attention_mask.append(cur_attention_mask[0:max_length])\n",
    "            new_labels.append(label)\n",
    "            new_topic_vectors.append(topics[index])\n",
    "            new_feature_vectors.append(features[index])\n",
    "            \n",
    "            cur_input_ids = cur_input_ids[max_length:]\n",
    "            cur_token_type_ids = cur_token_type_ids[max_length:]\n",
    "            cur_attention_mask = cur_attention_mask[max_length:]\n",
    "            \n",
    "        if len(cur_input_ids)>0:\n",
    "            new_labels.append(label)\n",
    "            new_topic_vectors.append(topics[index])\n",
    "            new_feature_vectors.append(features[index])\n",
    "            new_input_ids.append(np.lib.pad(cur_input_ids,(0,max_length-len(cur_input_ids)),constant_values=(0)))\n",
    "            new_token_type_ids.append(np.lib.pad(cur_token_type_ids,(0,max_length-len(cur_input_ids)),constant_values=(0)))\n",
    "            new_attention_mask.append(np.lib.pad(cur_attention_mask,(0,max_length-len(cur_input_ids)),constant_values=(0)))   \n",
    "        \n",
    "    return (new_labels, new_topic_vectors, new_feature_vectors,{\n",
    "        'input_ids': new_input_ids,\n",
    "        'token_type_ids': new_token_type_ids,\n",
    "        'attention_mask': new_attention_mask\n",
    "    })\n",
    "\n",
    "\n",
    "model_name = \"TurkuNLP/bert-base-finnish-uncased-v1\" \n",
    "max_length = 512\n",
    "\n",
    "from transformers import BertTokenizerFast\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "train_encodings = tokenizer(train_texts)\n",
    "\n",
    "(train_snippets_labels, train_snippets_topics, train_snippets_features, train_snippets_encodings) = split_encodings(train_labels, train_topics, train_features, train_encodings,max_length)\n",
    "\n",
    "valid_encodings = tokenizer(valid_texts)\n",
    "\n",
    "(valid_snippets_labels, valid_snippets_topics, valid_snippets_features, valid_snippets_encodings) = split_encodings(valid_labels, valid_topics, valid_features, valid_encodings,max_length)\n",
    "\n",
    "(all_snippets_classes, all_snippets_class_counts) = np.unique(np.concatenate((train_snippets_labels,valid_snippets_labels)),return_counts=True)\n",
    "(len(train_labels),len(train_snippets_labels),len(valid_labels),len(valid_snippets_labels),all_snippets_classes, all_snippets_class_counts)\n",
    "\n",
    "##print(type(valid_snippets_topics[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AkZN1X-zOoe0"
   },
   "outputs": [],
   "source": [
    "# What is below is mostly a copy of BertForSequenceClassification, but with an added class_weights parameter, \n",
    "# which gets used to tune the loss function. While this could be done in other ways (compute_loss in Trainer)\n",
    "# this copy also acts as a useful insight into what actually happens within the classifier\n",
    "\n",
    "from transformers.models.bert import BertPreTrainedModel,BertModel\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from transformers.models.bert.configuration_bert import BertConfig\n",
    "from torch import nn\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "\n",
    "class BertConfigWithClassWeights(BertConfig):\n",
    "    def __init__(\n",
    "        self,\n",
    "        class_weights = None,\n",
    "        freeze_bert_weights = False,\n",
    "        use_topics = False,\n",
    "        use_features = False,\n",
    "        use_embeddings = False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        self.class_weights = class_weights\n",
    "        self.freeze_bert_weights = freeze_bert_weights\n",
    "        self.use_topics = use_topics\n",
    "        self.use_features = use_features\n",
    "        self.use_embeddings = use_embeddings\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "class BertForWeightedSequenceClassification(BertPreTrainedModel):\n",
    "    config_class = BertConfigWithClassWeights\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.config = config\n",
    "        self.class_weights = torch.tensor(self.config.class_weights) if self.config.class_weights else None\n",
    "        if torch.cuda.is_available():\n",
    "            self.class_weights = self.class_weights.to(\"cuda\")\n",
    "        self.bert = BertModel(config)\n",
    "        classifier_dropout = (\n",
    "            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n",
    "        )\n",
    "        self.dropout = nn.Dropout(classifier_dropout)\n",
    "        print(\"arvot\")\n",
    "        print(config.hidden_size, config.num_labels)\n",
    "        \n",
    "                # use topics and embeddings\n",
    "        if self.config.use_features and self.config.use_embeddings and self.config.use_topics:\n",
    "                #print(\"all featr\")\n",
    "                self.classifier = nn.Sequential(\n",
    "                                                nn.Linear(config.hidden_size + 80 + 200, config.hidden_size + 80 + 200),\n",
    "                                                nn.ReLU(),\n",
    "                                                nn.Dropout(),\n",
    "                                                nn.Linear(config.hidden_size + 80 + 200, config.num_labels))\n",
    "   \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "                # use only cls embeddings\n",
    "        else:\n",
    "            #print(\"only cls\")\n",
    "            self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "\n",
    "        self.init_weights()\n",
    "        if config.freeze_bert_weights:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        topics=None,\n",
    "        features=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in :obj:`[0, ...,\n",
    "            config.num_labels - 1]`. If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),\n",
    "            If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        #print(f\"input ids : {input_ids[:5]}\")\n",
    "        #print(f\"len input ids: {len(input_ids[:5])}\")\n",
    "        \n",
    "        #topic_vectors = {}\n",
    "        #for index in range(len(input_ids)):\n",
    "        #    topic_vectors[index] = torch.FloatTensor(get_topic_distribution(get_document_text(index))).to(\"cuda\")\n",
    "        \n",
    "            \n",
    "            \n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "    \n",
    "\n",
    "        pooled_output = outputs[1]\n",
    "\n",
    "        #list_of_tensors = [torch.cat((pooled_output[index], topics[index]), 0) for index in range(len(input_ids))]\n",
    "        \n",
    "        \n",
    "        # TOPICS AND EMBEDDINGS\n",
    "        if self.config.use_topics and self.config.use_embeddings and not self.config.use_features:\n",
    "            list_of_tensors = [torch.cat((pooled_output[index], topics[index]), 0) for index in range(len(input_ids))]\n",
    "            pooled_output = torch.stack(list_of_tensors)\n",
    "            \n",
    "        # TOPICS ONLY\n",
    "        elif self.config.use_topics and not self.config.use_embeddings:\n",
    "            if not self.config.use_features:\n",
    "                list_of_tensors = [topics[index] for index in range(len(input_ids))]\n",
    "                pooled_output = torch.stack(list_of_tensors)\n",
    "            elif self.config.use_features:\n",
    "                list_of_tensors = [torch.cat((topics[index], features[index]), 0) for index in range(len(input_ids))]\n",
    "            pooled_output = torch.stack(list_of_tensors)\n",
    "            \n",
    "        elif self.config.use_topics and self.config.use_features and not self.config.use_embeddings:\n",
    "            list_of_tensors = [torch.cat((topics[index], features[index]), 0) for index in range(len(input_ids))]\n",
    "            pooled_output = torch.stack(list_of_tensors)\n",
    "            \n",
    "        # FEATURES ONLY\n",
    "        \n",
    "        elif self.config.use_features and not self.config.use_topics and not self.config.use_embeddings:\n",
    "            list_of_tensors = [features[index] for index in range(len(input_ids))]\n",
    "            pooled_output = torch.stack(list_of_tensors)\n",
    "    \n",
    "            \n",
    "        # CLS and structural features\n",
    "        elif self.config.use_features and self.config.use_embeddings and not self.config.use_topics:\n",
    "            list_of_tensors = [torch.cat((pooled_output[index], features[index]), 0) for index in range(len(input_ids))]\n",
    "            pooled_output = torch.stack(list_of_tensors)\n",
    "        \n",
    "        # all features combined\n",
    "            \n",
    "        elif self.config.use_features and self.config.use_topics and self.config.use_embeddings:\n",
    "            #print(\"yess\")\n",
    "            list_of_tensors = [torch.cat((pooled_output[index], features[index], topics[index]), 0) for index in range(len(input_ids))]\n",
    "            #print(len(list_of_tensors[0]))\n",
    "            pooled_output = torch.stack(list_of_tensors)\n",
    "\n",
    "        # EMBEDDINGS ONLY\n",
    "        \n",
    "        #print(len(pooled_output[3]))\n",
    "        \n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "\n",
    "\n",
    "         \n",
    "        logits = self.classifier(pooled_output)  \n",
    "      \n",
    "                      \n",
    "    \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                if self.num_labels == 1:\n",
    "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "                else:\n",
    "                    loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = CrossEntropyLoss(weight=self.class_weights)\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = BCEWithLogitsLoss(pos_weight=self.class_weights)\n",
    "                loss = loss_fct(logits, labels)\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# this function defines the metrics reported by our trainer in each evaluation pass\n",
    "def compute_metrics(pred):\n",
    "  labels = pred.label_ids\n",
    "  preds = pred.predictions.argmax(-1)\n",
    "  acc = accuracy_score(labels, preds)\n",
    "  cm = confusion_matrix(labels, preds)\n",
    "  return {\n",
    "      'accuracy': acc,\n",
    "      'confusion_matrix': str(cm)\n",
    "  }\n",
    "\n",
    "# this container mostly serves to turn our data into torch tensors when needed\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels, topics, features):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.topics = topics\n",
    "        self.features = features\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        item[\"topics\"] = torch.tensor(self.topics[idx])\n",
    "        item[\"features\"] = torch.tensor(self.features[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: Binary categorization into kopionti / other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOPICS ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "mlflow.end_run()\n",
    "class_labels_binary = [\"kritiikki/oma narratiivi\",\"kopiointi\"]\n",
    "train_snippets_labels_binary = [1 if x==1 else 0 for x in train_snippets_labels]\n",
    "valid_snippets_labels_binary = [1 if x==1 else 0 for x in valid_snippets_labels]\n",
    "(all_snippets_classes_binary, all_snippets_class_counts_binary) = np.unique(np.concatenate((train_snippets_labels_binary,valid_snippets_labels_binary)),return_counts=True)\n",
    "train_dataset_binary = Dataset(train_snippets_encodings, train_snippets_labels_binary, train_snippets_topics, train_snippets_features)\n",
    "valid_dataset_binary = Dataset(valid_snippets_encodings, valid_snippets_labels_binary, valid_snippets_topics, valid_snippets_features)\n",
    "num_classes = 2\n",
    "class_weights = (1/all_snippets_class_counts_binary).tolist()\n",
    "#class_weights = ((np.sum(all_snippets_class_counts)-all_snippets_class_counts)/all_snippets_class_counts).tolist()\n",
    "#class_weights = [5.0,1.0]\n",
    "freeze_bert_weights = True\n",
    "use_topics = True\n",
    "use_features = False\n",
    "use_embeddings = False\n",
    "\n",
    "print(all_snippets_class_counts_binary,class_weights)\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.trainer_utils import SchedulerType\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "training_args_binary = TrainingArguments(\n",
    "    output_dir='./results_binary',          # output directory\n",
    "    num_train_epochs=400,              # total number of training epochs\n",
    "    per_device_train_batch_size=batch_size,  # batch size per device during training\n",
    "    per_device_eval_batch_size=512,   # batch size for evaluation\n",
    "#    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs_binary',            # directory for storing logs\n",
    "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
    "    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
    "    warmup_steps=max(10,1000//2//batch_size),                # number of warmup steps for learning rate scheduler\n",
    "    logging_steps=max(1,4000//batch_size),               # log & save weights each logging_steps\n",
    "    save_steps=max(1,4000//batch_size),\n",
    "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",
    "    save_strategy=\"steps\",\n",
    "#    lr_scheduler_type = SchedulerType.COSINE_WITH_RESTARTS\n",
    ")\n",
    "\n",
    "model_binary = BertForWeightedSequenceClassification.from_pretrained(model_name, \n",
    "                                                                     num_labels=num_classes, \n",
    "                                                                     problem_type='single_label_classification', \n",
    "                                                                     class_weights=class_weights, \n",
    "                                                                     freeze_bert_weights=freeze_bert_weights, \n",
    "                                                                     use_topics=use_topics, \n",
    "                                                                     use_features=use_features,\n",
    "                                                                     use_embeddings=use_embeddings)\n",
    "if torch.cuda.is_available():\n",
    "  model_binary = model_binary.to(\"cuda\")\n",
    "\n",
    "trainer_binary = Trainer(\n",
    "  model=model_binary,                         # the instantiated Transformers model to be trained\n",
    "  args=training_args_binary,                  # training arguments, defined above\n",
    "  train_dataset=train_dataset_binary,         # training dataset\n",
    "  eval_dataset=valid_dataset_binary,          # evaluation dataset\n",
    "  compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    ")\n",
    "trainer_binary.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "preds = trainer_binary.predict(valid_dataset_binary)\n",
    "print(preds.metrics['test_confusion_matrix'])\n",
    "for index, (logits, label) in enumerate(zip(preds.predictions,preds.label_ids)):\n",
    "    pred_label = logits.argmax()\n",
    "    if pred_label != label:\n",
    "        text = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(valid_snippets_encodings['input_ids'][index]))\n",
    "        text = re.sub(\"\\[PAD\\]\",\"\",text).strip()\n",
    "        print(f\"* Predicted {class_labels_binary[pred_label]} ({logits}) != real {class_labels_binary[label]} for:\\n{text}\")\n",
    "        bin_topics.append((text, class_labels_binary[pred_label], class_labels_binary[label]))\n",
    "        \n",
    "df = pd.DataFrame.from_dict(bin_topics)\n",
    "df.to_csv(\"bin_topics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_topics[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURES ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "mlflow.end_run()\n",
    "class_labels_binary = [\"kritiikki/oma narratiivi\",\"kopiointi\"]\n",
    "train_snippets_labels_binary = [1 if x==1 else 0 for x in train_snippets_labels]\n",
    "valid_snippets_labels_binary = [1 if x==1 else 0 for x in valid_snippets_labels]\n",
    "(all_snippets_classes_binary, all_snippets_class_counts_binary) = np.unique(np.concatenate((train_snippets_labels_binary,valid_snippets_labels_binary)),return_counts=True)\n",
    "train_dataset_binary = Dataset(train_snippets_encodings, train_snippets_labels_binary, train_snippets_topics, train_snippets_features)\n",
    "valid_dataset_binary = Dataset(valid_snippets_encodings, valid_snippets_labels_binary, valid_snippets_topics, valid_snippets_features)\n",
    "num_classes = 2\n",
    "class_weights = (1/all_snippets_class_counts_binary).tolist()\n",
    "#class_weights = ((np.sum(all_snippets_class_counts)-all_snippets_class_counts)/all_snippets_class_counts).tolist()\n",
    "#class_weights = [5.0,1.0]\n",
    "freeze_bert_weights = True\n",
    "use_features = True\n",
    "use_topics = False\n",
    "use_embeddings = False\n",
    "\n",
    "print(all_snippets_class_counts_binary,class_weights)\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.trainer_utils import SchedulerType\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "training_args_binary = TrainingArguments(\n",
    "    output_dir='./results_binary',          # output directory\n",
    "    num_train_epochs=400,              # total number of training epochs\n",
    "    per_device_train_batch_size=batch_size,  # batch size per device during training\n",
    "    per_device_eval_batch_size=512,   # batch size for evaluation\n",
    "#    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs_binary',            # directory for storing logs\n",
    "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
    "    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
    "    warmup_steps=max(10,1000//2//batch_size),                # number of warmup steps for learning rate scheduler\n",
    "    logging_steps=max(1,4000//batch_size),               # log & save weights each logging_steps\n",
    "    save_steps=max(1,4000//batch_size),\n",
    "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",
    "    save_strategy=\"steps\",\n",
    "#    lr_scheduler_type = SchedulerType.COSINE_WITH_RESTARTS\n",
    ")\n",
    "\n",
    "model_binary = BertForWeightedSequenceClassification.from_pretrained(model_name, \n",
    "                                                                     num_labels=num_classes, \n",
    "                                                                     problem_type='single_label_classification', \n",
    "                                                                     class_weights=class_weights, \n",
    "                                                                     freeze_bert_weights=freeze_bert_weights, \n",
    "                                                                     use_topics=use_topics,\n",
    "                                                                     use_features=use_features,\n",
    "                                                                     use_embeddings=use_embeddings)\n",
    "if torch.cuda.is_available():\n",
    "  model_binary = model_binary.to(\"cuda\")\n",
    "\n",
    "trainer_binary = Trainer(\n",
    "  model=model_binary,                         # the instantiated Transformers model to be trained\n",
    "  args=training_args_binary,                  # training arguments, defined above\n",
    "  train_dataset=train_dataset_binary,         # training dataset\n",
    "  eval_dataset=valid_dataset_binary,          # evaluation dataset\n",
    "  compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    ")\n",
    "trainer_binary.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preds = trainer_binary.predict(valid_dataset_binary)\n",
    "print(preds.metrics['test_confusion_matrix'])\n",
    "for index, (logits, label) in enumerate(zip(preds.predictions,preds.label_ids)):\n",
    "    pred_label = logits.argmax()\n",
    "    if pred_label != label:\n",
    "        text = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(valid_snippets_encodings['input_ids'][index]))\n",
    "        text = re.sub(\"\\[PAD\\]\",\"\",text).strip()\n",
    "        print(f\"* Predicted {class_labels_binary[pred_label]} ({logits}) != real {class_labels_binary[label]} for:\\n{text}\")\n",
    "        bin_features.append((text, class_labels_binary[pred_label], class_labels_binary[label]))\n",
    "        \n",
    "df = pd.DataFrame.from_dict(bin_features)\n",
    "df.to_csv(\"bin_features_normalized.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMBEDDINGS ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "mlflow.end_run()\n",
    "class_labels_binary = [\"kritiikki/oma narratiivi\",\"kopiointi\"]\n",
    "train_snippets_labels_binary = [1 if x==1 else 0 for x in train_snippets_labels]\n",
    "valid_snippets_labels_binary = [1 if x==1 else 0 for x in valid_snippets_labels]\n",
    "(all_snippets_classes_binary, all_snippets_class_counts_binary) = np.unique(np.concatenate((train_snippets_labels_binary,valid_snippets_labels_binary)),return_counts=True)\n",
    "train_dataset_binary = Dataset(train_snippets_encodings, train_snippets_labels_binary, train_snippets_topics, train_snippets_features)\n",
    "valid_dataset_binary = Dataset(valid_snippets_encodings, valid_snippets_labels_binary, valid_snippets_topics, valid_snippets_features)\n",
    "num_classes = 2\n",
    "class_weights = (1/all_snippets_class_counts_binary).tolist()\n",
    "#class_weights = ((np.sum(all_snippets_class_counts)-all_snippets_class_counts)/all_snippets_class_counts).tolist()\n",
    "#class_weights = [5.0,1.0]\n",
    "freeze_bert_weights = True\n",
    "use_topics = False\n",
    "use_features = False\n",
    "use_embeddings = True\n",
    "\n",
    "print(all_snippets_class_counts_binary,class_weights)\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.trainer_utils import SchedulerType\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "training_args_binary = TrainingArguments(\n",
    "    output_dir='./results_binary',          # output directory\n",
    "    num_train_epochs=400,              # total number of training epochs\n",
    "    per_device_train_batch_size=batch_size,  # batch size per device during training\n",
    "    per_device_eval_batch_size=512,   # batch size for evaluation\n",
    "#    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs_binary',            # directory for storing logs\n",
    "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
    "    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
    "    warmup_steps=max(10,1000//2//batch_size),                # number of warmup steps for learning rate scheduler\n",
    "    logging_steps=max(1,4000//batch_size),               # log & save weights each logging_steps\n",
    "    save_steps=max(1,4000//batch_size),\n",
    "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",
    "    save_strategy=\"steps\",\n",
    "#    lr_scheduler_type = SchedulerType.COSINE_WITH_RESTARTS\n",
    ")\n",
    "\n",
    "model_binary = BertForWeightedSequenceClassification.from_pretrained(model_name, \n",
    "                                                                     num_labels=num_classes, \n",
    "                                                                     problem_type='single_label_classification', \n",
    "                                                                     class_weights=class_weights, \n",
    "                                                                     freeze_bert_weights=freeze_bert_weights, \n",
    "                                                                     use_topics=use_topics, \n",
    "                                                                     use_features=use_features,\n",
    "                                                                     use_embeddings=use_embeddings)\n",
    "if torch.cuda.is_available():\n",
    "  model_binary = model_binary.to(\"cuda\")\n",
    "\n",
    "trainer_binary = Trainer(\n",
    "  model=model_binary,                         # the instantiated Transformers model to be trained\n",
    "  args=training_args_binary,                  # training arguments, defined above\n",
    "  train_dataset=train_dataset_binary,         # training dataset\n",
    "  eval_dataset=valid_dataset_binary,          # evaluation dataset\n",
    "  compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    ")\n",
    "trainer_binary.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preds = trainer_binary.predict(valid_dataset_binary)\n",
    "print(preds.metrics['test_confusion_matrix'])\n",
    "for index, (logits, label) in enumerate(zip(preds.predictions,preds.label_ids)):\n",
    "    pred_label = logits.argmax()\n",
    "    if pred_label != label:\n",
    "        text = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(valid_snippets_encodings['input_ids'][index]))\n",
    "        text = re.sub(\"\\[PAD\\]\",\"\",text).strip()\n",
    "        print(f\"* Predicted {class_labels_binary[pred_label]} ({logits}) != real {class_labels_binary[label]} for:\\n{text}\")\n",
    "        bin_embeds.append((text, class_labels_binary[pred_label], class_labels_binary[label]))\n",
    "        \n",
    "df = pd.DataFrame.from_dict(bin_embeds)\n",
    "df.to_csv(\"bin_embeds.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOPICS + FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "mlflow.end_run()\n",
    "class_labels_binary = [\"kritiikki/oma narratiivi\",\"kopiointi\"]\n",
    "train_snippets_labels_binary = [1 if x==1 else 0 for x in train_snippets_labels]\n",
    "valid_snippets_labels_binary = [1 if x==1 else 0 for x in valid_snippets_labels]\n",
    "(all_snippets_classes_binary, all_snippets_class_counts_binary) = np.unique(np.concatenate((train_snippets_labels_binary,valid_snippets_labels_binary)),return_counts=True)\n",
    "train_dataset_binary = Dataset(train_snippets_encodings, train_snippets_labels_binary, train_snippets_topics, train_snippets_features)\n",
    "valid_dataset_binary = Dataset(valid_snippets_encodings, valid_snippets_labels_binary, valid_snippets_topics, valid_snippets_features)\n",
    "num_classes = 2\n",
    "class_weights = (1/all_snippets_class_counts_binary).tolist()\n",
    "#class_weights = ((np.sum(all_snippets_class_counts)-all_snippets_class_counts)/all_snippets_class_counts).tolist()\n",
    "#class_weights = [5.0,1.0]\n",
    "freeze_bert_weights = True\n",
    "use_topics = True\n",
    "use_features = True\n",
    "use_embeddings = False\n",
    "\n",
    "print(all_snippets_class_counts_binary,class_weights)\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.trainer_utils import SchedulerType\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "training_args_binary = TrainingArguments(\n",
    "    output_dir='./results_binary',          # output directory\n",
    "    num_train_epochs=400,              # total number of training epochs\n",
    "    per_device_train_batch_size=batch_size,  # batch size per device during training\n",
    "    per_device_eval_batch_size=512,   # batch size for evaluation\n",
    "#    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs_binary',            # directory for storing logs\n",
    "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
    "    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
    "    warmup_steps=max(10,1000//2//batch_size),                # number of warmup steps for learning rate scheduler\n",
    "    logging_steps=max(1,4000//batch_size),               # log & save weights each logging_steps\n",
    "    save_steps=max(1,4000//batch_size),\n",
    "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",
    "    save_strategy=\"steps\",\n",
    "#    lr_scheduler_type = SchedulerType.COSINE_WITH_RESTARTS\n",
    ")\n",
    "\n",
    "model_binary = BertForWeightedSequenceClassification.from_pretrained(model_name, \n",
    "                                                                     num_labels=num_classes, \n",
    "                                                                     problem_type='single_label_classification', \n",
    "                                                                     class_weights=class_weights, \n",
    "                                                                     freeze_bert_weights=freeze_bert_weights, \n",
    "                                                                     use_topics=use_topics, \n",
    "                                                                     use_features=use_features,\n",
    "                                                                     use_embeddings=use_embeddings)\n",
    "if torch.cuda.is_available():\n",
    "  model_binary = model_binary.to(\"cuda\")\n",
    "\n",
    "trainer_binary = Trainer(\n",
    "  model=model_binary,                         # the instantiated Transformers model to be trained\n",
    "  args=training_args_binary,                  # training arguments, defined above\n",
    "  train_dataset=train_dataset_binary,         # training dataset\n",
    "  eval_dataset=valid_dataset_binary,          # evaluation dataset\n",
    "  compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    ")\n",
    "trainer_binary.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preds = trainer_binary.predict(valid_dataset_binary)\n",
    "print(preds.metrics['test_confusion_matrix'])\n",
    "for index, (logits, label) in enumerate(zip(preds.predictions,preds.label_ids)):\n",
    "    pred_label = logits.argmax()\n",
    "    if pred_label != label:\n",
    "        text = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(valid_snippets_encodings['input_ids'][index]))\n",
    "        text = re.sub(\"\\[PAD\\]\",\"\",text).strip()\n",
    "        print(f\"* Predicted {class_labels_binary[pred_label]} ({logits}) != real {class_labels_binary[label]} for:\\n{text}\")\n",
    "        bin_topics_features.append((text, class_labels_binary[pred_label], class_labels_binary[label]))\n",
    "        \n",
    "df = pd.DataFrame.from_dict(bin_topics_features)\n",
    "df.to_csv(\"bin_topics_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOPICS + EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "mlflow.end_run()\n",
    "class_labels_binary = [\"kritiikki/oma narratiivi\",\"kopiointi\"]\n",
    "train_snippets_labels_binary = [1 if x==1 else 0 for x in train_snippets_labels]\n",
    "valid_snippets_labels_binary = [1 if x==1 else 0 for x in valid_snippets_labels]\n",
    "(all_snippets_classes_binary, all_snippets_class_counts_binary) = np.unique(np.concatenate((train_snippets_labels_binary,valid_snippets_labels_binary)),return_counts=True)\n",
    "train_dataset_binary = Dataset(train_snippets_encodings, train_snippets_labels_binary, train_snippets_topics, train_snippets_features)\n",
    "valid_dataset_binary = Dataset(valid_snippets_encodings, valid_snippets_labels_binary, valid_snippets_topics, valid_snippets_features)\n",
    "num_classes = 2\n",
    "class_weights = (1/all_snippets_class_counts_binary).tolist()\n",
    "#class_weights = ((np.sum(all_snippets_class_counts)-all_snippets_class_counts)/all_snippets_class_counts).tolist()\n",
    "#class_weights = [5.0,1.0]\n",
    "freeze_bert_weights = True\n",
    "use_topics = True\n",
    "use_features = False\n",
    "use_embeddings = True\n",
    "\n",
    "print(all_snippets_class_counts_binary,class_weights)\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.trainer_utils import SchedulerType\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "training_args_binary = TrainingArguments(\n",
    "    output_dir='./results_binary',          # output directory\n",
    "    num_train_epochs=400,              # total number of training epochs\n",
    "    per_device_train_batch_size=batch_size,  # batch size per device during training\n",
    "    per_device_eval_batch_size=512,   # batch size for evaluation\n",
    "#    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs_binary',            # directory for storing logs\n",
    "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
    "    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
    "    warmup_steps=max(10,1000//2//batch_size),                # number of warmup steps for learning rate scheduler\n",
    "    logging_steps=max(1,4000//batch_size),               # log & save weights each logging_steps\n",
    "    save_steps=max(1,4000//batch_size),\n",
    "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",
    "    save_strategy=\"steps\",\n",
    "#    lr_scheduler_type = SchedulerType.COSINE_WITH_RESTARTS\n",
    ")\n",
    "\n",
    "model_binary = BertForWeightedSequenceClassification.from_pretrained(model_name, \n",
    "                                                                     num_labels=num_classes, \n",
    "                                                                     problem_type='single_label_classification', \n",
    "                                                                     class_weights=class_weights, \n",
    "                                                                     freeze_bert_weights=freeze_bert_weights, \n",
    "                                                                     use_topics=use_topics, \n",
    "                                                                     use_features=use_features,\n",
    "                                                                     use_embeddings=use_embeddings)\n",
    "if torch.cuda.is_available():\n",
    "  model_binary = model_binary.to(\"cuda\")\n",
    "\n",
    "trainer_binary = Trainer(\n",
    "  model=model_binary,                         # the instantiated Transformers model to be trained\n",
    "  args=training_args_binary,                  # training arguments, defined above\n",
    "  train_dataset=train_dataset_binary,         # training dataset\n",
    "  eval_dataset=valid_dataset_binary,          # evaluation dataset\n",
    "  compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    ")\n",
    "trainer_binary.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preds = trainer_binary.predict(valid_dataset_binary)\n",
    "print(preds.metrics['test_confusion_matrix'])\n",
    "for index, (logits, label) in enumerate(zip(preds.predictions,preds.label_ids)):\n",
    "    pred_label = logits.argmax()\n",
    "    if pred_label != label:\n",
    "        text = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(valid_snippets_encodings['input_ids'][index]))\n",
    "        text = re.sub(\"\\[PAD\\]\",\"\",text).strip()\n",
    "        print(f\"* Predicted {class_labels_binary[pred_label]} ({logits}) != real {class_labels_binary[label]} for:\\n{text}\")\n",
    "        bin_topics_embeds.append((text, class_labels_binary[pred_label], class_labels_binary[label]))\n",
    "        \n",
    "df = pd.DataFrame.from_dict(bin_topics_embeds)\n",
    "df.to_csv(\"bin_topics_embeds.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURES + EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "mlflow.end_run()\n",
    "class_labels_binary = [\"kritiikki/oma narratiivi\",\"kopiointi\"]\n",
    "train_snippets_labels_binary = [1 if x==1 else 0 for x in train_snippets_labels]\n",
    "valid_snippets_labels_binary = [1 if x==1 else 0 for x in valid_snippets_labels]\n",
    "(all_snippets_classes_binary, all_snippets_class_counts_binary) = np.unique(np.concatenate((train_snippets_labels_binary,valid_snippets_labels_binary)),return_counts=True)\n",
    "train_dataset_binary = Dataset(train_snippets_encodings, train_snippets_labels_binary, train_snippets_topics, train_snippets_features)\n",
    "valid_dataset_binary = Dataset(valid_snippets_encodings, valid_snippets_labels_binary, valid_snippets_topics, valid_snippets_features)\n",
    "num_classes = 2\n",
    "class_weights = (1/all_snippets_class_counts_binary).tolist()\n",
    "#class_weights = ((np.sum(all_snippets_class_counts)-all_snippets_class_counts)/all_snippets_class_counts).tolist()\n",
    "#class_weights = [5.0,1.0]\n",
    "freeze_bert_weights = True\n",
    "use_topics = False\n",
    "use_features = True\n",
    "use_embeddings = True\n",
    "\n",
    "print(all_snippets_class_counts_binary,class_weights)\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.trainer_utils import SchedulerType\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "training_args_binary = TrainingArguments(\n",
    "    output_dir='./results_binary',          # output directory\n",
    "    num_train_epochs=400,              # total number of training epochs\n",
    "    per_device_train_batch_size=batch_size,  # batch size per device during training\n",
    "    per_device_eval_batch_size=512,   # batch size for evaluation\n",
    "#    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs_binary',            # directory for storing logs\n",
    "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
    "    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
    "    warmup_steps=max(10,1000//2//batch_size),                # number of warmup steps for learning rate scheduler\n",
    "    logging_steps=max(1,4000//batch_size),               # log & save weights each logging_steps\n",
    "    save_steps=max(1,4000//batch_size),\n",
    "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",
    "    save_strategy=\"steps\",\n",
    "#    lr_scheduler_type = SchedulerType.COSINE_WITH_RESTARTS\n",
    ")\n",
    "\n",
    "model_binary = BertForWeightedSequenceClassification.from_pretrained(model_name, \n",
    "                                                                     num_labels=num_classes, \n",
    "                                                                     problem_type='single_label_classification', \n",
    "                                                                     class_weights=class_weights, \n",
    "                                                                     freeze_bert_weights=freeze_bert_weights, \n",
    "                                                                     use_topics=use_topics, \n",
    "                                                                     use_features=use_features,\n",
    "                                                                     use_embeddings=use_embeddings)\n",
    "if torch.cuda.is_available():\n",
    "  model_binary = model_binary.to(\"cuda\")\n",
    "\n",
    "trainer_binary = Trainer(\n",
    "  model=model_binary,                         # the instantiated Transformers model to be trained\n",
    "  args=training_args_binary,                  # training arguments, defined above\n",
    "  train_dataset=train_dataset_binary,         # training dataset\n",
    "  eval_dataset=valid_dataset_binary,          # evaluation dataset\n",
    "  compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    ")\n",
    "trainer_binary.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preds = trainer_binary.predict(valid_dataset_binary)\n",
    "print(preds.metrics['test_confusion_matrix'])\n",
    "for index, (logits, label) in enumerate(zip(preds.predictions,preds.label_ids)):\n",
    "    pred_label = logits.argmax()\n",
    "    if pred_label != label:\n",
    "        text = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(valid_snippets_encodings['input_ids'][index]))\n",
    "        text = re.sub(\"\\[PAD\\]\",\"\",text).strip()\n",
    "        print(f\"* Predicted {class_labels_binary[pred_label]} ({logits}) != real {class_labels_binary[label]} for:\\n{text}\")\n",
    "        bin_features_embeds.append((text, class_labels_binary[pred_label], class_labels_binary[label]))\n",
    "        \n",
    "df = pd.DataFrame.from_dict(bin_features_embeds)\n",
    "df.to_csv(\"bin_features_embeds.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: three categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONLY TOPICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "s5a7QY_wP5iD",
    "outputId": "f54e78da-4afc-44d5-948b-cf64f5bfa422",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "mlflow.end_run()\n",
    "train_dataset = Dataset(train_snippets_encodings, train_snippets_labels, train_snippets_topics, train_snippets_features)\n",
    "valid_dataset = Dataset(valid_snippets_encodings, valid_snippets_labels, valid_snippets_topics, valid_snippets_features)\n",
    "\n",
    "#train_dataset = Dataset(None, train_snippets_labels, train_snippets_topics)\n",
    "#valid_dataset = Dataset(None, valid_snippets_labels, valid_snippets_topics)\n",
    "\n",
    "\n",
    "\n",
    "num_classes = 3\n",
    "class_weights = (1/all_snippets_class_counts).tolist()\n",
    "#class_weights = ((np.sum(all_snippets_class_counts)-all_snippets_class_counts)/all_snippets_class_counts).tolist()\n",
    "#class_weights = [100.0,1.0,100.0]\n",
    "freeze_bert_weights = True\n",
    "\n",
    "use_topics = True\n",
    "use_features = False\n",
    "use_embeddings = False\n",
    "\n",
    "print(all_snippets_class_counts,class_weights)\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.trainer_utils import SchedulerType\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=400,              # total number of training epochs\n",
    "    per_device_train_batch_size=batch_size,  # batch size per device during training\n",
    "    per_device_eval_batch_size=512,   # batch size for evaluation\n",
    "#    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
    "    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
    "    warmup_steps=max(10,1000//2//batch_size),                # number of warmup steps for learning rate scheduler\n",
    "    logging_steps=max(1,4000//batch_size),               # log & save weights each logging_steps\n",
    "    save_steps=max(1,4000//batch_size),\n",
    "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",
    "    save_strategy=\"steps\",\n",
    "#    lr_scheduler_type = SchedulerType.COSINE_WITH_RESTARTS\n",
    ")\n",
    "model = BertForWeightedSequenceClassification.from_pretrained(model_name, \n",
    "                                                              num_labels=num_classes, \n",
    "                                                              problem_type='single_label_classification', \n",
    "                                                              class_weights=class_weights, \n",
    "                                                              freeze_bert_weights=freeze_bert_weights, \n",
    "                                                              use_topics=use_topics, \n",
    "                                                              use_features=use_features,\n",
    "                                                              use_embeddings=use_embeddings)\n",
    "if torch.cuda.is_available():\n",
    "  model = model.to(\"cuda\")\n",
    "\n",
    "trainer = Trainer(\n",
    "  model=model,                         # the instantiated Transformers model to be trained\n",
    "  args=training_args,                  # training arguments, defined above\n",
    "  train_dataset=train_dataset,         # training dataset\n",
    "  eval_dataset=valid_dataset,          # evaluation dataset\n",
    "  compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "preds = trainer.predict(valid_dataset)\n",
    "print(preds.metrics['test_confusion_matrix'])\n",
    "for index, (logits, label) in enumerate(zip(preds.predictions,preds.label_ids)):\n",
    "    pred_label = logits.argmax()\n",
    "    if pred_label != label:\n",
    "        text = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(valid_snippets_encodings['input_ids'][index]))\n",
    "        text = re.sub(\"\\[PAD\\]\",\"\",text).strip()\n",
    "        print(f\"Predicted {class_labels[pred_label]} ({logits}) != real {class_labels[label]} for:\\n{text}\")\n",
    "        multi_topics.append((text, class_labels[pred_label], class_labels[label]))\n",
    "        \n",
    "df = pd.DataFrame.from_dict(multi_topics)\n",
    "df.to_csv(\"multi_topics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_only_topics[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONLY FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "s5a7QY_wP5iD",
    "outputId": "f54e78da-4afc-44d5-948b-cf64f5bfa422",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "mlflow.end_run()\n",
    "train_dataset = Dataset(train_snippets_encodings, train_snippets_labels, train_snippets_topics, train_snippets_features)\n",
    "valid_dataset = Dataset(valid_snippets_encodings, valid_snippets_labels, valid_snippets_topics, valid_snippets_features)\n",
    "\n",
    "#train_dataset = Dataset(None, train_snippets_labels, train_snippets_topics)\n",
    "#valid_dataset = Dataset(None, valid_snippets_labels, valid_snippets_topics)\n",
    "\n",
    "\n",
    "\n",
    "num_classes = 3\n",
    "class_weights = (1/all_snippets_class_counts).tolist()\n",
    "#class_weights = ((np.sum(all_snippets_class_counts)-all_snippets_class_counts)/all_snippets_class_counts).tolist()\n",
    "#class_weights = [100.0,1.0,100.0]\n",
    "freeze_bert_weights = True\n",
    "\n",
    "use_features = True\n",
    "use_topics = False\n",
    "use_embeddings = False\n",
    "\n",
    "print(all_snippets_class_counts,class_weights)\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.trainer_utils import SchedulerType\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=400,              # total number of training epochs\n",
    "    per_device_train_batch_size=batch_size,  # batch size per device during training\n",
    "    per_device_eval_batch_size=512,   # batch size for evaluation\n",
    "#    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
    "    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
    "    warmup_steps=max(10,1000//2//batch_size),                # number of warmup steps for learning rate scheduler\n",
    "    logging_steps=max(1,4000//batch_size),               # log & save weights each logging_steps\n",
    "    save_steps=max(1,4000//batch_size),\n",
    "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",
    "    save_strategy=\"steps\",\n",
    "#    lr_scheduler_type = SchedulerType.COSINE_WITH_RESTARTS\n",
    ")\n",
    "model = BertForWeightedSequenceClassification.from_pretrained(model_name, \n",
    "                                                              num_labels=num_classes, \n",
    "                                                              problem_type='single_label_classification', \n",
    "                                                              class_weights=class_weights, \n",
    "                                                              freeze_bert_weights=freeze_bert_weights, \n",
    "                                                              use_topics=use_topics, \n",
    "                                                              use_features=use_features,\n",
    "                                                              use_embeddings=use_embeddings)\n",
    "if torch.cuda.is_available():\n",
    "  model = model.to(\"cuda\")\n",
    "\n",
    "trainer = Trainer(\n",
    "  model=model,                         # the instantiated Transformers model to be trained\n",
    "  args=training_args,                  # training arguments, defined above\n",
    "  train_dataset=train_dataset,         # training dataset\n",
    "  eval_dataset=valid_dataset,          # evaluation dataset\n",
    "  compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "preds = trainer.predict(valid_dataset)\n",
    "print(preds.metrics['test_confusion_matrix'])\n",
    "for index, (logits, label) in enumerate(zip(preds.predictions,preds.label_ids)):\n",
    "    pred_label = logits.argmax()\n",
    "    if pred_label != label:\n",
    "        text = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(valid_snippets_encodings['input_ids'][index]))\n",
    "        text = re.sub(\"\\[PAD\\]\",\"\",text).strip()\n",
    "        print(f\"Predicted {class_labels[pred_label]} ({logits}) != real {class_labels[label]} for:\\n{text}\")\n",
    "        multi_features.append((text, class_labels[pred_label], class_labels[label]))\n",
    "        \n",
    "df = pd.DataFrame.from_dict(multi_features)\n",
    "df.to_csv(\"multi_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONLY EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "s5a7QY_wP5iD",
    "outputId": "f54e78da-4afc-44d5-948b-cf64f5bfa422",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "mlflow.end_run()\n",
    "train_dataset = Dataset(train_snippets_encodings, train_snippets_labels, train_snippets_topics, train_snippets_features)\n",
    "valid_dataset = Dataset(valid_snippets_encodings, valid_snippets_labels, valid_snippets_topics, valid_snippets_features)\n",
    "\n",
    "#train_dataset = Dataset(None, train_snippets_labels, train_snippets_topics)\n",
    "#valid_dataset = Dataset(None, valid_snippets_labels, valid_snippets_topics)\n",
    "\n",
    "\n",
    "\n",
    "num_classes = 3\n",
    "class_weights = (1/all_snippets_class_counts).tolist()\n",
    "#class_weights = ((np.sum(all_snippets_class_counts)-all_snippets_class_counts)/all_snippets_class_counts).tolist()\n",
    "#class_weights = [100.0,1.0,100.0]\n",
    "freeze_bert_weights = True\n",
    "use_topics = False\n",
    "use_features = False\n",
    "use_embeddings = True\n",
    "\n",
    "\n",
    "print(all_snippets_class_counts,class_weights)\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.trainer_utils import SchedulerType\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=400,              # total number of training epochs\n",
    "    per_device_train_batch_size=batch_size,  # batch size per device during training\n",
    "    per_device_eval_batch_size=512,   # batch size for evaluation\n",
    "#    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
    "    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
    "    warmup_steps=max(10,1000//2//batch_size),                # number of warmup steps for learning rate scheduler\n",
    "    logging_steps=max(1,4000//batch_size),               # log & save weights each logging_steps\n",
    "    save_steps=max(1,4000//batch_size),\n",
    "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",
    "    save_strategy=\"steps\",\n",
    "#    lr_scheduler_type = SchedulerType.COSINE_WITH_RESTARTS\n",
    ")\n",
    "model = BertForWeightedSequenceClassification.from_pretrained(model_name, \n",
    "                                                              num_labels=num_classes, \n",
    "                                                              problem_type='single_label_classification', \n",
    "                                                              class_weights=class_weights, \n",
    "                                                              freeze_bert_weights=freeze_bert_weights, \n",
    "                                                              use_topics=use_topics, \n",
    "                                                              use_features=use_features,\n",
    "                                                              use_embeddings=use_embeddings)\n",
    "if torch.cuda.is_available():\n",
    "  model = model.to(\"cuda\")\n",
    "\n",
    "trainer = Trainer(\n",
    "  model=model,                         # the instantiated Transformers model to be trained\n",
    "  args=training_args,                  # training arguments, defined above\n",
    "  train_dataset=train_dataset,         # training dataset\n",
    "  eval_dataset=valid_dataset,          # evaluation dataset\n",
    "  compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "preds = trainer.predict(valid_dataset)\n",
    "print(preds.metrics['test_confusion_matrix'])\n",
    "for index, (logits, label) in enumerate(zip(preds.predictions,preds.label_ids)):\n",
    "    pred_label = logits.argmax()\n",
    "    if pred_label != label:\n",
    "        text = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(valid_snippets_encodings['input_ids'][index]))\n",
    "        text = re.sub(\"\\[PAD\\]\",\"\",text).strip()\n",
    "        print(f\"Predicted {class_labels[pred_label]} ({logits}) != real {class_labels[label]} for:\\n{text}\")\n",
    "        multi_embeds.append((text, class_labels[pred_label], class_labels[label]))\n",
    "        \n",
    "df = pd.DataFrame.from_dict(multi_embeds)\n",
    "df.to_csv(\"multi_embeds.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOPICS + FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "s5a7QY_wP5iD",
    "outputId": "f54e78da-4afc-44d5-948b-cf64f5bfa422"
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "mlflow.end_run()\n",
    "train_dataset = Dataset(train_snippets_encodings, train_snippets_labels, train_snippets_topics, train_snippets_features)\n",
    "valid_dataset = Dataset(valid_snippets_encodings, valid_snippets_labels, valid_snippets_topics, valid_snippets_features)\n",
    "\n",
    "#train_dataset = Dataset(None, train_snippets_labels, train_snippets_topics)\n",
    "#valid_dataset = Dataset(None, valid_snippets_labels, valid_snippets_topics)\n",
    "\n",
    "\n",
    "\n",
    "num_classes = 3\n",
    "class_weights = (1/all_snippets_class_counts).tolist()\n",
    "#class_weights = ((np.sum(all_snippets_class_counts)-all_snippets_class_counts)/all_snippets_class_counts).tolist()\n",
    "#class_weights = [100.0,1.0,100.0]\n",
    "freeze_bert_weights = True\n",
    "use_topics = True\n",
    "use_features = True\n",
    "use_embeddings = False\n",
    "\n",
    "\n",
    "print(all_snippets_class_counts,class_weights)\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.trainer_utils import SchedulerType\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=400,              # total number of training epochs\n",
    "    per_device_train_batch_size=batch_size,  # batch size per device during training\n",
    "    per_device_eval_batch_size=512,   # batch size for evaluation\n",
    "#    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
    "    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
    "    warmup_steps=max(10,1000//2//batch_size),                # number of warmup steps for learning rate scheduler\n",
    "    logging_steps=max(1,4000//batch_size),               # log & save weights each logging_steps\n",
    "    save_steps=max(1,4000//batch_size),\n",
    "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",
    "    save_strategy=\"steps\",\n",
    "#    lr_scheduler_type = SchedulerType.COSINE_WITH_RESTARTS\n",
    ")\n",
    "model = BertForWeightedSequenceClassification.from_pretrained(model_name, \n",
    "                                                              num_labels=num_classes, \n",
    "                                                              problem_type='single_label_classification', \n",
    "                                                              class_weights=class_weights, \n",
    "                                                              freeze_bert_weights=freeze_bert_weights, \n",
    "                                                              use_topics=use_topics, \n",
    "                                                              use_features=use_features,\n",
    "                                                              use_embeddings=use_embeddings)\n",
    "if torch.cuda.is_available():\n",
    "  model = model.to(\"cuda\")\n",
    "\n",
    "trainer = Trainer(\n",
    "  model=model,                         # the instantiated Transformers model to be trained\n",
    "  args=training_args,                  # training arguments, defined above\n",
    "  train_dataset=train_dataset,         # training dataset\n",
    "  eval_dataset=valid_dataset,          # evaluation dataset\n",
    "  compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "preds = trainer.predict(valid_dataset)\n",
    "print(preds.metrics['test_confusion_matrix'])\n",
    "for index, (logits, label) in enumerate(zip(preds.predictions,preds.label_ids)):\n",
    "    pred_label = logits.argmax()\n",
    "    if pred_label != label:\n",
    "        text = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(valid_snippets_encodings['input_ids'][index]))\n",
    "        text = re.sub(\"\\[PAD\\]\",\"\",text).strip()\n",
    "        print(f\"Predicted {class_labels[pred_label]} ({logits}) != real {class_labels[label]} for:\\n{text}\")\n",
    "        multi_topics_features.append((text, class_labels[pred_label], class_labels[label]))\n",
    "        \n",
    "df = pd.DataFrame.from_dict(multi_topics_features)\n",
    "df.to_csv(\"multi_topics_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOPICS + EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "s5a7QY_wP5iD",
    "outputId": "f54e78da-4afc-44d5-948b-cf64f5bfa422",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "mlflow.end_run()\n",
    "train_dataset = Dataset(train_snippets_encodings, train_snippets_labels, train_snippets_topics, train_snippets_features)\n",
    "valid_dataset = Dataset(valid_snippets_encodings, valid_snippets_labels, valid_snippets_topics, valid_snippets_features)\n",
    "\n",
    "#train_dataset = Dataset(None, train_snippets_labels, train_snippets_topics)\n",
    "#valid_dataset = Dataset(None, valid_snippets_labels, valid_snippets_topics)\n",
    "\n",
    "\n",
    "\n",
    "num_classes = 3\n",
    "class_weights = (1/all_snippets_class_counts).tolist()\n",
    "#class_weights = ((np.sum(all_snippets_class_counts)-all_snippets_class_counts)/all_snippets_class_counts).tolist()\n",
    "#class_weights = [100.0,1.0,100.0]\n",
    "freeze_bert_weights = True\n",
    "use_topics = True\n",
    "use_features = False\n",
    "use_embeddings = True\n",
    "\n",
    "\n",
    "print(all_snippets_class_counts,class_weights)\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.trainer_utils import SchedulerType\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=400,              # total number of training epochs\n",
    "    per_device_train_batch_size=batch_size,  # batch size per device during training\n",
    "    per_device_eval_batch_size=512,   # batch size for evaluation\n",
    "#    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
    "    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
    "    warmup_steps=max(10,1000//2//batch_size),                # number of warmup steps for learning rate scheduler\n",
    "    logging_steps=max(1,4000//batch_size),               # log & save weights each logging_steps\n",
    "    save_steps=max(1,4000//batch_size),\n",
    "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",
    "    save_strategy=\"steps\",\n",
    "#    lr_scheduler_type = SchedulerType.COSINE_WITH_RESTARTS\n",
    ")\n",
    "model = BertForWeightedSequenceClassification.from_pretrained(model_name, \n",
    "                                                              num_labels=num_classes, \n",
    "                                                              problem_type='single_label_classification', \n",
    "                                                              class_weights=class_weights, \n",
    "                                                              freeze_bert_weights=freeze_bert_weights, \n",
    "                                                              use_topics=use_topics, \n",
    "                                                              use_features=use_features,\n",
    "                                                              use_embeddings=use_embeddings)\n",
    "if torch.cuda.is_available():\n",
    "  model = model.to(\"cuda\")\n",
    "\n",
    "trainer = Trainer(\n",
    "  model=model,                         # the instantiated Transformers model to be trained\n",
    "  args=training_args,                  # training arguments, defined above\n",
    "  train_dataset=train_dataset,         # training dataset\n",
    "  eval_dataset=valid_dataset,          # evaluation dataset\n",
    "  compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "preds = trainer.predict(valid_dataset)\n",
    "print(preds.metrics['test_confusion_matrix'])\n",
    "for index, (logits, label) in enumerate(zip(preds.predictions,preds.label_ids)):\n",
    "    pred_label = logits.argmax()\n",
    "    if pred_label != label:\n",
    "        text = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(valid_snippets_encodings['input_ids'][index]))\n",
    "        text = re.sub(\"\\[PAD\\]\",\"\",text).strip()\n",
    "        print(f\"Predicted {class_labels[pred_label]} ({logits}) != real {class_labels[label]} for:\\n{text}\")\n",
    "        multi_topics_embeds.append((text, class_labels[pred_label], class_labels[label]))\n",
    "        \n",
    "df = pd.DataFrame.from_dict(multi_topics_embeds)\n",
    "df.to_csv(\"multi_topics_embeds.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURES + EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "s5a7QY_wP5iD",
    "outputId": "f54e78da-4afc-44d5-948b-cf64f5bfa422",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "mlflow.end_run()\n",
    "train_dataset = Dataset(train_snippets_encodings, train_snippets_labels, train_snippets_topics, train_snippets_features)\n",
    "valid_dataset = Dataset(valid_snippets_encodings, valid_snippets_labels, valid_snippets_topics, valid_snippets_features)\n",
    "\n",
    "#train_dataset = Dataset(None, train_snippets_labels, train_snippets_topics)\n",
    "#valid_dataset = Dataset(None, valid_snippets_labels, valid_snippets_topics)\n",
    "\n",
    "\n",
    "\n",
    "num_classes = 3\n",
    "class_weights = (1/all_snippets_class_counts).tolist()\n",
    "#class_weights = ((np.sum(all_snippets_class_counts)-all_snippets_class_counts)/all_snippets_class_counts).tolist()\n",
    "#class_weights = [100.0,1.0,100.0]\n",
    "freeze_bert_weights = True\n",
    "use_topics = False\n",
    "use_features = True\n",
    "use_embeddings = True\n",
    "\n",
    "\n",
    "print(all_snippets_class_counts,class_weights)\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.trainer_utils import SchedulerType\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=400,              # total number of training epochs\n",
    "    per_device_train_batch_size=batch_size,  # batch size per device during training\n",
    "    per_device_eval_batch_size=512,   # batch size for evaluation\n",
    "#    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
    "    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
    "    warmup_steps=max(10,1000//2//batch_size),                # number of warmup steps for learning rate scheduler\n",
    "    logging_steps=max(1,4000//batch_size),               # log & save weights each logging_steps\n",
    "    save_steps=max(1,4000//batch_size),\n",
    "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",
    "    save_strategy=\"steps\",\n",
    "#    lr_scheduler_type = SchedulerType.COSINE_WITH_RESTARTS\n",
    ")\n",
    "model = BertForWeightedSequenceClassification.from_pretrained(model_name, \n",
    "                                                              num_labels=num_classes, \n",
    "                                                              problem_type='single_label_classification', \n",
    "                                                              class_weights=class_weights, \n",
    "                                                              freeze_bert_weights=freeze_bert_weights, \n",
    "                                                              use_topics=use_topics, \n",
    "                                                              use_features=use_features,\n",
    "                                                              use_embeddings=use_embeddings)\n",
    "if torch.cuda.is_available():\n",
    "  model = model.to(\"cuda\")\n",
    "\n",
    "trainer = Trainer(\n",
    "  model=model,                         # the instantiated Transformers model to be trained\n",
    "  args=training_args,                  # training arguments, defined above\n",
    "  train_dataset=train_dataset,         # training dataset\n",
    "  eval_dataset=valid_dataset,          # evaluation dataset\n",
    "  compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLS + TOPICS + STRUCTURAL FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "s5a7QY_wP5iD",
    "outputId": "f54e78da-4afc-44d5-948b-cf64f5bfa422",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 137 1040  334] [0.0072992700729927005, 0.0009615384615384616, 0.0029940119760479044]\n",
      "arvot\n",
      "768 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at TurkuNLP/bert-base-finnish-uncased-v1 were not used when initializing BertForWeightedSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForWeightedSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForWeightedSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForWeightedSequenceClassification were not initialized from the model checkpoint at TurkuNLP/bert-base-finnish-uncased-v1 and are newly initialized: ['classifier.0.bias', 'classifier.0.weight', 'classifier.3.bias', 'classifier.3.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/rh/rh-python38/root/usr/local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1144\n",
      "  Num Epochs = 400\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14400' max='14400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14400/14400 1:26:53, Epoch 400/400]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.968300</td>\n",
       "      <td>0.834119</td>\n",
       "      <td>0.741144</td>\n",
       "      <td>[[ 12   5   6]\n",
       " [ 26 228  16]\n",
       " [ 25  17  32]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.822300</td>\n",
       "      <td>0.747034</td>\n",
       "      <td>0.776567</td>\n",
       "      <td>[[ 16   5   2]\n",
       " [ 22 236  12]\n",
       " [ 22  19  33]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.749900</td>\n",
       "      <td>0.707459</td>\n",
       "      <td>0.809264</td>\n",
       "      <td>[[ 16   5   2]\n",
       " [ 21 239  10]\n",
       " [ 12  20  42]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.715600</td>\n",
       "      <td>0.671065</td>\n",
       "      <td>0.798365</td>\n",
       "      <td>[[ 16   4   3]\n",
       " [ 23 233  14]\n",
       " [ 16  14  44]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.683900</td>\n",
       "      <td>0.654101</td>\n",
       "      <td>0.833787</td>\n",
       "      <td>[[ 15   5   3]\n",
       " [ 15 241  14]\n",
       " [  5  19  50]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.658200</td>\n",
       "      <td>0.632024</td>\n",
       "      <td>0.822888</td>\n",
       "      <td>[[ 15   5   3]\n",
       " [ 17 237  16]\n",
       " [ 10  14  50]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>0.629700</td>\n",
       "      <td>0.618591</td>\n",
       "      <td>0.825613</td>\n",
       "      <td>[[ 15   5   3]\n",
       " [ 16 236  18]\n",
       " [ 11  11  52]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.611100</td>\n",
       "      <td>0.605437</td>\n",
       "      <td>0.828338</td>\n",
       "      <td>[[ 13   4   6]\n",
       " [ 12 234  24]\n",
       " [  7  10  57]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>0.595700</td>\n",
       "      <td>0.595068</td>\n",
       "      <td>0.831063</td>\n",
       "      <td>[[ 17   3   3]\n",
       " [ 17 233  20]\n",
       " [  9  10  55]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.582100</td>\n",
       "      <td>0.602446</td>\n",
       "      <td>0.825613</td>\n",
       "      <td>[[ 16   4   3]\n",
       " [ 13 240  17]\n",
       " [ 14  13  47]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1375</td>\n",
       "      <td>0.568500</td>\n",
       "      <td>0.586874</td>\n",
       "      <td>0.798365</td>\n",
       "      <td>[[ 17   3   3]\n",
       " [ 21 226  23]\n",
       " [ 16   8  50]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.563300</td>\n",
       "      <td>0.598115</td>\n",
       "      <td>0.828338</td>\n",
       "      <td>[[ 14   4   5]\n",
       " [ 10 240  20]\n",
       " [ 11  13  50]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1625</td>\n",
       "      <td>0.551700</td>\n",
       "      <td>0.581533</td>\n",
       "      <td>0.836512</td>\n",
       "      <td>[[ 15   4   4]\n",
       " [ 10 237  23]\n",
       " [  8  11  55]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.581449</td>\n",
       "      <td>0.798365</td>\n",
       "      <td>[[ 17   3   3]\n",
       " [ 22 229  19]\n",
       " [ 17  10  47]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1875</td>\n",
       "      <td>0.525400</td>\n",
       "      <td>0.579279</td>\n",
       "      <td>0.820163</td>\n",
       "      <td>[[ 14   4   5]\n",
       " [ 11 235  24]\n",
       " [ 11  11  52]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.507500</td>\n",
       "      <td>0.582237</td>\n",
       "      <td>0.828338</td>\n",
       "      <td>[[ 15   5   3]\n",
       " [ 10 238  22]\n",
       " [ 10  13  51]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2125</td>\n",
       "      <td>0.519600</td>\n",
       "      <td>0.575497</td>\n",
       "      <td>0.825613</td>\n",
       "      <td>[[ 15   4   4]\n",
       " [ 12 236  22]\n",
       " [ 12  10  52]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.497200</td>\n",
       "      <td>0.579138</td>\n",
       "      <td>0.803815</td>\n",
       "      <td>[[ 17   3   3]\n",
       " [ 19 229  22]\n",
       " [ 15  10  49]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2375</td>\n",
       "      <td>0.493000</td>\n",
       "      <td>0.577572</td>\n",
       "      <td>0.833787</td>\n",
       "      <td>[[ 16   4   3]\n",
       " [ 11 238  21]\n",
       " [ 11  11  52]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.472400</td>\n",
       "      <td>0.577066</td>\n",
       "      <td>0.833787</td>\n",
       "      <td>[[ 14   4   5]\n",
       " [ 10 239  21]\n",
       " [  9  12  53]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2625</td>\n",
       "      <td>0.480600</td>\n",
       "      <td>0.581639</td>\n",
       "      <td>0.825613</td>\n",
       "      <td>[[ 14   4   5]\n",
       " [  9 238  23]\n",
       " [ 10  13  51]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>0.468800</td>\n",
       "      <td>0.582962</td>\n",
       "      <td>0.817439</td>\n",
       "      <td>[[ 17   3   3]\n",
       " [ 15 235  20]\n",
       " [ 14  12  48]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2875</td>\n",
       "      <td>0.468200</td>\n",
       "      <td>0.571658</td>\n",
       "      <td>0.822888</td>\n",
       "      <td>[[ 17   3   3]\n",
       " [ 15 233  22]\n",
       " [ 12  10  52]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.457000</td>\n",
       "      <td>0.592134</td>\n",
       "      <td>0.820163</td>\n",
       "      <td>[[ 14   5   4]\n",
       " [ 10 240  20]\n",
       " [ 12  15  47]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3125</td>\n",
       "      <td>0.452200</td>\n",
       "      <td>0.578914</td>\n",
       "      <td>0.809264</td>\n",
       "      <td>[[ 17   3   3]\n",
       " [ 16 232  22]\n",
       " [ 14  12  48]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.448600</td>\n",
       "      <td>0.567854</td>\n",
       "      <td>0.814714</td>\n",
       "      <td>[[ 17   3   3]\n",
       " [ 16 231  23]\n",
       " [ 13  10  51]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3375</td>\n",
       "      <td>0.437200</td>\n",
       "      <td>0.567743</td>\n",
       "      <td>0.809264</td>\n",
       "      <td>[[ 15   3   5]\n",
       " [ 16 231  23]\n",
       " [ 12  11  51]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.431100</td>\n",
       "      <td>0.589959</td>\n",
       "      <td>0.822888</td>\n",
       "      <td>[[ 15   5   3]\n",
       " [ 10 242  18]\n",
       " [ 14  15  45]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3625</td>\n",
       "      <td>0.409200</td>\n",
       "      <td>0.591583</td>\n",
       "      <td>0.817439</td>\n",
       "      <td>[[ 15   5   3]\n",
       " [ 13 238  19]\n",
       " [ 13  14  47]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>0.422100</td>\n",
       "      <td>0.568843</td>\n",
       "      <td>0.803815</td>\n",
       "      <td>[[ 18   2   3]\n",
       " [ 17 229  24]\n",
       " [ 14  12  48]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3875</td>\n",
       "      <td>0.419100</td>\n",
       "      <td>0.565741</td>\n",
       "      <td>0.814714</td>\n",
       "      <td>[[ 13   4   6]\n",
       " [ 11 231  28]\n",
       " [ 11   8  55]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.414400</td>\n",
       "      <td>0.619981</td>\n",
       "      <td>0.817439</td>\n",
       "      <td>[[ 10   8   5]\n",
       " [  7 242  21]\n",
       " [  6  20  48]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4125</td>\n",
       "      <td>0.416900</td>\n",
       "      <td>0.586129</td>\n",
       "      <td>0.822888</td>\n",
       "      <td>[[ 14   4   5]\n",
       " [ 10 238  22]\n",
       " [ 10  14  50]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>0.567451</td>\n",
       "      <td>0.814714</td>\n",
       "      <td>[[ 14   4   5]\n",
       " [ 13 234  23]\n",
       " [ 11  12  51]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4375</td>\n",
       "      <td>0.396000</td>\n",
       "      <td>0.590539</td>\n",
       "      <td>0.811989</td>\n",
       "      <td>[[ 14   4   5]\n",
       " [ 13 235  22]\n",
       " [ 11  14  49]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.382600</td>\n",
       "      <td>0.572471</td>\n",
       "      <td>0.814714</td>\n",
       "      <td>[[ 14   4   5]\n",
       " [ 13 234  23]\n",
       " [ 11  12  51]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4625</td>\n",
       "      <td>0.392500</td>\n",
       "      <td>0.575028</td>\n",
       "      <td>0.814714</td>\n",
       "      <td>[[ 14   4   5]\n",
       " [ 13 234  23]\n",
       " [ 10  13  51]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4750</td>\n",
       "      <td>0.399900</td>\n",
       "      <td>0.568077</td>\n",
       "      <td>0.811989</td>\n",
       "      <td>[[ 16   2   5]\n",
       " [ 13 233  24]\n",
       " [ 12  13  49]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4875</td>\n",
       "      <td>0.373600</td>\n",
       "      <td>0.564515</td>\n",
       "      <td>0.820163</td>\n",
       "      <td>[[ 15   3   5]\n",
       " [ 13 233  24]\n",
       " [ 10  11  53]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.374900</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.809264</td>\n",
       "      <td>[[ 15   3   5]\n",
       " [ 13 233  24]\n",
       " [ 10  15  49]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5125</td>\n",
       "      <td>0.377100</td>\n",
       "      <td>0.573392</td>\n",
       "      <td>0.814714</td>\n",
       "      <td>[[ 17   3   3]\n",
       " [ 13 236  21]\n",
       " [ 11  17  46]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5250</td>\n",
       "      <td>0.368900</td>\n",
       "      <td>0.575188</td>\n",
       "      <td>0.811989</td>\n",
       "      <td>[[ 15   3   5]\n",
       " [ 14 233  23]\n",
       " [ 10  14  50]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5375</td>\n",
       "      <td>0.363900</td>\n",
       "      <td>0.569478</td>\n",
       "      <td>0.814714</td>\n",
       "      <td>[[ 15   3   5]\n",
       " [ 14 231  25]\n",
       " [  9  12  53]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.347400</td>\n",
       "      <td>0.587314</td>\n",
       "      <td>0.811989</td>\n",
       "      <td>[[ 14   3   6]\n",
       " [ 13 234  23]\n",
       " [ 11  13  50]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5625</td>\n",
       "      <td>0.362400</td>\n",
       "      <td>0.588378</td>\n",
       "      <td>0.811989</td>\n",
       "      <td>[[ 13   5   5]\n",
       " [ 13 234  23]\n",
       " [  9  14  51]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5750</td>\n",
       "      <td>0.356600</td>\n",
       "      <td>0.575038</td>\n",
       "      <td>0.809264</td>\n",
       "      <td>[[ 15   3   5]\n",
       " [ 15 231  24]\n",
       " [ 10  13  51]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5875</td>\n",
       "      <td>0.336600</td>\n",
       "      <td>0.589800</td>\n",
       "      <td>0.817439</td>\n",
       "      <td>[[ 14   4   5]\n",
       " [ 12 237  21]\n",
       " [ 10  15  49]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.351700</td>\n",
       "      <td>0.596018</td>\n",
       "      <td>0.814714</td>\n",
       "      <td>[[ 12   5   6]\n",
       " [ 12 236  22]\n",
       " [  9  14  51]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6125</td>\n",
       "      <td>0.348900</td>\n",
       "      <td>0.596956</td>\n",
       "      <td>0.811989</td>\n",
       "      <td>[[ 12   5   6]\n",
       " [ 12 235  23]\n",
       " [  9  14  51]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6250</td>\n",
       "      <td>0.352600</td>\n",
       "      <td>0.597812</td>\n",
       "      <td>0.820163</td>\n",
       "      <td>[[ 13   4   6]\n",
       " [ 12 237  21]\n",
       " [  9  14  51]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6375</td>\n",
       "      <td>0.335100</td>\n",
       "      <td>0.589978</td>\n",
       "      <td>0.814714</td>\n",
       "      <td>[[ 14   4   5]\n",
       " [ 13 235  22]\n",
       " [ 10  14  50]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.334300</td>\n",
       "      <td>0.619194</td>\n",
       "      <td>0.825613</td>\n",
       "      <td>[[ 12   6   5]\n",
       " [  7 243  20]\n",
       " [  7  19  48]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6625</td>\n",
       "      <td>0.349700</td>\n",
       "      <td>0.585693</td>\n",
       "      <td>0.820163</td>\n",
       "      <td>[[ 15   3   5]\n",
       " [ 12 234  24]\n",
       " [  9  13  52]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6750</td>\n",
       "      <td>0.334700</td>\n",
       "      <td>0.586389</td>\n",
       "      <td>0.814714</td>\n",
       "      <td>[[ 15   3   5]\n",
       " [ 13 234  23]\n",
       " [ 10  14  50]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6875</td>\n",
       "      <td>0.333800</td>\n",
       "      <td>0.577689</td>\n",
       "      <td>0.814714</td>\n",
       "      <td>[[ 15   3   5]\n",
       " [ 13 234  23]\n",
       " [ 10  14  50]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.334000</td>\n",
       "      <td>0.585371</td>\n",
       "      <td>0.817439</td>\n",
       "      <td>[[ 14   3   6]\n",
       " [ 12 234  24]\n",
       " [  9  13  52]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7125</td>\n",
       "      <td>0.319400</td>\n",
       "      <td>0.610610</td>\n",
       "      <td>0.833787</td>\n",
       "      <td>[[ 14   4   5]\n",
       " [  8 244  18]\n",
       " [  8  18  48]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7250</td>\n",
       "      <td>0.318700</td>\n",
       "      <td>0.600157</td>\n",
       "      <td>0.811989</td>\n",
       "      <td>[[ 14   4   5]\n",
       " [ 12 236  22]\n",
       " [ 10  16  48]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7375</td>\n",
       "      <td>0.325700</td>\n",
       "      <td>0.605111</td>\n",
       "      <td>0.811989</td>\n",
       "      <td>[[ 12   5   6]\n",
       " [ 11 236  23]\n",
       " [  8  16  50]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.309200</td>\n",
       "      <td>0.589072</td>\n",
       "      <td>0.814714</td>\n",
       "      <td>[[ 15   3   5]\n",
       " [ 12 234  24]\n",
       " [ 10  14  50]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7625</td>\n",
       "      <td>0.307100</td>\n",
       "      <td>0.586407</td>\n",
       "      <td>0.814714</td>\n",
       "      <td>[[ 14   3   6]\n",
       " [ 12 235  23]\n",
       " [ 10  14  50]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7750</td>\n",
       "      <td>0.304600</td>\n",
       "      <td>0.592219</td>\n",
       "      <td>0.817439</td>\n",
       "      <td>[[ 15   3   5]\n",
       " [ 12 238  20]\n",
       " [ 11  16  47]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7875</td>\n",
       "      <td>0.298200</td>\n",
       "      <td>0.603275</td>\n",
       "      <td>0.817439</td>\n",
       "      <td>[[ 13   4   6]\n",
       " [ 11 239  20]\n",
       " [  8  18  48]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.300800</td>\n",
       "      <td>0.574564</td>\n",
       "      <td>0.817439</td>\n",
       "      <td>[[ 14   3   6]\n",
       " [ 13 233  24]\n",
       " [  9  12  53]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8125</td>\n",
       "      <td>0.313600</td>\n",
       "      <td>0.588268</td>\n",
       "      <td>0.811989</td>\n",
       "      <td>[[ 13   4   6]\n",
       " [ 12 236  22]\n",
       " [ 10  15  49]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8250</td>\n",
       "      <td>0.296000</td>\n",
       "      <td>0.583801</td>\n",
       "      <td>0.817439</td>\n",
       "      <td>[[ 14   3   6]\n",
       " [ 12 234  24]\n",
       " [  9  13  52]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8375</td>\n",
       "      <td>0.300300</td>\n",
       "      <td>0.600737</td>\n",
       "      <td>0.822888</td>\n",
       "      <td>[[ 15   3   5]\n",
       " [ 12 239  19]\n",
       " [ 10  16  48]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.296400</td>\n",
       "      <td>0.597055</td>\n",
       "      <td>0.820163</td>\n",
       "      <td>[[ 15   3   5]\n",
       " [ 12 238  20]\n",
       " [ 10  16  48]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8625</td>\n",
       "      <td>0.301600</td>\n",
       "      <td>0.602001</td>\n",
       "      <td>0.820163</td>\n",
       "      <td>[[ 15   3   5]\n",
       " [ 12 241  17]\n",
       " [ 12  17  45]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8750</td>\n",
       "      <td>0.285900</td>\n",
       "      <td>0.580088</td>\n",
       "      <td>0.814714</td>\n",
       "      <td>[[ 14   3   6]\n",
       " [ 12 234  24]\n",
       " [ 10  13  51]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8875</td>\n",
       "      <td>0.305800</td>\n",
       "      <td>0.589742</td>\n",
       "      <td>0.820163</td>\n",
       "      <td>[[ 14   3   6]\n",
       " [ 12 237  21]\n",
       " [ 10  14  50]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.296100</td>\n",
       "      <td>0.601137</td>\n",
       "      <td>0.828338</td>\n",
       "      <td>[[ 14   3   6]\n",
       " [ 11 241  18]\n",
       " [  9  16  49]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9125</td>\n",
       "      <td>0.295600</td>\n",
       "      <td>0.594677</td>\n",
       "      <td>0.817439</td>\n",
       "      <td>[[ 14   3   6]\n",
       " [ 12 237  21]\n",
       " [ 10  15  49]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9250</td>\n",
       "      <td>0.284700</td>\n",
       "      <td>0.600169</td>\n",
       "      <td>0.817439</td>\n",
       "      <td>[[ 15   3   5]\n",
       " [ 12 236  22]\n",
       " [ 10  15  49]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9375</td>\n",
       "      <td>0.294700</td>\n",
       "      <td>0.591788</td>\n",
       "      <td>0.817439</td>\n",
       "      <td>[[ 13   4   6]\n",
       " [ 12 235  23]\n",
       " [  8  14  52]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.296100</td>\n",
       "      <td>0.598993</td>\n",
       "      <td>0.820163</td>\n",
       "      <td>[[ 13   4   6]\n",
       " [ 12 237  21]\n",
       " [  9  14  51]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9625</td>\n",
       "      <td>0.291200</td>\n",
       "      <td>0.619549</td>\n",
       "      <td>0.825613</td>\n",
       "      <td>[[ 13   4   6]\n",
       " [ 11 242  17]\n",
       " [  9  17  48]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9750</td>\n",
       "      <td>0.287500</td>\n",
       "      <td>0.598304</td>\n",
       "      <td>0.817439</td>\n",
       "      <td>[[ 13   4   6]\n",
       " [ 12 237  21]\n",
       " [ 10  14  50]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9875</td>\n",
       "      <td>0.274100</td>\n",
       "      <td>0.602797</td>\n",
       "      <td>0.828338</td>\n",
       "      <td>[[ 13   4   6]\n",
       " [ 11 241  18]\n",
       " [  9  15  50]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.289500</td>\n",
       "      <td>0.591893</td>\n",
       "      <td>0.820163</td>\n",
       "      <td>[[ 14   3   6]\n",
       " [ 12 235  23]\n",
       " [  9  13  52]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10125</td>\n",
       "      <td>0.270700</td>\n",
       "      <td>0.611614</td>\n",
       "      <td>0.831063</td>\n",
       "      <td>[[ 13   4   6]\n",
       " [ 10 243  17]\n",
       " [  9  16  49]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10250</td>\n",
       "      <td>0.292600</td>\n",
       "      <td>0.597872</td>\n",
       "      <td>0.831063</td>\n",
       "      <td>[[ 15   3   5]\n",
       " [ 12 241  17]\n",
       " [ 10  15  49]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10375</td>\n",
       "      <td>0.291300</td>\n",
       "      <td>0.602062</td>\n",
       "      <td>0.831063</td>\n",
       "      <td>[[ 13   4   6]\n",
       " [ 12 240  18]\n",
       " [  9  13  52]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.271400</td>\n",
       "      <td>0.615782</td>\n",
       "      <td>0.839237</td>\n",
       "      <td>[[ 13   4   6]\n",
       " [  9 243  18]\n",
       " [  7  15  52]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10625</td>\n",
       "      <td>0.285200</td>\n",
       "      <td>0.607440</td>\n",
       "      <td>0.831063</td>\n",
       "      <td>[[ 13   4   6]\n",
       " [ 11 241  18]\n",
       " [  9  14  51]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10750</td>\n",
       "      <td>0.281200</td>\n",
       "      <td>0.594556</td>\n",
       "      <td>0.822888</td>\n",
       "      <td>[[ 14   3   6]\n",
       " [ 12 239  19]\n",
       " [ 10  15  49]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10875</td>\n",
       "      <td>0.278100</td>\n",
       "      <td>0.604496</td>\n",
       "      <td>0.828338</td>\n",
       "      <td>[[ 14   3   6]\n",
       " [ 12 241  17]\n",
       " [ 10  15  49]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.276200</td>\n",
       "      <td>0.603636</td>\n",
       "      <td>0.828338</td>\n",
       "      <td>[[ 15   3   5]\n",
       " [ 12 241  17]\n",
       " [ 11  15  48]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11125</td>\n",
       "      <td>0.261700</td>\n",
       "      <td>0.616644</td>\n",
       "      <td>0.836512</td>\n",
       "      <td>[[ 13   4   6]\n",
       " [  9 244  17]\n",
       " [  8  16  50]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11250</td>\n",
       "      <td>0.283100</td>\n",
       "      <td>0.598244</td>\n",
       "      <td>0.828338</td>\n",
       "      <td>[[ 15   3   5]\n",
       " [ 12 241  17]\n",
       " [ 11  15  48]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11375</td>\n",
       "      <td>0.252900</td>\n",
       "      <td>0.600938</td>\n",
       "      <td>0.828338</td>\n",
       "      <td>[[ 14   3   6]\n",
       " [ 12 241  17]\n",
       " [ 10  15  49]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.272400</td>\n",
       "      <td>0.603036</td>\n",
       "      <td>0.831063</td>\n",
       "      <td>[[ 15   3   5]\n",
       " [ 12 241  17]\n",
       " [ 10  15  49]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11625</td>\n",
       "      <td>0.274700</td>\n",
       "      <td>0.597232</td>\n",
       "      <td>0.822888</td>\n",
       "      <td>[[ 14   3   6]\n",
       " [ 12 240  18]\n",
       " [ 11  15  48]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11750</td>\n",
       "      <td>0.262100</td>\n",
       "      <td>0.613892</td>\n",
       "      <td>0.831063</td>\n",
       "      <td>[[ 13   4   6]\n",
       " [  9 242  19]\n",
       " [  9  15  50]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11875</td>\n",
       "      <td>0.267000</td>\n",
       "      <td>0.603329</td>\n",
       "      <td>0.828338</td>\n",
       "      <td>[[ 14   3   6]\n",
       " [ 12 241  17]\n",
       " [ 10  15  49]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.276700</td>\n",
       "      <td>0.604855</td>\n",
       "      <td>0.825613</td>\n",
       "      <td>[[ 13   4   6]\n",
       " [ 12 241  17]\n",
       " [ 10  15  49]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12125</td>\n",
       "      <td>0.259400</td>\n",
       "      <td>0.603464</td>\n",
       "      <td>0.831063</td>\n",
       "      <td>[[ 14   3   6]\n",
       " [ 12 241  17]\n",
       " [  9  15  50]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12250</td>\n",
       "      <td>0.266200</td>\n",
       "      <td>0.608514</td>\n",
       "      <td>0.833787</td>\n",
       "      <td>[[ 13   4   6]\n",
       " [ 10 243  17]\n",
       " [  9  15  50]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12375</td>\n",
       "      <td>0.263600</td>\n",
       "      <td>0.606046</td>\n",
       "      <td>0.828338</td>\n",
       "      <td>[[ 14   3   6]\n",
       " [ 12 241  17]\n",
       " [ 10  15  49]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.252600</td>\n",
       "      <td>0.614067</td>\n",
       "      <td>0.833787</td>\n",
       "      <td>[[ 13   4   6]\n",
       " [ 10 243  17]\n",
       " [  9  15  50]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12625</td>\n",
       "      <td>0.259700</td>\n",
       "      <td>0.608752</td>\n",
       "      <td>0.831063</td>\n",
       "      <td>[[ 13   4   6]\n",
       " [ 11 242  17]\n",
       " [  9  15  50]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12750</td>\n",
       "      <td>0.270500</td>\n",
       "      <td>0.610826</td>\n",
       "      <td>0.828338</td>\n",
       "      <td>[[ 13   4   6]\n",
       " [ 12 241  17]\n",
       " [  9  15  50]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12875</td>\n",
       "      <td>0.272900</td>\n",
       "      <td>0.600703</td>\n",
       "      <td>0.828338</td>\n",
       "      <td>[[ 13   4   6]\n",
       " [ 12 241  17]\n",
       " [  9  15  50]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.253600</td>\n",
       "      <td>0.613197</td>\n",
       "      <td>0.833787</td>\n",
       "      <td>[[ 13   4   6]\n",
       " [ 10 243  17]\n",
       " [  9  15  50]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13125</td>\n",
       "      <td>0.252200</td>\n",
       "      <td>0.615992</td>\n",
       "      <td>0.833787</td>\n",
       "      <td>[[ 13   4   6]\n",
       " [ 10 243  17]\n",
       " [  9  15  50]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13250</td>\n",
       "      <td>0.270100</td>\n",
       "      <td>0.621612</td>\n",
       "      <td>0.833787</td>\n",
       "      <td>[[ 13   4   6]\n",
       " [ 10 243  17]\n",
       " [  9  15  50]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13375</td>\n",
       "      <td>0.258000</td>\n",
       "      <td>0.611881</td>\n",
       "      <td>0.833787</td>\n",
       "      <td>[[ 13   4   6]\n",
       " [ 10 243  17]\n",
       " [  9  15  50]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.271300</td>\n",
       "      <td>0.609566</td>\n",
       "      <td>0.828338</td>\n",
       "      <td>[[ 13   4   6]\n",
       " [ 12 241  17]\n",
       " [  9  15  50]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13625</td>\n",
       "      <td>0.252500</td>\n",
       "      <td>0.608923</td>\n",
       "      <td>0.828338</td>\n",
       "      <td>[[ 13   4   6]\n",
       " [ 12 241  17]\n",
       " [  9  15  50]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13750</td>\n",
       "      <td>0.251700</td>\n",
       "      <td>0.609495</td>\n",
       "      <td>0.828338</td>\n",
       "      <td>[[ 13   4   6]\n",
       " [ 12 241  17]\n",
       " [  9  15  50]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13875</td>\n",
       "      <td>0.271200</td>\n",
       "      <td>0.607547</td>\n",
       "      <td>0.828338</td>\n",
       "      <td>[[ 13   4   6]\n",
       " [ 12 241  17]\n",
       " [  9  15  50]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.246500</td>\n",
       "      <td>0.608306</td>\n",
       "      <td>0.828338</td>\n",
       "      <td>[[ 13   4   6]\n",
       " [ 12 241  17]\n",
       " [  9  15  50]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14125</td>\n",
       "      <td>0.264400</td>\n",
       "      <td>0.611406</td>\n",
       "      <td>0.828338</td>\n",
       "      <td>[[ 13   4   6]\n",
       " [ 12 241  17]\n",
       " [  9  15  50]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14250</td>\n",
       "      <td>0.252800</td>\n",
       "      <td>0.611268</td>\n",
       "      <td>0.828338</td>\n",
       "      <td>[[ 13   4   6]\n",
       " [ 12 241  17]\n",
       " [  9  15  50]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14375</td>\n",
       "      <td>0.260500</td>\n",
       "      <td>0.610798</td>\n",
       "      <td>0.831063</td>\n",
       "      <td>[[ 13   4   6]\n",
       " [ 11 242  17]\n",
       " [  9  15  50]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 12   5   6]\n",
      " [ 26 228  16]\n",
      " [ 25  17  32]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 12   5   6]\n",
      " [ 26 228  16]\n",
      " [ 25  17  32]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-125\n",
      "Configuration saved in ./results/checkpoint-125/config.json\n",
      "Model weights saved in ./results/checkpoint-125/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 16   5   2]\n",
      " [ 22 236  12]\n",
      " [ 22  19  33]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 16   5   2]\n",
      " [ 22 236  12]\n",
      " [ 22  19  33]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-250\n",
      "Configuration saved in ./results/checkpoint-250/config.json\n",
      "Model weights saved in ./results/checkpoint-250/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 16   5   2]\n",
      " [ 21 239  10]\n",
      " [ 12  20  42]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 16   5   2]\n",
      " [ 21 239  10]\n",
      " [ 12  20  42]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-375\n",
      "Configuration saved in ./results/checkpoint-375/config.json\n",
      "Model weights saved in ./results/checkpoint-375/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 16   4   3]\n",
      " [ 23 233  14]\n",
      " [ 16  14  44]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 16   4   3]\n",
      " [ 23 233  14]\n",
      " [ 16  14  44]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-500\n",
      "Configuration saved in ./results/checkpoint-500/config.json\n",
      "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 15   5   3]\n",
      " [ 15 241  14]\n",
      " [  5  19  50]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 15   5   3]\n",
      " [ 15 241  14]\n",
      " [  5  19  50]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-625\n",
      "Configuration saved in ./results/checkpoint-625/config.json\n",
      "Model weights saved in ./results/checkpoint-625/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 15   5   3]\n",
      " [ 17 237  16]\n",
      " [ 10  14  50]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 15   5   3]\n",
      " [ 17 237  16]\n",
      " [ 10  14  50]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-750\n",
      "Configuration saved in ./results/checkpoint-750/config.json\n",
      "Model weights saved in ./results/checkpoint-750/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 15   5   3]\n",
      " [ 16 236  18]\n",
      " [ 11  11  52]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 15   5   3]\n",
      " [ 16 236  18]\n",
      " [ 11  11  52]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-875\n",
      "Configuration saved in ./results/checkpoint-875/config.json\n",
      "Model weights saved in ./results/checkpoint-875/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 12 234  24]\n",
      " [  7  10  57]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 12 234  24]\n",
      " [  7  10  57]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-1000\n",
      "Configuration saved in ./results/checkpoint-1000/config.json\n",
      "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 17   3   3]\n",
      " [ 17 233  20]\n",
      " [  9  10  55]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 17   3   3]\n",
      " [ 17 233  20]\n",
      " [  9  10  55]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-1125\n",
      "Configuration saved in ./results/checkpoint-1125/config.json\n",
      "Model weights saved in ./results/checkpoint-1125/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 16   4   3]\n",
      " [ 13 240  17]\n",
      " [ 14  13  47]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 16   4   3]\n",
      " [ 13 240  17]\n",
      " [ 14  13  47]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-1250\n",
      "Configuration saved in ./results/checkpoint-1250/config.json\n",
      "Model weights saved in ./results/checkpoint-1250/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 17   3   3]\n",
      " [ 21 226  23]\n",
      " [ 16   8  50]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 17   3   3]\n",
      " [ 21 226  23]\n",
      " [ 16   8  50]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-1375\n",
      "Configuration saved in ./results/checkpoint-1375/config.json\n",
      "Model weights saved in ./results/checkpoint-1375/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 14   4   5]\n",
      " [ 10 240  20]\n",
      " [ 11  13  50]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 14   4   5]\n",
      " [ 10 240  20]\n",
      " [ 11  13  50]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-1500\n",
      "Configuration saved in ./results/checkpoint-1500/config.json\n",
      "Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 15   4   4]\n",
      " [ 10 237  23]\n",
      " [  8  11  55]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 15   4   4]\n",
      " [ 10 237  23]\n",
      " [  8  11  55]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-1625\n",
      "Configuration saved in ./results/checkpoint-1625/config.json\n",
      "Model weights saved in ./results/checkpoint-1625/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 17   3   3]\n",
      " [ 22 229  19]\n",
      " [ 17  10  47]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 17   3   3]\n",
      " [ 22 229  19]\n",
      " [ 17  10  47]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-1750\n",
      "Configuration saved in ./results/checkpoint-1750/config.json\n",
      "Model weights saved in ./results/checkpoint-1750/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 14   4   5]\n",
      " [ 11 235  24]\n",
      " [ 11  11  52]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 14   4   5]\n",
      " [ 11 235  24]\n",
      " [ 11  11  52]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-1875\n",
      "Configuration saved in ./results/checkpoint-1875/config.json\n",
      "Model weights saved in ./results/checkpoint-1875/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 15   5   3]\n",
      " [ 10 238  22]\n",
      " [ 10  13  51]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 15   5   3]\n",
      " [ 10 238  22]\n",
      " [ 10  13  51]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-2000\n",
      "Configuration saved in ./results/checkpoint-2000/config.json\n",
      "Model weights saved in ./results/checkpoint-2000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 15   4   4]\n",
      " [ 12 236  22]\n",
      " [ 12  10  52]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 15   4   4]\n",
      " [ 12 236  22]\n",
      " [ 12  10  52]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-2125\n",
      "Configuration saved in ./results/checkpoint-2125/config.json\n",
      "Model weights saved in ./results/checkpoint-2125/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 17   3   3]\n",
      " [ 19 229  22]\n",
      " [ 15  10  49]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 17   3   3]\n",
      " [ 19 229  22]\n",
      " [ 15  10  49]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-2250\n",
      "Configuration saved in ./results/checkpoint-2250/config.json\n",
      "Model weights saved in ./results/checkpoint-2250/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 16   4   3]\n",
      " [ 11 238  21]\n",
      " [ 11  11  52]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 16   4   3]\n",
      " [ 11 238  21]\n",
      " [ 11  11  52]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-2375\n",
      "Configuration saved in ./results/checkpoint-2375/config.json\n",
      "Model weights saved in ./results/checkpoint-2375/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 14   4   5]\n",
      " [ 10 239  21]\n",
      " [  9  12  53]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 14   4   5]\n",
      " [ 10 239  21]\n",
      " [  9  12  53]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-2500\n",
      "Configuration saved in ./results/checkpoint-2500/config.json\n",
      "Model weights saved in ./results/checkpoint-2500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 14   4   5]\n",
      " [  9 238  23]\n",
      " [ 10  13  51]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 14   4   5]\n",
      " [  9 238  23]\n",
      " [ 10  13  51]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-2625\n",
      "Configuration saved in ./results/checkpoint-2625/config.json\n",
      "Model weights saved in ./results/checkpoint-2625/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 17   3   3]\n",
      " [ 15 235  20]\n",
      " [ 14  12  48]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 17   3   3]\n",
      " [ 15 235  20]\n",
      " [ 14  12  48]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-2750\n",
      "Configuration saved in ./results/checkpoint-2750/config.json\n",
      "Model weights saved in ./results/checkpoint-2750/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 17   3   3]\n",
      " [ 15 233  22]\n",
      " [ 12  10  52]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"[[ 17   3   3]\n",
      " [ 15 233  22]\n",
      " [ 12  10  52]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-2875\n",
      "Configuration saved in ./results/checkpoint-2875/config.json\n",
      "Model weights saved in ./results/checkpoint-2875/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 14   5   4]\n",
      " [ 10 240  20]\n",
      " [ 12  15  47]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 14   5   4]\n",
      " [ 10 240  20]\n",
      " [ 12  15  47]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-3000\n",
      "Configuration saved in ./results/checkpoint-3000/config.json\n",
      "Model weights saved in ./results/checkpoint-3000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 17   3   3]\n",
      " [ 16 232  22]\n",
      " [ 14  12  48]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 17   3   3]\n",
      " [ 16 232  22]\n",
      " [ 14  12  48]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-3125\n",
      "Configuration saved in ./results/checkpoint-3125/config.json\n",
      "Model weights saved in ./results/checkpoint-3125/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 17   3   3]\n",
      " [ 16 231  23]\n",
      " [ 13  10  51]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 17   3   3]\n",
      " [ 16 231  23]\n",
      " [ 13  10  51]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-3250\n",
      "Configuration saved in ./results/checkpoint-3250/config.json\n",
      "Model weights saved in ./results/checkpoint-3250/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 16 231  23]\n",
      " [ 12  11  51]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 16 231  23]\n",
      " [ 12  11  51]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-3375\n",
      "Configuration saved in ./results/checkpoint-3375/config.json\n",
      "Model weights saved in ./results/checkpoint-3375/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 15   5   3]\n",
      " [ 10 242  18]\n",
      " [ 14  15  45]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 15   5   3]\n",
      " [ 10 242  18]\n",
      " [ 14  15  45]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-3500\n",
      "Configuration saved in ./results/checkpoint-3500/config.json\n",
      "Model weights saved in ./results/checkpoint-3500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 15   5   3]\n",
      " [ 13 238  19]\n",
      " [ 13  14  47]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 15   5   3]\n",
      " [ 13 238  19]\n",
      " [ 13  14  47]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-3625\n",
      "Configuration saved in ./results/checkpoint-3625/config.json\n",
      "Model weights saved in ./results/checkpoint-3625/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 18   2   3]\n",
      " [ 17 229  24]\n",
      " [ 14  12  48]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 18   2   3]\n",
      " [ 17 229  24]\n",
      " [ 14  12  48]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-3750\n",
      "Configuration saved in ./results/checkpoint-3750/config.json\n",
      "Model weights saved in ./results/checkpoint-3750/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 11 231  28]\n",
      " [ 11   8  55]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 11 231  28]\n",
      " [ 11   8  55]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-3875\n",
      "Configuration saved in ./results/checkpoint-3875/config.json\n",
      "Model weights saved in ./results/checkpoint-3875/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 10   8   5]\n",
      " [  7 242  21]\n",
      " [  6  20  48]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 10   8   5]\n",
      " [  7 242  21]\n",
      " [  6  20  48]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-4000\n",
      "Configuration saved in ./results/checkpoint-4000/config.json\n",
      "Model weights saved in ./results/checkpoint-4000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 14   4   5]\n",
      " [ 10 238  22]\n",
      " [ 10  14  50]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 14   4   5]\n",
      " [ 10 238  22]\n",
      " [ 10  14  50]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-4125\n",
      "Configuration saved in ./results/checkpoint-4125/config.json\n",
      "Model weights saved in ./results/checkpoint-4125/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 14   4   5]\n",
      " [ 13 234  23]\n",
      " [ 11  12  51]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 14   4   5]\n",
      " [ 13 234  23]\n",
      " [ 11  12  51]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results/checkpoint-4250\n",
      "Configuration saved in ./results/checkpoint-4250/config.json\n",
      "Model weights saved in ./results/checkpoint-4250/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 14   4   5]\n",
      " [ 13 235  22]\n",
      " [ 11  14  49]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 14   4   5]\n",
      " [ 13 235  22]\n",
      " [ 11  14  49]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-4375\n",
      "Configuration saved in ./results/checkpoint-4375/config.json\n",
      "Model weights saved in ./results/checkpoint-4375/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 14   4   5]\n",
      " [ 13 234  23]\n",
      " [ 11  12  51]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 14   4   5]\n",
      " [ 13 234  23]\n",
      " [ 11  12  51]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-4500\n",
      "Configuration saved in ./results/checkpoint-4500/config.json\n",
      "Model weights saved in ./results/checkpoint-4500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 14   4   5]\n",
      " [ 13 234  23]\n",
      " [ 10  13  51]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 14   4   5]\n",
      " [ 13 234  23]\n",
      " [ 10  13  51]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-4625\n",
      "Configuration saved in ./results/checkpoint-4625/config.json\n",
      "Model weights saved in ./results/checkpoint-4625/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 16   2   5]\n",
      " [ 13 233  24]\n",
      " [ 12  13  49]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 16   2   5]\n",
      " [ 13 233  24]\n",
      " [ 12  13  49]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-4750\n",
      "Configuration saved in ./results/checkpoint-4750/config.json\n",
      "Model weights saved in ./results/checkpoint-4750/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 13 233  24]\n",
      " [ 10  11  53]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 13 233  24]\n",
      " [ 10  11  53]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-4875\n",
      "Configuration saved in ./results/checkpoint-4875/config.json\n",
      "Model weights saved in ./results/checkpoint-4875/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 13 233  24]\n",
      " [ 10  15  49]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 13 233  24]\n",
      " [ 10  15  49]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-5000\n",
      "Configuration saved in ./results/checkpoint-5000/config.json\n",
      "Model weights saved in ./results/checkpoint-5000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 17   3   3]\n",
      " [ 13 236  21]\n",
      " [ 11  17  46]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 17   3   3]\n",
      " [ 13 236  21]\n",
      " [ 11  17  46]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-5125\n",
      "Configuration saved in ./results/checkpoint-5125/config.json\n",
      "Model weights saved in ./results/checkpoint-5125/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 14 233  23]\n",
      " [ 10  14  50]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 14 233  23]\n",
      " [ 10  14  50]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-5250\n",
      "Configuration saved in ./results/checkpoint-5250/config.json\n",
      "Model weights saved in ./results/checkpoint-5250/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 14 231  25]\n",
      " [  9  12  53]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 14 231  25]\n",
      " [  9  12  53]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-5375\n",
      "Configuration saved in ./results/checkpoint-5375/config.json\n",
      "Model weights saved in ./results/checkpoint-5375/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 14   3   6]\n",
      " [ 13 234  23]\n",
      " [ 11  13  50]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 14   3   6]\n",
      " [ 13 234  23]\n",
      " [ 11  13  50]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-5500\n",
      "Configuration saved in ./results/checkpoint-5500/config.json\n",
      "Model weights saved in ./results/checkpoint-5500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 13   5   5]\n",
      " [ 13 234  23]\n",
      " [  9  14  51]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 13   5   5]\n",
      " [ 13 234  23]\n",
      " [  9  14  51]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./results/checkpoint-5625/config.json\n",
      "Model weights saved in ./results/checkpoint-5625/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 15 231  24]\n",
      " [ 10  13  51]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 15 231  24]\n",
      " [ 10  13  51]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-5750\n",
      "Configuration saved in ./results/checkpoint-5750/config.json\n",
      "Model weights saved in ./results/checkpoint-5750/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 14   4   5]\n",
      " [ 12 237  21]\n",
      " [ 10  15  49]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 14   4   5]\n",
      " [ 12 237  21]\n",
      " [ 10  15  49]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-5875\n",
      "Configuration saved in ./results/checkpoint-5875/config.json\n",
      "Model weights saved in ./results/checkpoint-5875/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 12   5   6]\n",
      " [ 12 236  22]\n",
      " [  9  14  51]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 12   5   6]\n",
      " [ 12 236  22]\n",
      " [  9  14  51]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-6000\n",
      "Configuration saved in ./results/checkpoint-6000/config.json\n",
      "Model weights saved in ./results/checkpoint-6000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 12   5   6]\n",
      " [ 12 235  23]\n",
      " [  9  14  51]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 12   5   6]\n",
      " [ 12 235  23]\n",
      " [  9  14  51]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-6125\n",
      "Configuration saved in ./results/checkpoint-6125/config.json\n",
      "Model weights saved in ./results/checkpoint-6125/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 12 237  21]\n",
      " [  9  14  51]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 12 237  21]\n",
      " [  9  14  51]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-6250\n",
      "Configuration saved in ./results/checkpoint-6250/config.json\n",
      "Model weights saved in ./results/checkpoint-6250/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 14   4   5]\n",
      " [ 13 235  22]\n",
      " [ 10  14  50]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 14   4   5]\n",
      " [ 13 235  22]\n",
      " [ 10  14  50]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-6375\n",
      "Configuration saved in ./results/checkpoint-6375/config.json\n",
      "Model weights saved in ./results/checkpoint-6375/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 12   6   5]\n",
      " [  7 243  20]\n",
      " [  7  19  48]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 12   6   5]\n",
      " [  7 243  20]\n",
      " [  7  19  48]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-6500\n",
      "Configuration saved in ./results/checkpoint-6500/config.json\n",
      "Model weights saved in ./results/checkpoint-6500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 12 234  24]\n",
      " [  9  13  52]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 12 234  24]\n",
      " [  9  13  52]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-6625\n",
      "Configuration saved in ./results/checkpoint-6625/config.json\n",
      "Model weights saved in ./results/checkpoint-6625/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 13 234  23]\n",
      " [ 10  14  50]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 13 234  23]\n",
      " [ 10  14  50]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-6750\n",
      "Configuration saved in ./results/checkpoint-6750/config.json\n",
      "Model weights saved in ./results/checkpoint-6750/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 13 234  23]\n",
      " [ 10  14  50]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 13 234  23]\n",
      " [ 10  14  50]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-6875\n",
      "Configuration saved in ./results/checkpoint-6875/config.json\n",
      "Model weights saved in ./results/checkpoint-6875/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 14   3   6]\n",
      " [ 12 234  24]\n",
      " [  9  13  52]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 14   3   6]\n",
      " [ 12 234  24]\n",
      " [  9  13  52]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-7000\n",
      "Configuration saved in ./results/checkpoint-7000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results/checkpoint-7000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 14   4   5]\n",
      " [  8 244  18]\n",
      " [  8  18  48]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 14   4   5]\n",
      " [  8 244  18]\n",
      " [  8  18  48]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-7125\n",
      "Configuration saved in ./results/checkpoint-7125/config.json\n",
      "Model weights saved in ./results/checkpoint-7125/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 14   4   5]\n",
      " [ 12 236  22]\n",
      " [ 10  16  48]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 14   4   5]\n",
      " [ 12 236  22]\n",
      " [ 10  16  48]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-7250\n",
      "Configuration saved in ./results/checkpoint-7250/config.json\n",
      "Model weights saved in ./results/checkpoint-7250/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 12   5   6]\n",
      " [ 11 236  23]\n",
      " [  8  16  50]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 12   5   6]\n",
      " [ 11 236  23]\n",
      " [  8  16  50]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-7375\n",
      "Configuration saved in ./results/checkpoint-7375/config.json\n",
      "Model weights saved in ./results/checkpoint-7375/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 12 234  24]\n",
      " [ 10  14  50]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 12 234  24]\n",
      " [ 10  14  50]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-7500\n",
      "Configuration saved in ./results/checkpoint-7500/config.json\n",
      "Model weights saved in ./results/checkpoint-7500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 14   3   6]\n",
      " [ 12 235  23]\n",
      " [ 10  14  50]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 14   3   6]\n",
      " [ 12 235  23]\n",
      " [ 10  14  50]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-7625\n",
      "Configuration saved in ./results/checkpoint-7625/config.json\n",
      "Model weights saved in ./results/checkpoint-7625/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 12 238  20]\n",
      " [ 11  16  47]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 12 238  20]\n",
      " [ 11  16  47]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-7750\n",
      "Configuration saved in ./results/checkpoint-7750/config.json\n",
      "Model weights saved in ./results/checkpoint-7750/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 11 239  20]\n",
      " [  8  18  48]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 11 239  20]\n",
      " [  8  18  48]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-7875\n",
      "Configuration saved in ./results/checkpoint-7875/config.json\n",
      "Model weights saved in ./results/checkpoint-7875/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 14   3   6]\n",
      " [ 13 233  24]\n",
      " [  9  12  53]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 14   3   6]\n",
      " [ 13 233  24]\n",
      " [  9  12  53]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-8000\n",
      "Configuration saved in ./results/checkpoint-8000/config.json\n",
      "Model weights saved in ./results/checkpoint-8000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 12 236  22]\n",
      " [ 10  15  49]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 12 236  22]\n",
      " [ 10  15  49]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-8125\n",
      "Configuration saved in ./results/checkpoint-8125/config.json\n",
      "Model weights saved in ./results/checkpoint-8125/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 14   3   6]\n",
      " [ 12 234  24]\n",
      " [  9  13  52]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 14   3   6]\n",
      " [ 12 234  24]\n",
      " [  9  13  52]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-8250\n",
      "Configuration saved in ./results/checkpoint-8250/config.json\n",
      "Model weights saved in ./results/checkpoint-8250/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 12 239  19]\n",
      " [ 10  16  48]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 12 239  19]\n",
      " [ 10  16  48]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-8375\n",
      "Configuration saved in ./results/checkpoint-8375/config.json\n",
      "Model weights saved in ./results/checkpoint-8375/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 12 238  20]\n",
      " [ 10  16  48]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 12 238  20]\n",
      " [ 10  16  48]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-8500\n",
      "Configuration saved in ./results/checkpoint-8500/config.json\n",
      "Model weights saved in ./results/checkpoint-8500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 12 241  17]\n",
      " [ 12  17  45]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 12 241  17]\n",
      " [ 12  17  45]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-8625\n",
      "Configuration saved in ./results/checkpoint-8625/config.json\n",
      "Model weights saved in ./results/checkpoint-8625/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 14   3   6]\n",
      " [ 12 234  24]\n",
      " [ 10  13  51]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 14   3   6]\n",
      " [ 12 234  24]\n",
      " [ 10  13  51]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-8750\n",
      "Configuration saved in ./results/checkpoint-8750/config.json\n",
      "Model weights saved in ./results/checkpoint-8750/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 14   3   6]\n",
      " [ 12 237  21]\n",
      " [ 10  14  50]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 14   3   6]\n",
      " [ 12 237  21]\n",
      " [ 10  14  50]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-8875\n",
      "Configuration saved in ./results/checkpoint-8875/config.json\n",
      "Model weights saved in ./results/checkpoint-8875/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 14   3   6]\n",
      " [ 11 241  18]\n",
      " [  9  16  49]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 14   3   6]\n",
      " [ 11 241  18]\n",
      " [  9  16  49]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-9000\n",
      "Configuration saved in ./results/checkpoint-9000/config.json\n",
      "Model weights saved in ./results/checkpoint-9000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 14   3   6]\n",
      " [ 12 237  21]\n",
      " [ 10  15  49]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 14   3   6]\n",
      " [ 12 237  21]\n",
      " [ 10  15  49]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-9125\n",
      "Configuration saved in ./results/checkpoint-9125/config.json\n",
      "Model weights saved in ./results/checkpoint-9125/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 12 236  22]\n",
      " [ 10  15  49]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 12 236  22]\n",
      " [ 10  15  49]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-9250\n",
      "Configuration saved in ./results/checkpoint-9250/config.json\n",
      "Model weights saved in ./results/checkpoint-9250/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 12 235  23]\n",
      " [  8  14  52]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 12 235  23]\n",
      " [  8  14  52]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-9375\n",
      "Configuration saved in ./results/checkpoint-9375/config.json\n",
      "Model weights saved in ./results/checkpoint-9375/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 12 237  21]\n",
      " [  9  14  51]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 12 237  21]\n",
      " [  9  14  51]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-9500\n",
      "Configuration saved in ./results/checkpoint-9500/config.json\n",
      "Model weights saved in ./results/checkpoint-9500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 11 242  17]\n",
      " [  9  17  48]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 11 242  17]\n",
      " [  9  17  48]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-9625\n",
      "Configuration saved in ./results/checkpoint-9625/config.json\n",
      "Model weights saved in ./results/checkpoint-9625/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 12 237  21]\n",
      " [ 10  14  50]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 12 237  21]\n",
      " [ 10  14  50]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-9750\n",
      "Configuration saved in ./results/checkpoint-9750/config.json\n",
      "Model weights saved in ./results/checkpoint-9750/pytorch_model.bin\n",
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 11 241  18]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 11 241  18]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-9875\n",
      "Configuration saved in ./results/checkpoint-9875/config.json\n",
      "Model weights saved in ./results/checkpoint-9875/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 14   3   6]\n",
      " [ 12 235  23]\n",
      " [  9  13  52]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 14   3   6]\n",
      " [ 12 235  23]\n",
      " [  9  13  52]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-10000\n",
      "Configuration saved in ./results/checkpoint-10000/config.json\n",
      "Model weights saved in ./results/checkpoint-10000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 10 243  17]\n",
      " [  9  16  49]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 10 243  17]\n",
      " [  9  16  49]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-10125\n",
      "Configuration saved in ./results/checkpoint-10125/config.json\n",
      "Model weights saved in ./results/checkpoint-10125/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 12 241  17]\n",
      " [ 10  15  49]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 12 241  17]\n",
      " [ 10  15  49]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-10250\n",
      "Configuration saved in ./results/checkpoint-10250/config.json\n",
      "Model weights saved in ./results/checkpoint-10250/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 12 240  18]\n",
      " [  9  13  52]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 12 240  18]\n",
      " [  9  13  52]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-10375\n",
      "Configuration saved in ./results/checkpoint-10375/config.json\n",
      "Model weights saved in ./results/checkpoint-10375/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [  9 243  18]\n",
      " [  7  15  52]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [  9 243  18]\n",
      " [  7  15  52]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-10500\n",
      "Configuration saved in ./results/checkpoint-10500/config.json\n",
      "Model weights saved in ./results/checkpoint-10500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 11 241  18]\n",
      " [  9  14  51]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 11 241  18]\n",
      " [  9  14  51]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-10625\n",
      "Configuration saved in ./results/checkpoint-10625/config.json\n",
      "Model weights saved in ./results/checkpoint-10625/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 14   3   6]\n",
      " [ 12 239  19]\n",
      " [ 10  15  49]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 14   3   6]\n",
      " [ 12 239  19]\n",
      " [ 10  15  49]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-10750\n",
      "Configuration saved in ./results/checkpoint-10750/config.json\n",
      "Model weights saved in ./results/checkpoint-10750/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 14   3   6]\n",
      " [ 12 241  17]\n",
      " [ 10  15  49]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 14   3   6]\n",
      " [ 12 241  17]\n",
      " [ 10  15  49]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-10875\n",
      "Configuration saved in ./results/checkpoint-10875/config.json\n",
      "Model weights saved in ./results/checkpoint-10875/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 12 241  17]\n",
      " [ 11  15  48]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 12 241  17]\n",
      " [ 11  15  48]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-11000\n",
      "Configuration saved in ./results/checkpoint-11000/config.json\n",
      "Model weights saved in ./results/checkpoint-11000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [  9 244  17]\n",
      " [  8  16  50]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [  9 244  17]\n",
      " [  8  16  50]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-11125\n",
      "Configuration saved in ./results/checkpoint-11125/config.json\n",
      "Model weights saved in ./results/checkpoint-11125/pytorch_model.bin\n",
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 12 241  17]\n",
      " [ 11  15  48]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 12 241  17]\n",
      " [ 11  15  48]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-11250\n",
      "Configuration saved in ./results/checkpoint-11250/config.json\n",
      "Model weights saved in ./results/checkpoint-11250/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 14   3   6]\n",
      " [ 12 241  17]\n",
      " [ 10  15  49]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 14   3   6]\n",
      " [ 12 241  17]\n",
      " [ 10  15  49]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-11375\n",
      "Configuration saved in ./results/checkpoint-11375/config.json\n",
      "Model weights saved in ./results/checkpoint-11375/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 12 241  17]\n",
      " [ 10  15  49]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 15   3   5]\n",
      " [ 12 241  17]\n",
      " [ 10  15  49]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-11500\n",
      "Configuration saved in ./results/checkpoint-11500/config.json\n",
      "Model weights saved in ./results/checkpoint-11500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 14   3   6]\n",
      " [ 12 240  18]\n",
      " [ 11  15  48]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 14   3   6]\n",
      " [ 12 240  18]\n",
      " [ 11  15  48]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-11625\n",
      "Configuration saved in ./results/checkpoint-11625/config.json\n",
      "Model weights saved in ./results/checkpoint-11625/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [  9 242  19]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [  9 242  19]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-11750\n",
      "Configuration saved in ./results/checkpoint-11750/config.json\n",
      "Model weights saved in ./results/checkpoint-11750/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 14   3   6]\n",
      " [ 12 241  17]\n",
      " [ 10  15  49]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 14   3   6]\n",
      " [ 12 241  17]\n",
      " [ 10  15  49]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-11875\n",
      "Configuration saved in ./results/checkpoint-11875/config.json\n",
      "Model weights saved in ./results/checkpoint-11875/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 12 241  17]\n",
      " [ 10  15  49]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 12 241  17]\n",
      " [ 10  15  49]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-12000\n",
      "Configuration saved in ./results/checkpoint-12000/config.json\n",
      "Model weights saved in ./results/checkpoint-12000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 14   3   6]\n",
      " [ 12 241  17]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 14   3   6]\n",
      " [ 12 241  17]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-12125\n",
      "Configuration saved in ./results/checkpoint-12125/config.json\n",
      "Model weights saved in ./results/checkpoint-12125/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 10 243  17]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 10 243  17]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-12250\n",
      "Configuration saved in ./results/checkpoint-12250/config.json\n",
      "Model weights saved in ./results/checkpoint-12250/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 14   3   6]\n",
      " [ 12 241  17]\n",
      " [ 10  15  49]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 14   3   6]\n",
      " [ 12 241  17]\n",
      " [ 10  15  49]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-12375\n",
      "Configuration saved in ./results/checkpoint-12375/config.json\n",
      "Model weights saved in ./results/checkpoint-12375/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 10 243  17]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 10 243  17]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-12500\n",
      "Configuration saved in ./results/checkpoint-12500/config.json\n",
      "Model weights saved in ./results/checkpoint-12500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 11 242  17]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 11 242  17]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-12625\n",
      "Configuration saved in ./results/checkpoint-12625/config.json\n",
      "Model weights saved in ./results/checkpoint-12625/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 12 241  17]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 12 241  17]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-12750\n",
      "Configuration saved in ./results/checkpoint-12750/config.json\n",
      "Model weights saved in ./results/checkpoint-12750/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 12 241  17]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 12 241  17]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-12875\n",
      "Configuration saved in ./results/checkpoint-12875/config.json\n",
      "Model weights saved in ./results/checkpoint-12875/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 10 243  17]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 10 243  17]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-13000\n",
      "Configuration saved in ./results/checkpoint-13000/config.json\n",
      "Model weights saved in ./results/checkpoint-13000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 10 243  17]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 10 243  17]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-13125\n",
      "Configuration saved in ./results/checkpoint-13125/config.json\n",
      "Model weights saved in ./results/checkpoint-13125/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 10 243  17]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 10 243  17]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-13250\n",
      "Configuration saved in ./results/checkpoint-13250/config.json\n",
      "Model weights saved in ./results/checkpoint-13250/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 10 243  17]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 10 243  17]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-13375\n",
      "Configuration saved in ./results/checkpoint-13375/config.json\n",
      "Model weights saved in ./results/checkpoint-13375/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 12 241  17]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 12 241  17]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-13500\n",
      "Configuration saved in ./results/checkpoint-13500/config.json\n",
      "Model weights saved in ./results/checkpoint-13500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 12 241  17]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 12 241  17]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-13625\n",
      "Configuration saved in ./results/checkpoint-13625/config.json\n",
      "Model weights saved in ./results/checkpoint-13625/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 12 241  17]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 12 241  17]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-13750\n",
      "Configuration saved in ./results/checkpoint-13750/config.json\n",
      "Model weights saved in ./results/checkpoint-13750/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 12 241  17]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 12 241  17]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-13875\n",
      "Configuration saved in ./results/checkpoint-13875/config.json\n",
      "Model weights saved in ./results/checkpoint-13875/pytorch_model.bin\n",
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 12 241  17]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 12 241  17]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-14000\n",
      "Configuration saved in ./results/checkpoint-14000/config.json\n",
      "Model weights saved in ./results/checkpoint-14000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 12 241  17]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 12 241  17]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-14125\n",
      "Configuration saved in ./results/checkpoint-14125/config.json\n",
      "Model weights saved in ./results/checkpoint-14125/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 12 241  17]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 12 241  17]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-14250\n",
      "Configuration saved in ./results/checkpoint-14250/config.json\n",
      "Model weights saved in ./results/checkpoint-14250/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 11 242  17]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval_confusion_matrix\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[[ 13   4   6]\n",
      " [ 11 242  17]\n",
      " [  9  15  50]]\" of type <class 'str'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-14375\n",
      "Configuration saved in ./results/checkpoint-14375/config.json\n",
      "Model weights saved in ./results/checkpoint-14375/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results/checkpoint-4875 (score: 0.5645146369934082).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=14400, training_loss=0.3720787928501765, metrics={'train_runtime': 5214.3091, 'train_samples_per_second': 87.759, 'train_steps_per_second': 2.762, 'total_flos': 1.219472917757952e+17, 'train_loss': 0.3720787928501765, 'epoch': 400.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed(42)\n",
    "mlflow.end_run()\n",
    "train_dataset = Dataset(train_snippets_encodings, train_snippets_labels, train_snippets_topics, train_snippets_features)\n",
    "valid_dataset = Dataset(valid_snippets_encodings, valid_snippets_labels, valid_snippets_topics, valid_snippets_features)\n",
    "\n",
    "#train_dataset = Dataset(None, train_snippets_labels, train_snippets_topics)\n",
    "#valid_dataset = Dataset(None, valid_snippets_labels, valid_snippets_topics)\n",
    "\n",
    "\n",
    "\n",
    "num_classes = 3\n",
    "class_weights = (1/all_snippets_class_counts).tolist()\n",
    "#class_weights = ((np.sum(all_snippets_class_counts)-all_snippets_class_counts)/all_snippets_class_counts).tolist()\n",
    "#class_weights = [100.0,1.0,100.0]\n",
    "freeze_bert_weights = True\n",
    "use_topics = True\n",
    "use_features = True\n",
    "use_embeddings = True\n",
    "\n",
    "\n",
    "print(all_snippets_class_counts,class_weights)\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.trainer_utils import SchedulerType\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=400,              # total number of training epochs\n",
    "    per_device_train_batch_size=batch_size,  # batch size per device during training\n",
    "    per_device_eval_batch_size=512,   # batch size for evaluation\n",
    "#    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
    "    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
    "    warmup_steps=max(10,1000//2//batch_size),                # number of warmup steps for learning rate scheduler\n",
    "    logging_steps=max(1,4000//batch_size),               # log & save weights each logging_steps\n",
    "    save_steps=max(1,4000//batch_size),\n",
    "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",
    "    save_strategy=\"steps\",\n",
    "#    lr_scheduler_type = SchedulerType.COSINE_WITH_RESTARTS\n",
    ")\n",
    "model = BertForWeightedSequenceClassification.from_pretrained(model_name, \n",
    "                                                              num_labels=num_classes, \n",
    "                                                              problem_type='single_label_classification', \n",
    "                                                              class_weights=class_weights, \n",
    "                                                              freeze_bert_weights=freeze_bert_weights, \n",
    "                                                              use_topics=use_topics, \n",
    "                                                              use_features=use_features,\n",
    "                                                              use_embeddings=use_embeddings)\n",
    "if torch.cuda.is_available():\n",
    "  model = model.to(\"cuda\")\n",
    "\n",
    "trainer = Trainer(\n",
    "  model=model,                         # the instantiated Transformers model to be trained\n",
    "  args=training_args,                  # training arguments, defined above\n",
    "  train_dataset=train_dataset,         # training dataset\n",
    "  eval_dataset=valid_dataset,          # evaluation dataset\n",
    "  compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 367\n",
      "  Batch size = 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 15   3   5]\n",
      " [ 13 233  24]\n",
      " [ 10  11  53]]\n",
      "Predicted oma narratiivi ([ 0.6529228 -3.0439527  1.8922771]) != real kritiikki for:\n",
      "[CLS] lue aikaisemmat osat tasta : http : / / mvlehti. net / 2016 / 05 / 02 / suomea - johtaa - mafia - osa - 1 / http : / / mvlehti. net / 2016 / 05 / 02 / suomea - johtaa - mafia - osa - 2 / http : / / mvlehti. net / 2016 / 05 / 03 / suomea - johtaa - mafia - osa - 3 / http : / / mvlehti. net / 2016 / 05 / 04 / suomea - johtaa - mafia - osa - 4 / vaikka mielipidetuomioiden ja tyottomyyden uhka ovat merkittavia syita sille, ettei kansa uskalla nousta mafiaa vastaan, on ryovareiden aseista vaarallisin velan ohella media. edes kansanaanestyksilla ei ole valia, mikali mielipidemonopoli istuttaa jatkuvasti valheita kansalaisten tajuntaan. onneksi ihmiset ovat alkaneet siirtya vaihtoehtomedioiden lukijoiksi. ( kaavion lahde : yle. ) suomen maahanmuuttokriisi raiskauksineen ja kasvavine katujengeineen on niin nakyva epakohta, etta edes lehdisto ei ole kyennyt piilottamaan sita julkisuudelta. paljon ongelmallisempia ovatkin ilmiot, joita ei voi nahda katukuvassa ja joiden ymmartaminen vaatii ahkeraa omaehtoista opiskelua. siirtolaiskriisi on raikea oire taudista, joka on onnistuttu pitamaan nakymattomissa. taudin ydin on rahan keinotekoinen niukkuus ja valtioiden velkavankeus. velkakiristys jaytaa suomea vaivihkaa, suojassa suomalaisten katseilta. valtamedian tehtava on ohjata kansalaisten mielenkiinto pois itse taudista ja kohti taudin oireita. tarkeinta on, ettei velkakorruptiosta puhuta julkisesti. kun kyse on velkapommia konkreettisemmista aiheista, kuten euroopan unionista tai vapaakauppasopimuksista, kayttaa valehteleva lehdisto erilaisia harhautusmenetelmia. mtv oy : n entinen toimitusjohtaja pekka karhuvaara paljasti porin suomi areena – tapahtumassa 2010, etta helsingin sanomien omistaja aatos erkko pakotti kaikki suomalaislehdet propagoimaan eu - jasenyyden puolesta 1990 - luvulla. sopulilauma totteli herraansa uskollisesti. ilta - sanomat uutisoi vuonna 2010 karhuvaaran paljastuksen. toisin sanoen lehdisto sopi oligarkki erkon johdolla kansalta salassa, etta suomalaisia sumutettaisiin asenteellisella ” tiedotuksella ”, jonka tavoitteena oli huijata kansa aanestamaan eu - jasenyyden puolesta. suunnitelma myos onnistui. on jo sinansa aarimmaisen mielenkiintoista, etta kaikki pohjoismaiden suuret mediaperheet – erkot, hjornet ja bonnierit – edustavat samaa pienta heimoa, jonka osuus on virallisesti noin 0, 2 promillea suomen vaestosta. nain valta keskittyy. nyt mediaoligarkit valehtelevat kansalle esimerkiksi ttip : sta jattamalla kertomatta, etta vapaakauppasopimus mahdollistaisi luonnonvarojen ja peruspalveluiden kauppaamisen ulkomaisille monopoleille. kansalaiset vastustavat ttip : ta.\n",
      "Predicted oma narratiivi ([ 0.06774998 -0.9885494   0.71590054]) != real kritiikki for:\n",
      "kuva mielenosoituksesta. suomi on jo miehitetty – ja nyt puolustusvoimia puretaan suomi miehitettiin viimeistaan siina vaiheessa, kun meidat huijattiin osaksi euroopan unionia. taman jalkeen meidat pakotettiin ulkomaalaisten pankkien velkavangiksi. stalinistinen vaestonsiirtopolitiikka on jo taydessa vauhdissa : suomalaiset korvataan afrikan ja arabimaiden maahanmuuttajilla. olemme jo siis kaytannossa menettaneet valtaosan poliittisesta itsenaisyydestamme. akuutein uhka ei ole ulkomaalainen valloittaja vaan arkadianmaen parittajat, jotka myyvat suomi - neitoa pilkkahintaan ulkomaalaisille gangstereille. mafian pr - toimistot ovat kiivaasti ajamassa suomea nyt myos natoon, joka on ttip : n sotilaallinen vastine. amerikkalaiset joukot tulevat jarjestamaan kolme harjoitusta suomen maaperalla kevaan ja kesan aikana. perussuomalainen puolustusministeri jussi niinisto pimitti tiedon harjoituksista viimeiseen asti, mika raivostutti jopa monia poliitikkoja. jussi niinisto. suomalaisten sanomalehtien paatoimittajat eivat edes peittele rakkauttaan natoa kohtaan. mista kansanvihollisten into johtuu? syy selviaa sotilasliiton kotisivuilta, jossa kerrotaan, etta nato perustettiin paitsi torjumaan neuvostoliiton uhkaa, niin myos vastustamaan eurooppalaista nationalismia. naton omien sanojen mukaan sen tehtava on myos ajaa euroopan yhdistymista eli liittovaltioprojektia. nato tekee siis vakivalloin sita, mita poliitikot ja pankit tekevat korruption kautta : myyvat valtioiden itsenaisyyden mafialle. keinotekoinen velkakriisi on ollut hyodyksi myos nato - fundamentalisteille. puolustusministerion kansliapaallikkona vuoden 2015 loppuun saakka toiminut arto raty totesi yleisradiossa 29. 12. 2015, etta suomen ” budjettivajeen ” vuoksi maamme sodanajan joukkojen vahvuutta taytyy leikata tuntuvasti. arto raty kuvassa oikealla. asemastaan huolimatta raty ei ole edes yrittanyt ajaa puolustusvoimien etua. sen sijaan han on vaikuttanut varsin tyytyvaiselta saastokuuriin, silla leikkaukset pakottavat suomen ” lisaamaan kansainvalista yhteistyota ”. suomen taytyy myyda puolustusvoimansa pankkimafialle, jotta saisimme vastineeksi toimia yhdysvaltojen sotilaallisena kasikassarana. ratya odottavat varmasti yltakyllaiset elakevuodet. lahde : a. p. / magneettimedia t2 / mv toimitus2mv @ gmail. com [SEP]\n",
      "Predicted kritiikki ([ 1.2787656  0.762726  -2.3051102]) != real kopiointi for:\n",
      "[CLS] suomen keskusrikospoliisin mukaan perussuomalaisten kansanedustajasta olli immosesta on tehty tutkintapyynto. krp kirjoittaa twitter - tilillaan, etta yksityishenkilo on tehnyt tutkintapyynnon immosen facebook - paivityksesta. krp selvittaa, onko asiassa syyta epailla rikosta. perussuomalaisten kansanedustaja olli immonen kirjoitti sunnuntaina facebookissa lyyrillisen kirjoituksen monikulttuurisuutta vastaan. perussuomalaiset - puolue, jonka kansanedustaja immonen on, ei kannata monikulttuurisuutta. kommentissaan immonen kertoo ” haaveilevansa vahvasta valtiosta, joka voittaisi taman painajaisen nimelta monikulttuurisuus ”. siihen on helppo kenen tahansa yhtya, kun katsoo vaikkapa raiskaustilastoja, joissa monikulttuurisuuden kohtaamiselta ei voi valttya. ja mista vetoa, etta seuraavaksi halutaan kieltaa kansallismielisyys, ja kaikki, mika johti maamme itsenaistymiseen ja itsenaisyyden puolustamiseen pitaa polttaa, havittaa ja piilottaa? suomi on henkisesti sairas maa. lahde : aamulehti [SEP]\n",
      "Predicted oma narratiivi ([ 0.03377585 -1.732239    1.2867421 ]) != real kritiikki for:\n",
      "2012 : lauri helve ( mm. kauppalehden pitkaaikainen paatoimittaja ) : ” kun aatos - seta lahti voimakkaasti eu - jasenyyden taakse, kaikki kriittiset makatykset loppuivat ” alkuperainen kirjoitus : juhani huopainen / puheenvuoro - blogikirjoitus [SEP]\n",
      "Predicted oma narratiivi ([-3.6258695  1.3950654  1.8818399]) != real kopiointi for:\n",
      "[CLS] talouselama. fi uutisoi, etta suomessa perunan harmaahilseen torjuntaan kaytettavan rizolex 50 sc - valmisteen jaamien enimmaismaaravaatimukset tiukentuvat. tassa valmisteessa on tehoaineena tolklofossi - metyylia, jonka jaamien enimmaismaara myytavassa perunassa tiukentuu 26. elokuuta alkaen. tiukennukset johtuvat tehoaineelle tehdyista riskinarvioista. aineen myyntipakkauksessa lukee mm. seuraavaa : voi aiheuttaa allergisen ihoreaktion. erittain myrkyllista vesielioille, pitkaaikaisia haittavaikutuksia. valta polyn / savun / kaasun / sumun / hoyryn / suihkeen hengittamista. kayta suojakasineita / suojavaatetusta / silmiensuojainta / kasvonsuojainta. jos kemikaalia joutuu iholle : pese runsaalla vedella. jos ilmenee ihoarsytysta tai ihottumaa : hakeudu laakariin. valumat on kerattava. noudata kayttoohjeita ihmisen terveydelle ja ymparistolle aiheutuvien vaarojen valttamiseksi. tehoaine : tolklofossi - metyyli 500 g / l valmistetta ei saa kayttaa varhaisperunalla, koska se aiheuttaa siihen makuvirheita. vesieliovaikutusten vuoksi perunoita peitattaessa, valmisteella peitattuja perunoita istutettaessa seka peittaus - ja istutuslaitteita puhdistettaessa on varmistauduttava, ettei ainetta joudu vesistoon tai viemariverkostoon. ylijaanyt, kayttokelvoton kasvinsuojeluaine viedaan vaarallisen jatteen kerayspisteeseen ja tyhjat, huuhdellut myyntipakkaukset asianmukaiseen jatepisteeseen. viitekuva. tolklofossi - metyyli - tehoaineen jaamien enimmaismaara on ollut perunalla 0, 2 mg / kg. 26. elokuuta alkaen tolklofossi - metyyli - tehoainejaamia saa olla myytavassa perunassa vain 0, 01 mg / kg. koska ollaan suomessa, ei tuolla paivamaaralla 26. elokuuta ole todellista merkitysta. kaytannossa paivayksen vuosiluvuksi voisi kirjoittaa 2017. tukesin linjauksen mukaan tana kevaana peittauksessa tehoainetta sisaltavaa rizolex 50 sc - valmistetta voi kayttaa aiempien vuosien tapaan. suomen jaamavalvojat seuraavat kayttohetken mukaista jaaman enimmaismaaraa. koska rizolexilla peitattu siemenperuna istutetaan kevaalla, saa syksylla myytavissa perunoissa olla tolklofossi - metyylin jaamia enimmillaan 0, 2 mg / kg. rizolex - valmisteella peitatusta siemenperunasta korjattavaa satoa voi siis kayttaa suomessa elintarvikkeena. tiukennukset jaamien enimmaismaarissa koskevat satokautta 2017. kuluttajan kannalta katsottuna vasta satokauden 2017 perunoiden pitaa olla uuden saannoksen mukaisia. viranomaisten toiminta on arveluttavaa ja tuomittavaa siksi, etta paatosta tehtaessa vuoden 2016 satokausi ei ollut viela alkanut. uskaltavat\n",
      "Predicted oma narratiivi ([-1.2947799   0.10442173  0.71630764]) != real kopiointi for:\n",
      "##ko suomalaiset lapsiperheet enaa kayttaa suomalaista tulevan tai edellisen satokauden perunaa? sille, etta uusi turvallisuusraja 20 kertaa pienempi kuin entinen, on varmasti vahvat perusteet. viela yli vuoden ajan suomalaiset lapset syovat perunaa, jossa voi olla 20 kertainen maara tolklofossi - metyyli - myrkkya turvalliseksi luokilteltuun perunaan verrattuna. lahde : talouselama. fi t3 / mv toimitus3mv @ gmail. com [SEP]\n",
      "Predicted kritiikki ([ 0.389521  -0.3744228 -0.0805717]) != real kopiointi for:\n",
      "[CLS] turun sanomissa 11. 3. 2016 on suomen turvallisuuskomitean asiantuntijajasen, valtioneuvoston viestintajohtaja markku mantila tuominnut ” pysyvaksi riesaksi ” nato - kriittisen nettikirjoittelun, jossa asetetaan kyseenalaiseksi suomen valtiollisten paattajien jotkut ratkaisut ja motiivit. valtioneuvoston vietintajohtaja, turvallisuuskomitean jasen markku mantila mustamaalaa nato - kriittiset mielipiteet ” trollien ” toiminnaksi markku mantila uskoo, etta suomen mahdollista nato - jasenyytta koskeva valtamedian paatoimittajien kirjoittelu herattaa heti trollit. tallaista trollausta mantila uskoo nakevansa kevaalla 2016, kun suomessa aletaan keskustella nato - selvityksesta seka ulko - ja turvallisuuspoliittisesta selonteosta. lisaksi trollit pyrkivat kayttamaan hyvaksi myos pakolaiskriisia, vaittaa mantila. turvallisuuskomitean asiantuntijajasen markku mantila vakuuttaa, etta nato - kriittiset sosiaalisen median kirjoittajat ” otetaan tosissaan myos valtionhallinnossa. valtioneuvoston kanslian ja eri ministerioiden asiantuntijoista koottu yhteysryhma vaihtaa jarjestelmallisesti tietoja keskenaan ”. tiukimmat kriitikot ovat moittineet, etta suomen valtioneuvosto olisi vuonna 2013 perustetun turvallisuuskomitean alainen. turvallisuuskomitea on ” kokonaisturvallisuuselin ”, joka nayttaa vastaavan vain amerikan yhdysvalloille ja natolle. valtioneuvoston viestintajohtaja markku mantila on suomen turvallisuuskomitean asiantuntijajasen. kaleva - lehdessa mantila kertoi mainittujen viranomaisten varautuvan venajan infosotaan, mita vastaan piti perustaa myos ” iskuryhma ” kevaalla 2015. paatantavalta turvallisuusasioista on suomessa siirretty yha enemman turvallisuuskomitean asiantuntijoille, jotka valvovat usa : n ja naton intresseja suomessa. turvallisuuskomitea kertoo itsekin, etta suomi on liittynyt erinaisten jarjestelyjen avulla amerikan yhdysvaltojen capitive nations – alusmaihin. turvallisuuskomitean kehittaman perustamiskertomuksen mukaan komitea tuli tarpeelliseksi venajan infosodan johdosta. komitea aloitti toimintansa helmikuussa 2013. heidan web - sivustonsa perustettiin kuitenkin jo vuotta aiemmin. lahteet : jussi saarinen, turun sanomat 11. 3. 2016. venaja - trollaus hiljeni : suomeen kohdistuvat lokakampanjat vahentyneet juha vainio, kaleva 26. 4. 2015. viranomaiset varautuvat venajan infosotaan – suomeen perustettiin iskuryhma. http : / / www. kaleva. fi / uutiset / kotimaa / viranomaiset - varautuvat - venajan - infosotaan - suomeen - perustettiin - iskuryhma / 695491 / turvallisuuskomitea 9. 4. 2015. suomi osallistuu kansainvaliseen multinational capability development – kampanjaan ( mcdc ). t9 / mv toimitus9mv @ gmail. com [SEP]\n",
      "Predicted kritiikki ([ 0.83015037  0.33428076 -1.4155484 ]) != real oma narratiivi for:\n",
      "[CLS] yle uutisoi eilen, etta lappeenrannassa tehdyista turvapaikkapaatoksista yli puolet on ollut myonteisia, kun koko maan keskiarvo on neljannes. mv - lehti kertoi asiasta tuoreeltaan : onko iiris hjelt yksi syy siihen, etta turvapaikkahakemus menee lappeenrannassa lapi suomen helpoiten? laskimme, etta kun lappeenrannan paatokset otetaan pois koko maan paatoksista, muualla maassa myonteisen turvapaikkapaatoksen saa vain yksi viidesta – perati 80 prosenttia hakijoista on siis tullut suomeen perusteetta – lappeenrantaa lukuunottamatta. tanaan yle kertoo, etta eilinen uutinen oli virheellinen. yle kirjoittaa : lappeenrannassa on tana vuonna tehty 1 743 turvapaikkapaatosta, joista myonteisia on ollut 445 ja kielteisia 910. eli suurin osa lappeenrannassa tehdyista paatoksista on ollut valtakunnallisen linjan mukaisesti kielteisia. maanantaina kerroimme maahanmuuttovirastosta saamiimme tietoihin pohjaten, etta turvapaikkapaatoksia olisi tehty lappeenrannassa noin 5 500 ja suurin osa niista olisi ollut myonteisia. kuvakaappaus ylen tamanpaivaisesta uutisesta. kuviossa on jotain outoa, silla eilisessa ylen jutussa maahanmuuttoviraston johtaja hanna tikkala kertoi, etta ero hyvaksyntamaarissa johtuu hakijaprofiileista. saimaan tulosalueella on tikkalan mukaan ollut enemman esimerkiksi syyrialaisia turvapaikanhakijoita, joille myonnetaan nyt kaikille oleskelulupa suomeen, kertoi yle. tikkala oli siis tietoinen lappeenrannan poikkeuksellisesta tilanteesta, kun osasi selittaa sen. tikkala itse tyoskentelee maahanmuuttoviraston saimaa 2 - tulosalueen johtajana lappeenrannassa, joten hanen luulisi tuntevan ja tietavan tilanteen erittain hyvin. hanna tikkala imatralainen - julkaisun uutisessa helmikuussa. jutussa kerrotaan, etta tikkala itse tyoskentelee lappeenrannassa. kuvakaappaus. nyt kysymys kuuluu : kenella tuli hatakakka housuun, ja mika on lopullinen totuus? onko maahanmuuttovirasto eilisen jalkeen mennyt sormeilemaan lukuja, koska lappeenrannan tilanne tuli ilmi, vai onko maahanmuuttoviraston johto lappeenrannassa taysin pihalla lappeenrannan yksikon toiminnasta ja tulosluvuista? tahan tulisi saada selvyys. lahde : yle t2 / mv toimitus2mv @ gmail. com [SEP]\n",
      "Predicted kopiointi ([-2.2207325   1.6874281   0.30466187]) != real oma narratiivi for:\n",
      "[CLS] eduskunta pitaa ylla listausta istunnoista poissaolleista kansanedustajista. listassa kerrotaan syyt, miksi edustaja ole paassyt paikalle. esimerkkina sdp : n kansanedustaja susanna huovinen : kuvakaappaus : eduskunta. susanna huovinen on eduskunnan tilaston mukaan sairas ihminen. kuvakaappaus : susannahuovinen. fi kansanedustajan palkkio ei ole suomessa palkansaajiin verrattuna mitenkaan huono, joten siihen nahden tuollaiset ” muut poissaolot ” ovat suomalaisille palkanmaksajille ja demokratialle irvailua. veronmaksajat maksavat kansanedustajien palkkiot. poissaolo veron - eli palkanmaksajien maksamasta tyosta on halveksuntaa demokratiaa vastaan. esimerkiksi sveitsissa, joka on nykyisen demokratian kehto suorine demokratioineen, eraskin kunnanjohtaja saa pienta palkkaa tehdessaan kunnanjohtajan tyota sivutoimisena oman tyonsa ohella. sveitsin pikkukunnissa ei tarvita kokopaivaisia kunnanjohtajia, kuten suomessa ; suomesta vastakkaisena esimerkkina vaikka puolanka, joka haluaa turvapaikanhakijoita kuntaansa, vaikka kunta jo valmiiksi elaa valtiontukien varassa. kuten sen kunnanjohtajakin. uusi suomi - julkaisu huomioi eduskunnan tilastosta, etta alexander stubb on ollut tana syksyna aktiivisesti poissa veronmaksajien maksamista tehtavistaan. stubb pidatteli itkua viime kesana, kun hanta ei valittu jatkamaan kokoomuksen puheenjohtajana. uusi suomi kirjoittaa : kesan jalkeen, syys – lokakuussa 2016, eduskunnassa on pidetty 32 taysistuntoa. eduskunnan tilastojen mukaan stubb on ollut poissa 15 taysistunnosta. nain ollen han on ollut paikalla 17 taysistunnossa. puheenvuoroja han ei ole taysistunnoissa pitanyt. stubb on ollut muutenkin melko nakymaton kotimaan politiikassa. kaikkiin stubbin poissaoloihin on merkitty syyksi ” muu poissaolo ”, joten esimerkiksi sairaudesta ei ole ollut kysymys. myoskaan eduskuntatyohon liittyvista matkoista ei ole voinut olla kyse, silla eduskunnan mukaan poissaolojen tilastoinnissa ” eduskuntatyohon liittyva tehtava rinnastetaan lasnaoloon taysistunnossa, jolloin tilastoon ei tule merkintaa poissaolosta ”. lahteet : kansanedustajien poissaolot lokakuussa 2016, pdf - tiedosto, uusi suomi t2 / mv toimitus2mv @ gmail. com [SEP]\n",
      "Predicted kopiointi ([-0.6751235   0.72307974 -0.24928041]) != real oma narratiivi for:\n",
      "[CLS] halla - aho nousi ” uhoten ” mamuasioiden kasittelemisessa eduskunnan tarkeimman valiokunnan johtoon. http : / / www. kaleva. fi / uutiset / kotimaa / halla - aho - vetamaan - maahanmuuttoasioita - kasittelevaa - valiokuntaa / 419121 / kavi puheenjohtajana valiokunnan sihteerin kanssa matkalla etiopiassa, jossa sijatsee somalian edustusto. matkalle osallistui myos useita kansanedustajia. perheenyhdistaminen tarkoittaa sita, etta oleskeluluvan suomesta saanut turvapaikanhakija voi yrittaa saada suomeen myos perheensa. http : / / www. hs. fi / politiikka / a1305550447892 kuten hs - jutusta ilmenee han kehui perheidenyhdistamisohjelman sujuvuutta. mutta kuinka sitten kavikaan? ” messias ” pyysi eroa puheenjohtajan tehtavista. etunenassa eroa vaati vihreat. kaikkien maahanmuuttokriittisten ” toiveet ” murenivat silla sekunnilla. ei saatu sita mita tilattiin. http : / / www. iltasanomat. fi / kotimaa / art - 2000000513218. html tohtorimme taipui erovaatimuksien edessa. ei kantti kestanyt! ” ken leikkiin lahtee han leikin kestakoon ”. olavi maenpaa kaupunginvaltuutettu turku perussuomalaiset ne on vaan veronkierron asialla, kukaan muu ei. - ilja j / mv kuvat [SEP]\n",
      "Predicted kritiikki ([ 1.2219446  -0.39916685 -1.0854428 ]) != real kopiointi for:\n",
      "[CLS] ylikomisario jari taposen ” miksei islamisti saa kayda koulua ” - tviitit ovat herattaneet kansainvalistakin huomiota. muun muassa suosittu amerikkalainen infowars - vaihtoehtomedia nosti taposen tviitit esiin jutussaan. mv - lehden englanninkielinen juttu linkissa : moronic tweets by finnish police chief gain international attention suomalaiselle medialle taponen esittaa olevansa informaatiosodan uhri. ” tama on tyypillista informaatiovaikuttamista, jolla pyritaan polarisoimaan keskustelua ja yhteiskuntaa. laitamme twitteriin mita hyvansa, niin sita lahdetaan vaaristelemaan ”, taponen kommentoi mtv : n uutisille. taponen vaittaa, etta hanen viestinsa ymmarrettiin tahallaan vaarin. taposen mukaan han tarkoitti tviitissaan sita, etta oppiminen kannattaa aina ja voi auttaa paasemaan aariajatuksista eroon. han vaittaa, ettei missaan vaiheessa viitannut turun iskuun, vaan puhui asioista yleisella tasolla. taponen valehtelee harskisti jos twitter - ketjun lukee kokonaisuudessaan, on helppo nahda, etta taponen valehtelee. hanen viestinsa olivat suoria vastauksia huolestuneiden kansalaisten kysymyksiin, jotka koskivat nimenomaan aikuisten, potentiaalisten muslimiterroristien laittamista ylaasteen kouluihin nuorten suomalaiskoululaisten sekaan. twitter - ketju, johon taponen vastasi. taponen nayttaa nyttemmin poistaneen kiistanalaiset tviittinsa, joten ehka niissa oli hanenkin mielestaan jotain vikaa. ” on ihminen tehnyt minka rikoksen tahansa, jonain paivana han vapautuu vankilasta ja hanen pitaisi olla silloin yhteiskuntakelpoinen ”, kommentoi taponen mtv : lle. on vaikea ymmartaa, mihin tama kommentti liittyy. turun islamilainen terroristi abderrahman bouanane, 22, ei ollut vankilassa kaydessaan puropellon ylaastetta. han oli tullut suomeen turvapaikanhakijana ja valehdellut olevansa alaikainen. vai tarkoittaako taponen, etta bouanane pitaa pistaa takaisin ylaasteen koulunpenkille, kun han joskus vapautuu vankilasta? yritetaanko poliisien idioottimaisia tviitteja vaientaa? taposen mukaan kommentoijien joukosta loytyy ” useita aktiivisia aarioikeiston kannattajia ja trolleja ”. ” asialle saadaan nakyvyytta, kun kauhistellaan taposen sanomisia. sen myota tavallisetkin ihmiset lahtevat mukaan kauhisteluun huomaamatta ollenkaan, mika se alkuperainen tviitti oikeasti oli. ” taposen alkuperainen tviitti oli ” hyvaa oppi tekee terroristillekin! ” se oli kirjoitettu vastauksena ihmisten huoleen siita, etta aikuinen terroristi pistettiin samaan kouluun nuorten suomalaislasten kanssa. asiaa kommentoineiden mahdollinen puoluekanta ei muuta tata tosiasiaa mitenkaan. taposen mukaan viime viikolla vastaavanlaisen ” some - ryopytyksen ” kohteeksi joutui helsingin poliisilaitoksen johtokeskuksen johtaja, ylikomisario jussi huhtela sen jalkeen kun perussuomalaisten puheenjohtaja jussi halla - aho oli nostanut huhtelan poliisina lahettaman poliittisen tviitin esiin facebook -\n",
      "Predicted kritiikki ([ 1.3833604  -0.18317406 -1.3396349 ]) != real kopiointi for:\n",
      "sivullaan. kyse oli tasta tviitista. jokainen voi itse paatella, onko halla - ahon huoli poliisin politisoitumisesta aiheellinen. halla - ahon kommentti huhtelan tviittiin. taponen katsoo, etta ” some - ryopytyksella yritetaan hiljentaa ja heikentaa poliisia ”. on hieman epaselvaa, kenen taponen vaittaa yrittavan hiljentaa ja heikentaa poliisia. todisteiden valossa nayttaisi silta, etta kaikkein pahiten suomen poliisin uskottavuutta ja puolueettomuutta heikentavat nimenomaan taposen ja huhtelan kaltaiset ylikomisariot, jotka kayttavat poliisin asemaansa oman poliittisen agendansa ajamiseen. ainakaan mv - lehti ei pyri hiljentamaan taposta ja muita suvaitsevaisia poliisijohtajia, vaan toivoo, etta he jatkavat islamisti - ja terroristimyonteisten tviittiensa levittamista ja saavat niille mahdollisimman paljon julkisuutta. ihmisilla on oikeus tietaa, mita poliisin johtoporras ajattelee. lue myos : ylikomisario jussi huhtela kommentoi jyvaskylan vokkimellakkaa lahde : mtv - uutiset t12 / mv toimitus12mv @ protonmail. com [SEP]\n",
      "Predicted oma narratiivi ([-1.0724916 -1.0194327  1.9723302]) != real kopiointi for:\n",
      "[CLS] yle 15. 6. 2016 otsikko jussi niinisto : baltian nato - pataljoonat tuovat vakautta itameren ymparistoon nato - maiden tiistaina tekema paatos vahvistaa lasnaoloaan baltiassa ja puolassa perustamalla baltian maihin ja puolaan noin tuhannen sotilaan vahvuiset pataljoonat on suomen kannalta positiviinen, puolustusministeri jussi niinisto ( ps. ) arvioi. – luulen, etta silla on vakauttava merkitys. baltian maat ovat olleet jossain maarin enemman turvallisuuden kuluttajia kuin sen tuottajia. jos tama sitten lieventaa sita epaselvyytta, niinisto kommentoi brysselissa. puolustusministerimme jussi niinisto siis ajattelee, etta tama nato : n toimi vakauttaa! ei voi olla totta! yle itsekin myontaa, etta tama toimi, taistelujoukkojen tuominen ita - eurooppaan rikkoo venajan ja nato : n valista sopimusta : nato ja venaja ovat sopineet, etta merkittavia pysyvia taistelujoukkoja ei tuoda lahelle toisen aluetta. naton pataljoonat ovat diplomaattilahteiden mukaan pysyvaisluonteisia mutta perustuvat kuitenkin rotaatioon, eli vakea vaihdetaan aika ajoin. deutsche wirtschafts nachrichten otsikoi : nato aloittaa venaja piirittamisen ( taalla engl. ) ja kirjoittaa : virallisesti pataljoonat eivat ole pysyvasti sijoitettu ita - euroopan maihin, vaan vaihtuvat saannollisesti. talla pataljoonien kierrattamisella nato haluaa muodollisesti valttaa rikkomasta venajan kanssa vuonna 1997 tekemaansa sopimusta nato - russia founding act, joka kieltaa pysyvien taistelujoukkojen sijoittamisen ita - eurooppaan. obama siis haluaa toimia aggressiivisemmin, kuin nato - russia founding act antaisi myoten ; obama haluaa rikkoa sopimusta siten, etta han voi sanoa ettei riko sopimusta. nato - russia founding act in addition, in the negotiations on the adaptation of the cfe treaty ( tavanomaiset aseet euroopassa - sopimus, tae - sopimus ), the member states of nato and russia will, together with other states parties, seek to strengthen stability by further developing measures to prevent any potentially threatening build - up of conventional forces in agreed regions of europe, to include central and eastern europe. [ [UNK] ] nato reiterates that in the current and foreseeable security environment, the alliance will carry out its collective defence and other missions by ensuring the necessary interoperability, integration, and capability for reinforcement rather than by addit\n",
      "Predicted oma narratiivi ([-0.15465371 -1.1263752   0.8391934 ]) != real kopiointi for:\n",
      "##ional permanent stationing of substantial combat forces. tama usa - nato : n suorittama venajan harnaaminen, venajan kanssa tehdyn sopimuksen rikkominen on puolustusministeri jussi niiniston mielesta suomen kannalta positiivinen paatos ja itameren aluetta vakauttava paatos!!! voi perkeleen perkele! lahde : mv - blogi t11 / mv mvtoimitus11 @ gmail. com [SEP]\n",
      "Predicted kritiikki ([ 0.8582006  -1.1577371   0.04590032]) != real kopiointi for:\n",
      "[CLS] mv - lehti ennakoi fobban potkuja ilmeisesti ainoana mediassa jo eilisessa uutisessaan : marko [UNK] fobba ” forss ei sovellu vihapuhetutkintaryhman tutkinnanjohtaksi yle. fi uutisoi, etta nettipoliisina tunnettu marko ” fobba ” forss ei jatka poliisin vihapuhetyoryhman johtajana. potkut tuli! poliittiseksi suvakkipoliisiksi ryhtynyt forss ei ollut tarpeeksi suvakki toimiessaan poliisin suljetun facebook - vihapuheryhman yllapitajana. entinen poliisin vihapuheryhman tutkinnanjohtaja marko ” fobba ” forss. helsingin poliisipaallikon lasse aapion mukaan marko forss ei voi jatkaa poliisin vihapuhetyoryhman tutkinnanjohtajana. lasse aapio. poliisiylijohtaja seppo kolehmainen on paheksuvinaan ” rasistista kirjoittelua ” ryhmassa : ” ensimmainen reaktio oli, etta onko ihmisilla niin paha olla, etta tallaista kirjoittavat? eiko ihmisilla ole muita kanavia purkaa paineita? ” seppo kolehmainen. kolehmainen korostaa, etta rasismille on nollatoleranssi. kolehmainen sanoo : ” ryhmassa ilmennyt materiaali on nyt lahtenyt valtakunnansyyttajan virastoon esitutkintaan. somekayttaytyminen kaydaan lapi ja huomenna on henkilostolle tiedossa tietoisku, jossa todetaan mita on tapahtunut, ja ilmaisen henkilokohtaisen pettymyksen asiaan. ” pyorat lahtivat pyorimaan vitunvirkkaaja johanna vehkoon lujasti kytkeytyvan longplay. fi - sivuston paljatuksista : suvakkipoliisit aikovat laittaa rasistipoliisit ruotuun lahde : yle. fi vitunvirkkaajat varmaankin juovat kuplivaa tanaan fobban paanahan kunniaksi! poliisien [UNK] rasismiryhmasta ” vasikoinut longplay. fi - sivusto on vitunvirkkaaja - vehkoon projekti t3 / mv toimitus3mv @ gmail. com [SEP]\n",
      "Predicted kritiikki ([ 1.7690334  -0.41503158 -1.5074044 ]) != real kopiointi for:\n",
      "[CLS] kaatoiko suomalainen johan backman alexander stubbin? alpo rusi pitaa mahdollisena, etta alexander stubb saattoi joutua luopumaan viime kesana kokoomuksen puheenjohtajuudesta ja valtiovarainministerin salkusta osittain dosentti johan backmanin parjauskampanjan vuoksi. – stubbille tuli noutaja kesan 2016 puoluekokouksessa. varmasti syita oli stubbissa itsessaankin, mutta vaikea on todistaa, etteiko ulosheitossa olisi ollut mukana vierasta voimanlisaa, rusi pohtii uutuuskirjassaan. keskiviikkona julkistetun yhdessa vai erikseen – suomen ja ruotsin turvallisuuspolitiikka tienhaarassa - kirjan mukaan backman leimasi stubbin cia : n agentiksi ja yhdysvaltojen etujen edistajaksi. – kokoomus teki lappeenrannan puoluekokouksessa omat ratkaisunsa. niihin minulla ei tietenkaan ole huomauttamista, vaikka itse kannatin uudeksi puheenjohtajaksi elina lepomakea, rusi sanoo. pakolaisten joukossa ehka ” illegaaleja ” suomeen on saapunut parissa vuodessa noin 35 000 pakolaista lahinna sota - alueilta syyriasta, irakista ja afganistanista. rusin mukaan pakolaisvirran mukana on saattanut tulla vieraan vallan urkkijoita. – puolan tiedustelulaitos on vaittanyt lahteisiinsa nojautuen, etta venaja on pakolaisten mukana siirrattanyt eu : n alueelle [UNK] illegaaleja [UNK], joiden tehtavana on olla [UNK] silmina ja korvina [UNK] venajan tiedustelulle. suomi on tuskin valttanyt taysin taman ilmion, rusi kirjoittaa. johan backman yle ylistaa putinia kirjassaan han arvostelee myos yleisradiota kritiikittomasta suhtautumisesta venajan vallanpitajiin. rusin havaintojen mukaan yle on esimerkiksi luonut venajan presidentti vladimir putinista urheilullisen ja hyvantahtoisen valtiomiehen kuvaa saman aikaan kuin muualla mediassa putinista on puhuttu ihmisoikeusloukkauksista tai malesialaisen matkustajakoneen alas - ampumisesta mahdollisesti vastuussa olevana valtiojohtajana. – yksi syy ylen heikkoon uutisointiin venajasta on se, etta haastateltavina on kaytetty usein aleksanteri - instituutin tutkijoita, jotka ovat aika systemaattisesti erehtyneet venajan kehityksen arvioinnissa, alpo rusi vaittaa. lahde : ilkka hartio http : / / www. ksml. fi / kotimaa / rusi - ep % c3 % a4ilee - johan - b % c3 % a4ckmanin - kaataneen - alexander - stubbin - ilja j / mv [SEP]\n",
      "Predicted kritiikki ([ 1.0200741  0.633024  -1.98328  ]) != real kopiointi for:\n",
      "[CLS] elavan lampaan teurastaminen muhamettilaisittain. ts. fi ja mtv. fi uutisoivat turun seudulla tapahtuneista bosnian muhamettilaisen miehen tekemista raaoista ja vastenmielisista rituaaliteurastuksista. mtv. fi kirjoittaa : varsinais - suomen karajaoikeus tuomitsi kuun alussa bosnialaismiehen tuntuvaan sakkorangaistukseen taman teurastettua kolme lammasta elainsuojelulakien vastaisesti ja jatettya niiden ruhot jatesakeissa ulkoilualueelle. todellisuudessa allahin nimeen brutaalisti teurastanut muslimi tuskin jatti lampaiden ruhoja jatesakeissa ulkoilualueelle. kyseessa todennakoisesti olivat lampaiden teurasjatteet! raisiossa asunut muslimi oli marraskuussa 2015 ostanut lampaat yksityishenkilolta ja teurastanut ne ulkoilmavarastossaan. muslimimies vaitti tainnuttaneensa lampaat ennen teurastusta pesapallomailalla lyomalla. se ei oikeuden mukaan ole riittava toimenpide. kokonaan toinen kysymys on, oliko pesapallomailavaite puhdasta taqiyyaa muutoinkin, koska tainnuttaminen ei kuulu uskonnolliseen halal - teurastukseen, vaan on muslimien mielesta lansimaista hapatusta. bosnialainen rituaaliteurastaja tuomittiin elainsuojelurikoksesta ja jatelain rikkomisesta 60 paivasakkoon, joka hanen tuloillaan oli 1140 euroa. lahteet : ts. fi ja mtv. fi ( ville eklund 19. 10. 2017 ) lue myos : tamperelaisen halal - lihakaupan pitaja manaa mv - lehtea – ongelma! t3 / mv toimitus3mv @ protonmail. com [SEP]\n",
      "Predicted kopiointi ([-2.2044554   1.941372   -0.11339079]) != real oma narratiivi for:\n",
      "[CLS] asikkalan vaaksyssa sijaitsevan hotellin tallukan muuntuminen vastaanottokeskukseksi on alusta saakka herattanyt tunteita. jo kattelyssa hotellin omistaja sai rakennettua ristiriitaa asukkaiden ja vok - hankkeen valille sanomalla, ettei han ole tilivelvollinen kiinteistonsa kayttotavasta. kunnanjohtaja juri nieminen kertoi joulukuun alkupuolella, etta asikkalan kunnanhallitus kasittelee tammikuussa mahdollisuutta riitauttaa vastaanottokeskuksen perustaminen. han sai tiedon tulevasta vastaanottokeskuksesta marraskuun puolivalissa sahkopostilla. [UNK] otin valittomasti yhteytta maahanmuuttovirastoon. halusin kertoa kunnan kannan paatokseen. tarjosin myos vaihtoehtoista suunnitelmaa, jossa olisimme sijoittaneet turvapaikanhakijoita hotelli tallukan sijaan kunnan vuokra - asuntoihin. on vahan eri asia ottaa muutamia perheita, kuin satoja miehia. ” silla valin tallukan asuttaminen matuilla on edennyt, ja tanaan asukkaille on jarjestetty keskustelutilaisuus. ess : n uutisointi aiheesta. ess kertoo, etta kuntalaiskeskustelu tallukan vastaanottokeskuksesta kaytiin asikkalassa vaaksyn liikuntasalissa. paikalla oli satoja kuntalaisia ja muita vastaanottokeskuksesta kiinnostuneita. kuntalaisten kysymyksiin olivat vastailemassa kotouma oy : n toimitusjohtaja lari christensen, hameen poliisin vesa okkola, tallukan vastaaottokeskuksen johtaja marko lehto ja asikkalan kunnan koulutusjohtaja juha leppialho. kunnanjohtaja juri nieminen puuttui paikalta, koska han on jaanyt pitkalle sairaslomalle. sairasloma alkoi sen jalkeen, kun mies julkaisi kantaaottavan hitler - videon siita, miten vok on paikkakunnalle junailtu. video ehti olla muutaman tunnin katsottavissa youtubessa. kiinteiston omistaja kalevi gran puuttui myos paikalta, ja huhu kertoo hanen paenneen ainakin hetkellisesti ulkomaille kuumennutta tilannetta. kiinteiston omistaja kalevi gran. ess : n mukaan suorimmin keskustelutilaisuudessa kantaa otti mies, joka kertoi perustaneensa katupartion turvapaikanhakijoiden tuloa varten. ” en tykkaa teista kotouman kusipaista yhtaan, mutta haluaisimme silti tehda yhteistyota. oletteko siihen valmiita? ” kotouman toimitusjohtajalle lari christensenille yhteistyo ess : n mukaan sopii. yhteistyotarjouksen sisalto jai selviamatta. keskustelu oli ess : n mukaan vilkasta ja kriittiset kysymykset saivat suurimmat aplodit. tallukan vastaanottokeskus on avautumassa turvapaikanhakijoille maanantaista alkaen. turvapaikanhakijat tuodaan paikalle erissa. vastustus tallukkaan perustettavaa vastaanottokeskusta kohtaan on ollut todella voimakasta. tallukasta on viety hotelliin johtavat luontoportaat – kahdesti – paikalliset ovat keranneet vastustusadressin, paikalla on pidetty mielenosoituksia ja paikka on yritetty polttaa. vastustus on synnyttanyt jopa laulun : lue myos nama : http : / / mvlehti. net / 2015 / 12 / 20 / asikkalan - tallukkaan - johtavat - portaat - on - havitetty - uudestaan / http : / / mvlehti. net / 2015 / 11 / 19 / hirvisaari - helvet\n",
      "Predicted oma narratiivi ([-3.1158495  1.1136782  1.7602552]) != real kopiointi for:\n",
      "[CLS] norjan maahanmuuttovirasto on paatynyt siihen tulokseen, etta lahtobonuksen maksaminen tulee halvemmaksi kuin turvapaikanhakijoiden hyysaaminen maan rajojen sisalla. tasta syysta norja on paattanyt ottaa kayttoonsa lahes 1083, 20 euron bonuksen, jonka turvapaikanhakija saa jattaessaan maan. kuvakaappaus : independent taman lisaksi naapurimaamme on jo valmiiksi lupautunut maksamaan 20 000 kruunun eli noin 2 166, 40 euron kannustinrahan matkalaisille, jotka paattavat jattaa maan. tunkeutujat tienaavat kaiken kaikkiaan 3 249, 60 euroa pelkastaan nayttamalla koukkunokkaansa naapurimaassamme norjassa. viime maanantaina kayttoon otettu tarjous lisabonuksesta on valitettavasti voimassa vain kuuden viikon ajan, ja paikallisen uutistoimisto nrk : n mukaan se toimii nopeimmat ensin periaatteella. lahtorahaa tarjotaan vain viidellesadalle nopeimmalle ja sen hakijan on pitanyt saapua norjaan ennen taman vuoden huhtikuuta. norjan maahanmuuttoministeri sylvi listhaug toivoo, etta lahtoraha rohkaisisi maahanmuuttajia ja turvapaikanhakijoita palaamaan heidan kotimaihinsa. hanen mukaan valtion tulisi tehda kaikkensa houkutellakseen ihmisia lahtemaan vapaaehtoisesti takaisin. raha on yksi naista keinoista, jolla tasoitetaan tieta. listhaug uskoo, etta pitkalla aikavalilla norja saastaa toimissa, silla ihmisten asuttaminen maahanmuuttokeskuksiin on kallista puuhaa, kuten norjalaisten holmolaisnaapuritkin ovat joutuneet huomaamaan. ei ole tainut pyha - sylvi asiaa loppuun asti miettia, silla mita enemman rahaa sina ryysylaisille syydat, niin sita ahkerammin he palaavat takaisin luoksesi, kun kevat taas koittaa. noin 31 000 norjaan saapuneesta turvapaikanhakijasta jopa 7 825 : n hakemus hylattiin viime vuonna. arvioiden mukaan vain kolmasosa turvapaikanhakijoista olivat syyrialaisia. tosin tamakin on tuntuvasti enemman kuin suomessa, jossa saapuvat mierolaiset ovat paaosin afgaaneja, irakilaisia ja somaleja. norjalaiset tuskin ovat ajatelleet asiaa ihan loppuun saakka, silla valtion tarjoama avokatinen lahtoraha tai kipuraha on maaraltaan suurempi kuin ihmisten vuotuiset keskiansiot esimerkiksi irakissa, afganistanissa tai somaliassa, joista valtaosa turvapaikanhakijoista tulee. kylla yli vuoden palkka varmasti houkuttelee nihkeimmatkin lahtemaan pohjolan lomakeitaaseen, jossa ei tarvitse kuin pyorahtaa, etta rahat kilahtavat tilille. kyllahan mina aina tiesin, etta norjassa rahaa on, silla juoksivathan suomalaisetkin siella kalalautoilla tienaamassa. lahi - idan ja afrikan vesselit olivat meita holmolaisia fiksumpia. mitapa sita kalan ja paskan hajussa hikoilemaan, kun helpommallakin voi rikastua. seuraavana vuonna voidaan tehda sitten sama reissu uudestaan, silla eihan heidan tuloistaan ja menoistaan pideta minkaanlaista todellista rekisteria, koska se olisi paattajiemme mielesta eettisesti epailyttavaa touhua. kannattaa pysahtya matkan varrella\n",
      "Predicted kritiikki ([ 0.8011301  -0.7752448  -0.09816813]) != real kopiointi for:\n",
      "myos ruotsiin ja suomeen, silla varmasti nyt mekin haluamme kantaa kortemme kekoon. suomesta esimerkiksi saa ilmaiset parin tuhannen euron arvoiset lennot ja taksit takaisin kotipihaan bagdadiin. muistakaa silti kayda ensin kerjaamassa norjalaisten rahat pois. tamahan alkaa muistuttamaan aivan mafiameininkia, kun turvapaikanhakijat kerailevat suojelurahaa pitkin pohjoismaita. olisikohan minunkin jo korkea aika lahtea kaymaan norjassa lomilla. vieraanvarainen naapurimme tarjoaa tayden yllapidon, jos vain muistaa mainita tuon tuhannen ja yhden yon tarinoistakin tutun taikasanan – asylum. lahteena the independent - lukijan suomennos ja mielipiteet - ilja j / mv [SEP]\n",
      "Predicted oma narratiivi ([-1.6279017   0.13157102  1.4655238 ]) != real kopiointi for:\n",
      "[CLS] lukijakuntaa on hyva muistuttaa taannoin turussa jatetysta valtuustoaloitteesta jonka kasittelyajankohta on viela taysi arvoitus. mv - media tulee seuraamaan asiaa tiiviisti, etenkin siita perspektiivista, etta jatetaanko veronmaksajien mielipiteet asiasta taas taysin huomioimatta. luultavasti nain tulee tapahtumaan, koska nain tapahtui rakkaassa suomen paakaupungissa, helsingissakin. aloite toistaiseksi koskee selvityksen muodossa, etta paperittomille ulkomaalaisille taattaisiin valttamattomat palvelut, kuten terveydenhuolto, sosiaalihuolto ja koulutus. ilmaiseksi, eli nykytulkinnassa ilmainen tarkoittaa veronmaksajia, toisaalta sita se on ollut aina. elamme kuitenkin suomessa, jossa keksittiin vaestonrajahdyksen ja ikuisten sotien ratkaisukeino – tulkaa tanne, rahaa on! aloitteen jatti vihreiden valtuustoryhman puheenjohtaja, humanistityttonen, niina ratilainen. aloitteen ovat allekirjoittaneet vihreat, rkp ja vasemmistoliitto. myos kokoomuksesta, sdp : sta ja keskustasta on allekirjoitukset. allekirjoituksen paperiin sydamien kera rustasi myos turun valtuuston puheenjohtaja, kokoomuksen lauri kattelus. hienoa, etta puheenjohtaja - tasolla sydan on lammin, joka maailman kolkkaan asti – oletan ainakin nain, koska onhan meilla tilaa ja avuntarvitsijat eivat lopu talla menolla koskaan. ei ole siis pelkoa – turun veronmaksajien rahoille on jatkossakin kayttoa, vaikka niita hieman parkkimittareista viimeaikoina onkin kavallettu – etenkin, jos asia jaa naiden edella mainittujen tahojen paatettavaksi. on kuitenkin hyvin oletettavaa, etta aanestyskayttaytyminen ei muutu myohemmassakaan vaiheessa turun valtuustossa, jossa harvalla on aivoja, puhumattakaan aidoista ja jarkevista arvoista. turkulainen. fi julkaisemassa uutisessa, koskien aloitetta, veronmaksaja paasee jopa nayttamaan mita mielta siita ollaan. tuon perusteella aloitteen voi laittaa paperisilppurista suoraan roskakoriin. taalta lisaa ja katsotaan kuinka turussa kay : turkulainen turun sanomat t1022 [SEP]\n",
      "Predicted kritiikki ([ 0.18221563  0.12151404 -0.48449087]) != real oma narratiivi for:\n",
      "[CLS] kun malmossa oli sattunut yli 100 ammuskelutapausta, poliisi paatti kaynnistaa ” operaatio olivian ”, milla kansalaiset laitettaisiin ruotuun ja rauha palaisi takaisin kadulle. nyt poliisi on arvioinut tyonsa tuloksia. tulos : malmossa ammutaan ja rajaytellaan enemman kuin ennen. vuonna 2013 varmaan kaikki malmon 30 rikollista innostuivat riehumaan. kaksi poliisin aikaisempaa erikoissatsausta oli juuri paattynyt edellisena kesana. ratkaisuksi keksittiin ” olivia ”, mika vihdoinkin ratkaisisi kaupunkia riivaavan ongelman. tuoreessa raportissa poliisi kay lapi saavutettuja tuloksia. tavoitteisiin ei ole koskaan paasty, mutta muuten satsaus on onnistunut. jos muut asiat eivat olisi sitoneet henkilokuntaa, menestys olisi todennakoisesti ollut vielakin suurempi, raportin laatijat toteavat. vuonna 2014 takavarikoitiin laittomia aseita enemman kuin koskaan aikaisemmin. 169 katosi kadulta, mutta kaupungissa esiintyvan vakivallan vaaraan silla ei nayta olleen suurempaa vaikutusta. ammuskeluja ja pommien rajaytyksia tapahtui 55 kipaletta enemman kuin edellisena vuonna. ilma tayttyi edelleen lyijysta, mika ei suinkaan ollut peraisin autojen pakokaasuista, mutta malmolaiset olivat mielissaan nahdessaan aikaisempaa enemman poliiseja kadulla. tama tiedon poliisi tosin on vetanyt hatusta, silla vaitteen takana ei ole mitaan kyselya tai vastaavaa, vaan se perustuu poliisin omaan nakemykseen siita, miten kansalaiset suhtautuvat poliisin. poliisi on yrittanyt luoda kontakteja paikalliseen vaestoon etupaassa kolmella alueella – rosengardissa, sevedissa seka holma / kroksbackissa. malmon poliisialueen varajohtaja mats karlsson oli yksi henkiloista, joita haastateltiin ennen raportin julkaisua. miksi naita ammuskeluja ja pomminrajaytyksia on tapahtunut niin paljon erikoisoperaation aikana? ” no, tama johtuu siita, etta ihmiset aseistautuvat. mutta olemme saaneet kylla monia heista kiinni ”. milta malmossa on nayttanyt erikoisoperaation aikana? ” naihin kysymyksiin on vaikea vastata. joissakin sattumuksissa tiedamme taustalta loytyvat syyt, mutta on tietaa, olisiko sattumukset tapahtuneet joka tapauksessa. siihen vaaditaan niin vahan. kyseessa voi olla tuloerot, perheiden valiset riidat tai muuta vastaavaa, mika on voinut kytea pinnan alla jo pidempaan ”. miten selitatte kaikkea tata, mita on tapahtunut viime ja tana vuonna? ” tamakin kysymys on vaikea. talla hetkella ei voi vaittaa, etta poliisin aktivoituminen olisi vaikuttanut ammuskelujen maaraan, mutta toisaalta ei voi vaittaa painvastaistakaan. tama on niin monimutkainen kuvio ja saamme vasta paljon myohemmin tietaa, miksi konflikteja sattuu. toisinaan on vaikeaa saada minkaanlaista vastausta ”. poliisin selvityksessa todetaan, etta operaatiota olisi syyta jatkaa. arvion mukaan vakivaltarikollisuus on nyt ihan yhta yleista kuin ennenkin. lukija voi itse paattaa, uskoako naihin kertomuksiin vai ei. herra torkku ei usko. talousmiehena han voisi kansanomaisesti selittaa\n",
      "Predicted kritiikki ([ 0.92921466 -0.92092943 -0.23531476]) != real oma narratiivi for:\n",
      "meille ennakkoluuloisille pottunokille, miksi kaupunki, jonka maantieteellinen sijainti on valtakunnassa paras mahdollinen, mista liikenneyhteydet keski - euroopan markkinoille ovat erinomaiset, minka vaesto on nuorta, kansainvalista, innovatiivista ja aivan uutta ajattelua ummehtuneeseen impiwaaralaisuuten tuovaa, on kaytannossa konkurssikypsa ja elaa taysin kehitysalueille tarkoitettujen tulonsiirtojen varassa? ja mita sattumuksiin tulee, ihan jokaista tussahdusta ei ole aikaa noteerata erikseen, mutta kerrottakoon tassa yhteydessa, etta viime yona sossun toimisto yritettiin rajayttaa halsjogatanilla. toissayona puolestaan rajaytettiin auto limhamnissa. molemissa sattumuksissa kaytettiin kasikranaattia. rajahdykset malmossa vuoden 2014 jalkeen. ammuskelut malmossa vuoden 2014 jalkeen. lahde : rahmispossu [SEP]\n",
      "Predicted oma narratiivi ([-0.7035041  -0.3498168   0.59720737]) != real kopiointi for:\n",
      "sisaltavan, ja tasat syysta maarat ovat suurempia. vastaajan kertomuksesta on ilmennyt, etta han oli ollut turkissa vain muutaman tunnin ylitettyaan turkin ja syyrian rajan. vastaajan mukaan han oli ilmeisesti kuormituksestaan johtuen unohtanut reseptin asunnolle, jossa han oli turkissa oleskellut. tuossa asunnossa oleskellut henkilo oli lahettanyt vastaajan pyynnosta reseptin vastaajalle. lahde : yle. fi ( sara rigatelli 18. 10 2016 ) katso myos : alan salehzadeh pitaa sdp : n rami adhamia islamistina t3 / mv toimitus3mv @ gmail. com [SEP]\n",
      "Predicted kritiikki ([ 0.9411073  0.5960687 -1.6909955]) != real kopiointi for:\n",
      "[CLS] ” jos julkisuudessa saavat puhua aina samat tyonantajan edustajat ja asiantuntijat, se vaikuttaa ajan saatossa mielipiteeseen, jonka kyseisesta tahosta muodostamme. horisontin kaventuminen ei ole vain poliisin ongelma, vaan koskee monia tyonantajia. jos rivihoitajat kertovat, etta vanhukset makaavat kaytavilla, mutta hoitolaitoksen johto kieltaa asian olevan nain, kumman totuutta uskomme? ” kysyy toimittaja saara larkio. ” vaikka asiaa ei julkisesti myonneta, on medialle kommentteja antaneita yksittaisia tyontekijoita moitittu ankarastikin lausunnoistaan. tiettyyn rajaan asti varovaisuuden voi ymmartaa, mutta koomisimmillaan toimittaja kyselee lahden ruuhkista helsingissa istuvalta paallikolta ”, kirjoittaa larkio, ja kertoo parin vuoden takaisesta tilanteesta. ” tilanteesta on jo pari vuotta aikaa, mutta se palautui mieleeni, kun luin savon sanomien uutisen laittoman varoituksen saaneesta rikoskomisariosta. olin sopinut jo hyppaavani kuvaajan kanssa tutun poliisin matkaan yhden yovuoron ajaksi repparin tekoon, paivakin oli paatetty. olin yhteydessa laitoksen johtoon, ja kerroin alustavasta sopimuksestamme. hameen poliisilaitoksen johto halusi kuitenkin vaihtaa keikalle tulevat miehet. juttu voitaisiin tehda vain, jos laitos saa paattaa, ketka kyyditsevat toimittajaa. nain siita sopimuksesta huolimatta, etta laitoksen johto saisi lukea jutun ennen julkaisua. ” ” laitoksen poliisipaallikko tapio saarni ei ota suoraan kantaa siihen, miksi poliisit vaihdettiin juttukeikalle, mutta kertoo sahkopostissaan, etta yksittaisen poliisimiehen sananvapautta ja poliisinlaitoksen viestintaa voi ja useassa yhteydessa on tarkasteltava erikseen. ” ” maailma tuskin jarkkyi poliisien vaihtumisesta repparikeikalla, mutta jutusta olisi tullut aivan erilainen alkuperaisella miehityksella, koska tuttavani on suorasanainen mies ”, kirjoittaa larkio. journalistiliiton lakimiehen sanna nikulan kanta sananvapausasiaan on selva : ” jos viranhaltijat eivat saa kritisoida sen yhteison toimia, jonka palveluksessa he ovat, minkalainen tama yhteiskunta olisi? ei ainakaan demokratia ”, han sanoo. lahde : ess [SEP]\n",
      "Predicted kritiikki ([ 0.86670196  0.152904   -1.1905899 ]) != real oma narratiivi for:\n",
      "solidaarisuuden osoituksena rasistin pahoinpitelysta. muutaman paivan oyhkaamisen jalkeen juttu laukesi ja totuus paljastui, kun eras muslimimies soitti radion suoraan lahetykseen ja kertoi pahoinpitelyn oikeat taustat. fatima doubakil oli siis mukana keksimassa juttua, tekorasismia. ihailee avoimesti osama bin ladenia. tallaiset henkilot ovat siis mukana ruotsin islamisoittamisessa. molemmat tyypit ovat kayttaneet jo vuosia samaa taktiikkaa islamisaation tunkemisessa yhteiskuntaan : he keksivat kaiken maailman juttuja rasismista ja sen sellaisesta, vaikka itse aivan avoimesti puhuvat vaarauskoisten veriloylyista. ruotsalaisten ongelma taas on se, etta he eivat rasismileiman pelossa uskalla sanoa naillekaan tyypeille ei kiitos. lahde : paavo tajukangas [SEP]\n",
      "Predicted oma narratiivi ([-0.30081362 -0.81330794  0.64912003]) != real kopiointi for:\n",
      "ei - edes - eroteta - koulusta / [SEP]\n",
      "Predicted kritiikki ([ 1.1165872 -2.2452672  0.6627735]) != real oma narratiivi for:\n",
      "koululaisten pisa - tulokset ovat laskeneet viime vuosina halyttavasti myos suomessa. ilmion vakavuudesta kertoo se, etta jopa kehitysmaalaisten maahanmuuttoa suosinut helsingin sanomat taipui kirjoittamaan tasta yhteiskunnallisesta tosiasiasta jutussaan ” pisa - tutkimus : maahanmuuttajien tulokset huolestuttavat suomessa ”. saman ovat todenneet myos koulujen opettajat. tulokset ovat laskeneet vuodesta 2006, jolloin maahanmuuttajien maarat alkoivat nousta peruskouluissa. olli ainola. myos iltalehti tuo omalla tavallaan valoa asiaan. olli ainolan kirjoittamassa jutussa opetusneuvos ulla laine opetushallituksesta sanoo, etta ” oppilaiden osaamiserot kasvavat aidinkielessa ”. ulla laine. yliopistonlehtori venla bernelius taas lausuu, etta ” [ u ] usi huono - osaisuus puolestaan paikantuu kaupunkiseutujen heikkeneville alueille ”. hanen mukaansa ” hyvaosaiset perheet hakeutuvat pois ongelmallisiksi leimautuneista naapurustoista ja kouluista ”. venla bernelius. nama sosioekonomiset selitystekijat muistuttavat vahvasti maahanmuutosta johtuvista ongelmista, jotka helposti paljastuvat heikon opintomenestyksen syiksi ja ovat johtamassa koululaitoksen halkeamiseen. silti selitysta ei loydeta eika paikanneta oppilasaineksen muutokseen, vaan sita haetaan jatkuvasti jarjestelmasta, ja keskitytaan osoittamaan vain maahanmuuttopolitiikan hallinnollisia seurauksia. lehtori berneliuksen mukaan ” [ m ] uuttoliike eriyttaa naapurustoja, ja toisaalta vapaa kouluvalinta muuhun kuin omaan lahikouluun voi kiihdyttaa koulujen valista eriytymista. ratkaisu tilanteeseen ei ole yksiselitteinen. kansainvalisesti on esimerkiksi osoitettu, etta kouluvalintojen taydellinen kieltaminen ruokkii useissa tapauksissa asuinalueiden valista eriytymista, kun paikka halutusta koulusta – tai torjutun koulun valttely – varmistetaan muuttamalla. ” taman mukaan syyt tiettyjen koulujen ja alueiden vajoamiseen johtuisivat tiettyjen asukkaiden pakenemisesta maahanmuuttajalahioista, jolloin syyllisina tason laskuun esitetaan ongelmalahioista kaikkovat parempitasoiset oppilaat. on muistettava, etta kytkintaan ovat nostaneet nimenomaan kantavaestot, joten vikaa voisi hakea noihin ” torjuttuihin kouluhin ” jaaneesta vierasperaisesta oppilasaineksesta. mita kouluissa sitten tehdaan? pari vuotta sitten helsingin sanomat ja ilta - sanomat iloitsivat, etta jokainen yhdeksasluokkalainen saa chimamanda ngozi adichien kirjoittaman feminismikirjan nimelta ” meidan kaikkien pitaisi olla feministeja ”. chimamanda ngozi adichie. tama ruskeiden tyttojen propagoimiseen tahtaava kulttuurimadatys ei voi olla vaikuttamatta suomalaisten poikien koulunkayntihalukkuuteen, joten poikien heikommaksi vaitettya opintomenestysta voidaan selittaa koulumaailmaa leimaavalla taysfeminismilla, jonka tuloksena naisopettajattarien korkokenka polkee miesten kulkusia. koska suuri osa koulujen opetuksesta on pelkkaa feministi\n",
      "Predicted kritiikki ([ 1.9282613 -3.17432    0.8543799]) != real oma narratiivi for:\n",
      "##sta aivopesua, jossa poliittinen korrektius, monikulttuurisuus ja maahanmuuton suosiminen on nostettu loogisen ajattelun edelle, ei tarvitse ihmetella, miksi menestys alya vaativissa oppiaineissa, kuten matematiikassa, fysiikassa ja muissa luonnontieteissa, floppaa. voidaankin kysya, kuinka viisasta on ollut paastaa feministiset naisasianaiset paattamaan valtionpolitiikkaan liittyvista asioista ja sita kautta ratkaisemaan kansakuntamme kohtalonkysymyksia, jotka riippuvat ennen muuta vaestopoliittisista valinnoista, maahanmuuttopolitiikasta ja kansakuntamme etnisesta rakenteesta. chimamanda ngozi adichien indoktrinaatio - oppaan sijasta opetus - ja kulttuuriministerio, jyvaskylan yliopisto ja niiden kanssa kimpassa olevat tahot olisivat voineet jakaa peruskoulun yhdeksasluokkalaisille 100 000 kappaletta kirjaani ” kansallisfilosofinen manifesti – tie tulevaisuuden suomeen ”. valkoisen vaeston syrjayttamiseen ja omiin kouluhinsa ghettouttamiseen johtava ongelma on globaali. kyseessa ovat alkusoinnut politiikkaan, jonka tuloksena lansimaiden kantavaestot suljetaan ennen pitkaa omiin reservaatteihinsa entisissa kotimaissaan. samalla, kun yleisradio viettaa jatkuvaa nenapaivaa, jossa tuskaillaan afrikkalaisten ja muiden kehitysmaalaisten auttamisen puolesta, helsingin sanomat julkaisee vitsikkaan uutisen, jonka mukaan 15 000 tieteenharjoittajaa ovat huolissaan joukkotuhosta ja varoittavat, etta ” pitkaan jatkunut vaestonkasvu on syy moniin ekologisiin ja yhteiskunnallisiin uhkiin ”. mina olisin huolissani siita, etta vasta nyt niin sanottu tiedeyhteiso kakaisee kurkustaan tuollaisen itsestaanselvyyden, jonka kuka tahansa pulliainen on voinut todeta jo 1970 - luvulta asti. pitaako siis noita vaestonkasvustaan piittaamattomia afrikan ja kaukoidan kehitysmaita jatkuvasti ruokkia, kun syyna niissa asuvien perhepoliittiseen kurjuuteen ovat heidan omat valinpitamattomat valintansa? tyhminkin ihminen varmasti tietaa, milla tavoin jalkelaisia tehdaan tai ei tehda, joten syy heidan tukalaan todellisuuteensa on heidan itsensa. mathieu cherchel. idiootinkin luulisi ymmartavan myos sen, milla tavoin jalkelaisia pitaa kohdella ja mita vastuu merkitsee. siita ranskan kansalaiseksi mainostetun mathieu cherchelin tekema, omaan lapseensa kohdistunut murha, ei anna hyvaa esimerkkia – ei myoskaan norsunluurannikkolaisen seydou kouandan tapa kohdella tytartaan. seydou kouanda. asia ei tule paremmaksi, vaikka punavihrea madattajamedia kuinka yrittaisi vaieta myos porvoon surmaajan etnisesta taustasta ja selittaa hanen tekonsa ” huoltajuuskiistasta ” johtuvaksi tai ” harvinaiseksi ” tapaukseksi. tosiasiassa faktapohjainen tilastoinformaatio valaisee, etta afrikkalaistaustaiset kehitysmaalaiset tekevat suomessa moninkertaisesti vakivaltarikoksia kantavaestoon verrattuna ( oikeuspoliittisen tutkimuslaitoksen tilasto tassa, yliopiston tassa ja poliisin tassa ), ja\n",
      "Predicted oma narratiivi ([-1.0734221   0.24692723  0.6358335 ]) != real kopiointi for:\n",
      "[CLS] vastavalkea - media kirjoittaa : bulgarialainen trud newspaper - sanomalehti on julkaissut artikkelin : ” 350 diplomatic flights carry weapons for terrorists ” kaukasuksen ja ita - euroopan maiden kautta kulkevasta cia : n valvomasta asesalakuljetusreitista. artikkelin mukaan azerbaidzanin valtion omistamaa silk way airlines - lentoyhtiota kaytetaan saannollisesti ” diplomaattisuojattujen ” ja siten verovapaiden aselastien salakuljettamiseen saudi - arabiaan, yhtyneisiin arabiemiirikuntiin ( uae ) ja turkkiin, mista ne jatkavat matkaansa varsinaiselle vastaanottajalle. asesalakuljetus on osa cia : n valvomaa ohjelmaa, jonka kautta aseistetaan syyrian laillista hallitusta vastaan taistelevia palkkaterroristeja. jo aiemmin on tutkittu silk way airlinesin osallisuutta asekuljetuksiin saudi - arabian jemenissa kaymaa sotaa varten. osana artikkelia julkaistiin hakkeroitua, vuodettua kirjeenvaihtoa seka sisaisia muistioita, jotka vaikuttaisivat olevan bulgarian ulkoministerion ja azerbaidjanin sofiassa, bulgarian paakaupungissa, sijaitsevan lahetyston valisia. kirjeenvaihdon mukana on liitteena tarvittavat asiakirjat, joilla lentokenttamuodollisuudet hoidetaan diplomaattisuojauksen alla. asiakirjojen perusteella silk way airlines on tarjonnut asesalakuljetuspalvelua yksityisille asevalmistajille ja eri maiden armeijoille kuten saksan ja tanskan armeijoille, ruotsin irakissa oleville joukoille seka yhdysvaltain armeijan erikoisjoukoille ( ussocom ). aseiden kuljettaminen siviili - ilmailuun tarkoitetuilla lennoilla ilman kansainvalisen lentorahtiliitto iata : n antamaa lupaa on laitonta. tassa valittajana toimi azerbaidzanin ulkoministerio, joka haki – ja sai – lupia aseiden ja ammusten kuljettamiseen mm. bulgarialta, serbialta, romanialta, tsekin tasavallalta, unkarilta, slovakialta, puolalta, turkilta, kreikalta, saksalta, isolta - britannialta jne. niinikaan aseita on kuljetettu bosnia - herzegovinan ja kroatian kautta. suurimpia silk way airlinesin asiakkaita ovat olleet amerikkalaisyritykset – mm. purple shovel, orbital atk, culmen international lcc, chemring military products, alliant techsystems operations – joista osalla on alihankintasopimuksia yhdysvaltain armeijan kanssa seka yhdysvaltain armeija. amerikkalaisten puolesta kuljetetut aseet ovat olleet amerikkalaiseen standardiin sopimattomia ( non - u. s. standard ), joten aseita ei ollut tarkoitettu yhdysvaltain armeijain joukoille. eras tunnettu asesalakuljetusreitti toimii nato : n rauhankumppaniohjelman jasenen valko - venajan kautta. trud newspaperin artikkelin kirjoittaja dilyana gaytandzhieva sai myos vuoden 2016 joulukuussa taltioitua filmille yhdeksan al - nu\n",
      "Predicted oma narratiivi ([-0.04159863 -1.003976    0.8576797 ]) != real kopiointi for:\n",
      "##sra front - terroristijarjeston maanalaista varastoa taynna bulgariasta saapuneita aseita. lansimaisen arvoyhteison ja jihadistien valinen liitto on pitkaan ollut tunnettu. eri maiden hallitusten lainrikkomuksia paljastaneen gaytandzhievan kuulustelemisesta ja tyopaikastaan erottamisesta on jo huolehdittu. ensisijainen lahde : gaytandzhieva, dilyana [UNK] trud newspaper ( 02. 07. 2017 ) : 350 diplomatic flights carry weapons to terrorists https : / / trud. bg / 350 - diplomatic - flights - carry - weapons - for - terrorists / lahde : vastavalkea mv - lehden toimitus [SEP]\n",
      "Predicted oma narratiivi ([-1.4852235   0.25600624  1.3459908 ]) != real kopiointi for:\n",
      "[CLS] yle [UNK] s editor - in - chief and head of news and current affairs atte jaaskelainen has left the national broadcaster. jaaskelainen was under a lot of pressure to resign after it became obvious he was the key player in so called ylegate centred on reporting of prime minister juha sipila [UNK] s potential conflicts of interest. in a press release issued monday afternoon, yle announced that the company [UNK] s board, chief executive lauri kivinen and editor - in - chief atte jaaskelainen had agreed that jaaskelainen would leave his job at the national broadcaster with immediate effect. atte jaaskelainen. the release stated that jaaskelainen ” no longer had the prerequisite to successfully manage his role ” as editor in chief and head of news and current affairs. the board has named svenska yle director marit af bjorkesten as director and head of news and current affairs with effect from 1 june, while editor riikka venalainen will temporarily hold the editor - in - chief position until the beginning of june. the company said it will begin the search for jaaskelainen [UNK] s successor immediately. ” i believe that yle [UNK] s role in society is more important than my role in yle. my aspiration to lead yle [UNK] s news and current affairs department in responsible journalism has come under suspicion. i hope that our decision helps restore a stable working environment, ” jaaskelainen said on monday. key role in ” ylegate ” jaaskelainen was the central figure in a series of media reports about freedom of speech at the national broadcaster – dubbed ” ylegate ” – after claims that the editor - in - chief had bowed to political pressure when he muzzled reports on stories about potential conflicts of interest by prime minister juha sipila late last year. these claims were later back\n",
      "Predicted oma narratiivi ([-1.5236132   0.37336668  1.2042518 ]) != real kopiointi for:\n",
      "##ed by an independent investigator commissioned by yle to review the case. in march, the self - regulating council for mass media ruled that prime minister juha sipila had curbed freedom of speech when he bombarded journalists with emails complaining about an yle conflict - of - interest story. subsequently atte jaaskelainen made the decision to scale back yle [UNK] s coverage of the story. after several journalists resigned over what many saw as censorship, jaaskelainen refused to step down and kivinen affirmed his support for the editor - in - chief. now, after weeks of pressure, jaaskelainen finally decided to resign. source : yle t12 / mv toimitus12mvrebel @ gmail. com [SEP]\n",
      "Predicted oma narratiivi ([-0.83615553  0.0943555   0.42151573]) != real kopiointi for:\n",
      "[CLS] rami adham erosi, ainakin muodollisesti, itse. mahdollisesti asia oli sovittu puoleen sisalla niin tapahtuvaksi : jihadisti rami adhamista tuli ongelma sdp : lle – adham erosi aamulehti. fi uutisoi sdp : n puheenjohtajan antti rinteen sanoneen rami adham - jihadistiyhteyksista : ” asia on loppuun kasitelty ” antti rinne. sdp : n puheenjohtaja antti rinne ei suoraan kommentoi sita, miten adhamin tapaus on vaikuttanut sdp : n maineeseen. antti rinne kommentoi : ” totean vain, etta sdp : n osalta asia on loppuun kasitelty. ” kun rinne puolueen puheenjohtajana ja siten puolueen suuna vaittaa, etta jihadisti rami adham - kausti on sdp : n osalta loppuun kasitelty, niin se tarkoittaa sita, etta ainakaan julkisuudessa asian kasittelya ei edes aloiteta. loppui ennen kuin ehti alkaa! lahde : aamulehti. fi t3 / mv toimitus3mv @ gmail. com [SEP]\n",
      "Predicted kopiointi ([-1.2403824   1.2199184  -0.41213685]) != real oma narratiivi for:\n",
      "[CLS] yk : n siirtolaisjarjesto iom on julkaissut massasiirtolaisuutta markkinoivan propagandavideon, jossa ei enaa puhutakaan pakolaisista vaan siirtolaisista. videon mukaan 244 miljoonaa siirtolaista on jo liikkeella. videolla afrikasta eurooppaan suuntautuvaa massamaahanmuuttoa markkinoidaan ” vaistamattomana ”, ” valttamattomana ” ja jopa ” himoittavana ” ( desirable ). propagandavideo on linjassa yk : n jo vuonna 2000 julkaiseman raportin kanssa. siina vaitettiin euroopan – ja myos japanin – tarvitsevan massamaahanmuuttoa afrikasta, koska euroopan maiden syntyvyys on laskenut. samanaikaisesti kantavaeston syntyvyyden edistamiseksi ei ole tehty juuri mitaan. moni on aivopesty ajattelemaan, etta paras ilmastoteko on jattaa lapset hankkimatta. esimerkkina helsingin sanomien artikkeli 19. 7. 2017 : ” ilmastonmuutoksen takia kannattaisi jattaa lapset tekematta, mutta onko se liikaa vaadittu? katja hintikainen mietti pitkaan, voiko han synnyttaa lisaa kuluttajia maailmaan ” ” helsinkilainen katja hintikainen mietti pitkaan, milla oikeudella han voi synnyttaa lisaa kuluttajia jo valmiiksi ylikulutuksesta karsivaan maailmaan. ” lahteet : youtube / henna kajava, wnd. com, yk t12 / mv toimitus12mvrebel @ gmail. com [SEP]\n",
      "Predicted kopiointi ([-1.1866155   0.59451854  0.47850087]) != real oma narratiivi for:\n",
      "turvapaikanhakijoiden elattamiseen olisi sopinut kansantaloustieteen laskelmiin suurempanakin asiana kuin lyhyena huomautuksena joihinkin ” paaosin lyhytaikaisiin ” kustannuksiin. ” maahanmuuttajat syrjayttavat ainoastaan heikoimmin koulutettuja natiiveja ” engdahl liittyy povattuun unelmaan, jossa ” maahanmuutto parantaa kilpailukykya, kasvattaa ulkomaankauppaa, vahvistaa yrittajyytta seka lisaa tyomarkkinoiden joustavuutta ”. ” tyomarkkinoiden joustavuus ” on naissa onnen ja rikkauden povauksissa avain kasite. ” heikosti koulutetut maahanmuuttajat syrjayttavat ainoastaan kaikkein heikoimmin koulutettuja natiiveja ”, engdahl vetoaa wellesley collegessa vanhempana tutkijana tyoskentelevaan sari pekkala - kerriin. ” syrjayttavat ainoastaan kaikkein heikoimmin koulutettuja natiiveja ” on kivasti ilmaistu julma rahanteon lause. siina kirjoitetaan ” natiiveja ”, koska ei tohdita lausua, etta syrjaytetyt ovat ” kantasuomalaisia ”. ” maahanmuutto lisaa tyomarkkinoiden joustavuutta ” matalapalkkaisten koyhien kantasuomalaisten syrjayttaminen ei ole engdahlin mukaan paha, vaan suorastaan upea juttu : ” maahanmuutto [ [UNK] ] lisaa tyomarkkinoiden joustavuutta. ” ” tyomarkkinoiden joustavuus ” syntyy maahanmuuttajien ansiosta matalapalkka - aloille, kun ja jos kantasuomalaiset eivat ole suojaamassa edes viimeisia sopimusten mukaisia tyooikeuksiaan. tuntipalkka laskee. engdahl ei povauksessaan ota huomioon lainkaan suomessa karsittavaa valtavaa tyottomyytta. sen sijaan han murehtii : ” tyoikaisten maara suomessa vahenee runsaalla 10 000 henkilolla vuosittain pari seuraavaa vuosikymmenta, jos maahanmuuttajien maara ei kasva. ” eurooppaan tulleita laittomia siirtolaisia. mika ongelma on tyoikaisten maaran vahentyminen tilanteessa, jossa vallitsee ja on odotettavissa valtava tyottomyys? ongelma on ainoastaan tyoehtojen joustavuuden kannalta kansantaloustieteen matematiikan valossa : jos saatavalla olevaa joutilasta tyovoimaa ei ole ylen maarin, silloin tyontekijoiden neuvotteluvoima tyoehdoista parantuu. jos tyottomyys on suuri, silloin tyonantaja sanelee ehdot ja tyonhakija vikisee. suomessa vuonna 2014 afrikan valtioiden kansalaisten maahanmuuttajien tyottomyysaste oli 42 prosenttia. jo vuoden maassa asuneiden maahanmuuttajien – taustoista riippumatta – tyollisyysaste oli tilastokeskuksen mukaan 41 %. tassa valossa engdahl povaa tosi vahilla perusteilla maahanmuuttajien tuovan suomeen onnea ja rikkautta – rakkautta ja lapsia varmasti syntyy. engdahl vetoaa toiseen povariin : terveyden ja hyvinvointilaitoksen tutkija kaarina reini simuloi, etta ilman maahanmuuttajien tyopanosta suomen bkt laskisi 2, 9 – 3, 4 miljardia euroa pitkalla aikavalilla. engdahl liittyy reinin kauniiseen lupaukseen : ” maahanmuuttajat ovat paaosin parhaassa tyoiassa olevia, 20 - 34 – vuotiaita henkiloita. ” engdahl paatyy paratiisin porteille suomen pankin juuso vanhalan oivalluksen avulla niin, etta nama tyoiassa olevat mamut tyollistyvat ja suomesta tulee pohjantahden alle oikea paratiisi,\n",
      "Predicted kopiointi ([-1.1155558   1.0802413  -0.05954411]) != real oma narratiivi for:\n",
      "jos palkat tiputetaan alemmaksi : ” maahanmuuttajien heikompi tyollistyminen johtuu myos tyomarkkinoidemme jaykkyyksista. suomessa on vahan matalan tuottavuuden tyopaikkoja ja suhteellisen korkea minimipalkkataso. ” ” korkeat sisaantulopalkat ovat haitallisia maahanmuuttajien tyollistymiselle ja korkea minimipalkka hinnoittelee monet vahan koulutetut maahanmuuttajat ulos tyomarkkinoilta. ” ” maahanmuutto on suuri mahdollisuus ”, kuten paastrategi vesa engdahl lausuu. ” nyt kaivataan entista aktiivisempaa maahanmuuttopolitiikkaa. ” haittamaahanmuutolla on seurauksensa. enta jos ” korkeat ” minimipalkat pudotetaan todella alemmiksi? jos pankin povaria on uskominen, niin suomen onni ja rikkaus tulevat siita, kun korkeat minimipalkat tiputetaan alemmaksi. engdahl ei kerro konkreettisia eurohintoja, koska hanen 120 000 euron vuosiansioillaan ei euroa ajatella enaa samalla tavalla. tosielaman tasolla matalapalkka - alojen ” korkeat minimipalkat ” tarkoittavat kantasuomalaisten siivoojien 9 euron tuntipalkkaa bruttona, mika olisi pankin povarin mukaan aivan liian korkea minimipalkka suomen menestykselle. kun postin uudet postinjakajat eivat osaa suomea, ruotsia eika englantia, kuten viikko sitten keravalla pikahalytyksella palkattiin uuttera tumma mies toihin postiin, niin nama jakavat perjantaina jakamattomaksi jaaneet paivapostit ( osoitteita ihmisilta kysyen ja etsien, jos loytavat yhteisen afrikkalaisen murteen ) viela lauantaina ja sunnuntaina. tuntipalkka voidaan tiputtaa minimin alle myos kellottamalla jakopiirit entista kiireellisemmiksi. vantaan sanomissa 9. 4. 2016 kerrottiin uudet tilastotiedot : vantaan lansimaessa 52 % lapsista elaa pienimpaan tuloluokkaan kuuluvissa perheissa. viela pari vuosikymmenta sitten heidan osuus oli lansimaessa vasta 17 %. pankin povarin mukaan isien ja aitien minimipalkat ovat kaikista koyhista lapsista huolimatta liian korkeat. lahteet : fim lounge, fim engdahl, iltalehti, vantaan sanomat 9. 4. 2016 mv - lehti : ” valtioneuvosto : jokainen turvapaikanhakija maksaa veronmaksajille 5 833, 30 kuukaudessa! ” t9 / mv toimitus9mv @ gmail. com [SEP]\n",
      "Predicted oma narratiivi ([-2.810615    0.79049194  1.7495775 ]) != real kopiointi for:\n",
      "[CLS] nama sitaatit eivat ole poimintoja finnairin akkilahtotarjouksista. ne ovat peraisin arabiankieliselta ” matkusta ja hae turvapaikkaa ruotsista ” - facebook - sivustolta, jolla on perati 34 000 tykkaajaa. ammattimaisesti toteutettu sivusto tarjoaa turvapaikkapalveluita varsin avoimesti. – hanki viisumi, jolla paaset beirutista ruotsiin. saat viisumin lailliselta turistimatkoja jarjestavalta yritykselta. ensin haastattelu suurlahetystossa, sen kahden ja puolen kuukauden odotusaika. kun saat viisumin, voit matkustaa silla ruotsiin. kun olet perilla, voit hakea turvapaikkaa valittomasti. hinta : 15 000 dollaria, sivusto lupaa. sama taho jarjestaa myos matkoja istanbulista ruotsiin, norjaan tai tanskaan. tarpeelliset matkustusasiakirjat maksavat 10 000 euroa. hollantiin tai saksaan paasee 9 500 eurolla, ranskaan tai itavaltaan 9 000 eurolla. – istanbulista italiaan : 6 000 dollaria. lapset puoleen hintaan. lahdot perjantaina tai lauantaina. – hae vuoden maaraaikaista tyopaikkaa unkarilaisesta tai puolalaisesta suuryrityksesta. mahdollisuus matkustaa junalla saksaan ja hakea siella turvapaikkaa. 10 000 euroa. laivalla turkin mersin kaupungista kreikkaan. ei matkatavaroita mukaan. 7 000 dollaria. matkakauppiaat avustavat asiakkaitaan ja lupaavat heille neuvoja rajanylitystilanteisiin, jotta valvovien viranomaisten epailykset eivat heraisi. sivuston yllapito pyytaa, etta vain tosissaan liikkeella olevat ottaisivat yhteytta koska heilla on niin paljon ruuhkaa. yllapito ilmoittaa myos, etta he saavat paivittain 500 yhteydenottoa. reteasti valimeren reittia – eurooppa odottaa sinua, lupailee toinen facebook - sivusto. sivustolla tarjotaan libyasta lahtevia venematkoja eurooppaan. unelmia heratellaan luksusjahtien valokuvilla ja hymyilevan, passeja pitelevan pariskunnan valokuvilla. reitti lahtee joko libyan paakaupungista tripolista tai pienemmasta bengasin kaupungista. ” tartu tilaisuuteen ja varaa paikkasi. tavoitteemme on sinun turvallisuutesi! ” jos mainoskuvaa on uskominen, matka taittuu reteasti okyjahdin kannella. ja vaikka kulkuvalineisiin ei oikeasti olisikaan panostettu, niin mainoskuviin on. hienoilla valokuvilla maalataan kuvaa seesteisen ja vauraan pohjoisen yltakyllaisyydesta. kissaa ja hiirta somessa facebook tai muut sosiaalisen median jatit eivat ole innostuneita tarjoamaan verkkopalveluita jarjestaytyneille rikollisille. niinpa ihmissalakuljettajien sivustoja poistetaan verkosta sita mukaa kun niita sinne ilmestyy. uusia ilmestyy kuitenkin nopeasti poistettujen tilalle. monilla sivustoilla yllapitajat vaativat, etta kaikki yhteydenotot tehtaisiin pelkastaan facebook - viestein eika julkisin kommentein. taman takia suuri osa turvapaikkaturismin ymparilla kaytavasta verkkokeskustelusta jaa piiloon. mutta senkin perusteella mita on julkisesti nakyvilla, voidaan saada kasitysta ilmion massiivisesta mittakaavasta. silja linen laivoilla pohjolan paratiisiin hammastyttavaa markkinointiosaamista on myos sen\n",
      "Predicted oma narratiivi ([-3.0837853  1.3405994  1.5931149]) != real kopiointi for:\n",
      "sivustolla, jossa tarjotaan ylellisia ihmissalakuljetuspalveluita kaikille suomalaisille tutulla silja serenadella. sivusto on sittemmin poistettu facebookista, mutta kuva on edelleen tallella guardian - lehden ihmissalakuljetusta kasittelevassa artikkelissa. muitakin suuria seilaajia on valjastettu mielikuvamyyntiin. international business times kertoo sivuillaan salakuljettajista, jotka markkinoivat valimeren ylitysta rouheilla valtameriluokan aluksilla. monet tuhansien eurojen matkalipun ostaneet ovat pettyneet katkerasti nahtyaan, etta tarjolla onkin ollut kiikkera kumivene. hengenvaaralliselle matkalle lahdetaan silti. blogeista turvapaikkaohjeita lyhyella googlaamisella loytaa verkosta arabiankielisia sivustoja, joissa opastetaan kadesta pitaen turvapaikan hankintaprosessissa. helpoin tapa paasta ruotsiin – blogikirjoituksessa kasitellaan useita tapoja, joilla saada maasta oleskelulupa. keinoja on monia, osa helpompia ja osa monimutkaisempia. opiskelu ruotsissa on yksi keino. maahantulo turistiviisumilla ja naimisiinmeno on toinen. puolisoa voi etsia joko tavallisin keinoin tai sitten sellaisten ihmisten joukosta, jotka myyvat puolisopalveluita. sivusto varoittaa siita, etta tallaiset ” aviopuolisot ” saattavat kiristaa kumppaniaan. tilanne houkuttelee tahan – mikali side ” puolisoon ” katkeaa, myos maassaolon peruste poistuu. toisena keinona mainitaan niin ikaan turistiviisumilla maahantulo, ja heti maahantulon jalkeen haetaan turvapaikkaa joko poliittisin tai humanitaarisin syin. mikali hakemuksessa on maininta pakottavista syista ja kotimaassa odottavasta kuoleman uhasta, on silla mahdollisuus menestya. paras maa – ruotsi parhaat maat turvapaikanhakijoille – blogissa on listattu turvapaikanhakijan kannalta houkuttelevimmat maat. ne ovat paremmuusjarjestyksessa : ruotsi, saksa, norja, itavalta, hollanti, tanska. kuvaan keltaisella merkityt maat koetaan blogin mukaan houkuttelevimmiksi. ruotsi vetaa pisimman korren muun muassa tulijoille jakamansa avokatisen taloudellisen tuen ansiosta. suomi ei ole talle listalle paassyt, mutta sivuston yllapitaja lupailee kommenttipuolella, etta maa otettaisiin jatkossa mukaan vertailuun. lahde ; https : / / www. suomenuutiset. fi / ei - ihme - etta - valimerella - kay - kuhina - laitonta - maahanmuuttoa - pyorittaa - ammattimainen - markkinointikoneisto / [SEP]\n",
      "Predicted kopiointi ([-1.5898194  2.6074233 -1.174141 ]) != real oma narratiivi for:\n",
      "[CLS] etela - saimaa kirjoittaa seuraavaa : lahes sata sotiemme veteraania ei paassyt hakemaansa kuntoutukseen etela - karjalassa viime vuonna. syyna on valtion maararahan niukkuus. tukirahat ovat vahissa muutenkin, kertoo veteraanineuvoja sanna nurmiainen eksotelta. kotiin annettavia tukipalveluita ei voida myontaa rahapulan takia laheskaan kaikille tarvitsijoille. jonossa on tallakin hetkella liki 50 veteraania. tilanne harmittaa veteraanineuvojaa. hanesta palvelu pitaisi myontaa veteraanin tarpeen, eika maararahan riittavyyden mukaan. ” aina veteraanille etsitaan se apu mita han tarvitsee, mutta maksajana on liian usein veteraani itse ”, nurmiainen toteaa. siina missa suomeen elintasopakolaisena tullut matu saa kaiken tarvitsemansa avun, niin suomen rakentanut sotaveteraani jaa vaille apua. suomen valtio asettaa maahantunkeutujat suomen itsenaisyyden puolesta taistelleiden omien kansalaisten edelle. tama kertoo kiistatta siita, etta nykyhallitus on taysin epaisanmaallinen, ja osoittaa ajattelua, jossa sotaveteraanin arvostus on pienempaa kuin maahantunkeutujan. tata on mahdotonta ymmartaa. ilman veteraaneja ei olisi suomea, mutta nykyinen hallitus ei arvosta patkan vertaa isanmaata, suomalaisia arvoja tai nykyisen suomen rakentaneita veteraaneja. pikemminkin tavoitteena on tuhota suomi massamaahanmuutolla. jos tilanne on se, etta rahaa riittaa joko veteraaneille tai matuille, niin jokainen isanmaallinen paattaja antaa rahaa veteraaneille, ja jattaa antamatta sita matuille. lahteet : etela - saimaa, iltalehti lukija t2 / mv toimitus2mv @ gmail. com [SEP]\n",
      "Predicted oma narratiivi ([-0.07360029 -0.2621525   0.21436359]) != real kritiikki for:\n",
      "tulevia maahanmuuttajia ei voitaisi paastaa suomeen. huhtelan tviittaus on milla tahansa kriteereilla politikointia. se on myos maalittamista ja vihanlietsontaa toisella tavalla ajattelevia kansalaisaktivisteja kohtaan. ennen kaikkea se on poliisin toiminnan parodiointia ja naurunalaiseksi tekemista, silla poliisin virkatehtaviin ei kuulu ottaa poliittisesti kantaa ja maalittaa toisinajattelijoita. toimittajan kommentti poliisilta pitaa voida vaatia lain noudattamista hanen suorittaessaan virkatehtavia. demokraattisessa, avoimessa yhteiskunnassa pitaisi olla itsestaan selvaa, etta kansalaisella on oikeus saada tietaa hanelle kaskyja tai pamppua antavan poliisimiehen nimi, jotta vaaryyksista voi valittaa. poliisilta pitaa voida vaatia tavanomaista mallikelpoisempaa kaytosta myos virka - ajan ulkopuolella : kansalaisaktivisteja kannissa uhkailevaa poliisia tulisi ehdottomasti rangaista. nollatoleranssi kansalaisten uhkailulle ja maalittamiselle ja poliisin politikoinnille! lahteet : helsingin sanomien nyt - liite, suomen laki t12 / mv toimitus12mv @ protonmail. com [SEP]\n",
      "Predicted oma narratiivi ([-1.11269     0.26668173  0.79372305]) != real kopiointi for:\n",
      "[CLS] suomen sahkon aluehintojen erot lahtivat kasvmaan viime kesan alusta muun pohjolan tasosta. nyt kaymassa samoin. tanaan kello 9 - 10 valilla verrattuna ruotsiin, suomen sahkon hinnassa oli 230 % suomi - lisaa. lannessa sahkon tukkuhinta on alle 38 euroa / megawattitunti, niin suomessa 125 euroa. sahkon tuntihinnat vaihtelevat, mutta vuorokauden kaikki tunnit yhteenlaskettuinakin, suomalaiset maksavat 36 % enemman sahkosta, kuin ruotsalaiset. toukokuussa suomen tukkusahkon aluehinta oli keskimaarin 28, 06€ / megawattitunnilta. myos toukokuussa ruotsalaiset maksoivat liki viidennneksen vahemman. keskimaarainen hintataso ottaa huomioon myos sen, etta pohjolan tukkusahkon hintaerot tasaantuvat yon ajaksi. sahkoa tosin kaytetaan enemman paivalla, jolloin hintaerot ovat suurimmillaan. kantaverkkoyhtio fingridin oman paivityksen mukaan suomella ja ruotsin kolmella sahkon hinta - alueella oli yhtenainen sahkon tukkuhinta tammi - toukokuun tunneista vain alta puolet eli 47 prosenttia. prosenttilukema on siis pudonnut jo alle 50 : een, kun sen pitaisi olla 100 prosenttia. suomen sahkonkulutus oli tanaan aamupaivalla tavanomaiset 9 300 megawattia, joten sahkon niukkuus on hieman yllattavaa. sahkoa tuodaan ruotsista paraikaa niinkin paljon, kuin 2 720 megawattia, kun taas venajalta sahkoa tulee ainoastaan 59 megawatin teholla. suomen oma tuotantoteho on talla hetkella noin 6 300 megawattia. lahde : te t11 / mv mvtoimitus11 @ gmail. com [SEP]\n",
      "Predicted oma narratiivi ([-1.2922125  0.5619046  0.8680092]) != real kopiointi for:\n",
      "[CLS] express writes : viktor orban said elitist leaders in the west were steaming ahead with migrant settling plans their citizens were vehemently against. he laid into the region at a summit yesterday, where he declared the tumultus continent was now actually being lead by the visegrad states – hungary, slovakia, poland and the czech republic. in a ferocious critique of the european union, he explained while governments of western countries like the uk, germany and france were ignoring their citizens, the visegrad was listening to concerns and representing the views of the population – especially regarding immigration. he said [UNK] everything is cracking in the west of us ”, where never before has [UNK] everything people wanted and everything elites did so opposed ”. in contrast, he said, visegrad was now the [UNK] most stable region in terms of economy and politics ” and [UNK] the most successful and stable region of the world ”. he said : [UNK] governments are stable, democratic systems are stable, constitutions are voted by the people and stable, democratic procedures are going on. ” czech europe minister tomas prouza added the visegard [UNK] were right ” about their long - standing concerns over the migrant crisis – a worry western countries have ignored for too long. hungary in particular has been adamant about its defence of its borders, building a 500km - long razor wire fence in an attempt to keep out illegal migrants. read more : http : / / www. express. co. uk / news / world / 678463 / western - europe - cracking - up - orban - eu - referendum - migrants - ilja j / mv [SEP]\n",
      "Predicted oma narratiivi ([-0.6448922  -0.02311706  0.2954216 ]) != real kopiointi for:\n",
      "[CLS] / / static. mvlehti. net / uploads / 2017 / 08 / jussi - halla - aho - uutisextra - 18. 8. 2017 - online - video - cutter. com [UNK]. mp4 lahde : mtv katso myos : lukijan videokuvaa : talta tilanne naytti paikan paalla turussa kun jihadistit iskivat! ( k18 ) t3 / mv toimitus3mv @ gmail. com [SEP]\n",
      "Predicted kopiointi ([-2.4852574  1.1723499  0.9743849]) != real oma narratiivi for:\n",
      "[CLS] kavimme sivistynytta keskustelua pakolaisista kaverini seinalla. siella oli paljon asiallista keskustelua, ennen kuin jouni janatuinen yhta akkia ilmestyi, ja kommentoi seuraavaa. alkupatka keskustelusta ei ole mukana koska se on tassa kohtaa merkitykseton. hanesta loytyy heti seuraavaa hakusanalla ” jouni janatuinen vastaanottokeskus ” seuraavia tuloksia. ja sen jalkeen hieman lisa googlailua ja loytyykin seuraavaa [UNK] ja tassa on vasta yksi tonkaisu ja tulos. kysymys siis kuuluu, onko mahdollista etta tassa on vilpittomassa mielessa kaytetty veronmaksajien rahoja? vuodelta 2014 jo, eli tata seulottavaa jouni janatuisesta tulee riittamaan. tama on juuri se mika mvta tai minua henkilokohtaisesti kiinnostaa eniten. kuka tassa hyotyy - ” follow the money ”. kuka on kaiken taman takana? vastaanottokeskusten katutanssit : ( mitahan mahtoi maksaa? ) http : / / www. iltalehti. fi / keskustelu / showthread. php? t = 1016829 vastaanottokeskusten katutanssit : 10. 1. helsinki kallion vastaanottokeskus 13. 1. helsinki metsalan vastaanottokeskus 14. 1. helsinki metsalan sailoonottoyksikko 15. 1. espoon ryhma - ja perhekoti 16. 1. helsinki punavuoren vastaanottokeskus 20. 1. joutsenon vastaanottokeskus ( konnunsuo ) 21. 1. kotkan vastaanottokeskus 22. 1. mantta - vilppulan vastaanottokeskus 23. 1. punkalaitumen vastaanottokeskus 24. 1. siuntion vastaanottokeskus 27. 1. lammin vastaanottokeskus 28. 1. kristiinankaupungin vastaanottokeskus 29. 1. vaasan vastaanottokeskus 30. 1. kajaanin vastaanottokeskus 31. 1. turun vastaanottokeskus 3. 2. rovaniemen vastaanottokeskus ( mukana kemin vastaanottokeskus ) 4. 2. pudasjarven vastaanottokeskus 5. 2. pudasjarven vastaanottokeskus 6. 2. oulun vastaanottokeskus 7. 2. ruukin vastaanottokeskus http : / / www. migri. fi / medialle / tiedott [UNK] ottokeskuksiin lisatietoja medialle puheenjohtaja jouni janatuinen, suomen katutanssiliitto ry puh. 0400 352 333, s - posti : jj @ nordicmoves. com ylitarkastaja olli snellman, maahanmuuttoviraston vastaanottoyksikko puh. 071 873 0431, s - posti : etunimi. sukunimi @ migri. fi tanssikiertue vie katutanssin vastaanottokeskuksiin suomen katutanssiliitto ry ja maahanmuuttovirasto jarjestavat koko suomen kattavan katutanssikiertueen. terveytta tanssista - kiertue kiertaa kaikissa turvapaikanhakijoiden vastaanottokeskuksissa kevaan 2014 aikana. http : / / www. migri. fi / medialle / tiedott [UNK] ottokeskuksiin katutanssi esittaytyy joutsenon vastaanottokeskuksessa [UNK] etela [UNK]\n",
      "Predicted oma narratiivi ([-0.68548375 -0.33602238  0.5503407 ]) != real kopiointi for:\n",
      "[CLS] kari tolvanen. iltalehti. fi uutisoi, etta jari aarnion kodin turvajarjestelyiden laskut hyvaksyi aarnion hyva kaveri, nykyinen kansanedustaja kari tolvanen. vuonna 2007 aarnion silloinen nurmijarven omakotitalo panssaroitiin ” pieneksi linnoitukseksi ” asentamalla turvalasit ja - ikkunat. helsingin poliisilaitos maksoi niista yli 114 000 euroa. laskuja oli hyvaksynyt aarnion hyva kaveri, helsingin murharyhman silloinen paallikko kari tolvanen. lahde : iltalehti. fi ( johanna mattinen 13. 2. 2017 ) ovatko kaikki aarnioon kytkoksissa olevat poliisit rikollisia? huumeparoni jari aarnion korvannutta jukka paasiotakin epaillaan vilpista t3 / mv toimitus3mv @ gmail. com [SEP]\n",
      "Predicted kritiikki ([ 0.4773218  -0.67620033 -0.1420163 ]) != real oma narratiivi for:\n",
      "[CLS] suomalainen valtamedia helsingin sanomia myoten uutisoi kulttuurimarxistien huhumylly - nimisesta projektista, jonka tavoite on propagoida avoimien rajojen maahanmuuttopolitiikan puolesta. huhumyllyn tavoitteena on nostaa esille tyhjanpaivaisia maahanmuuttoaiheisia some - huhuja ja peittaa niiden avulla todelliset maahanmuuttajien rikostilastot. huhumylly ei esimerkiksi koskaan tule kommentoimaan sita, etta vuosi sitten alkanut pakolaiskriisi kolminkertaisti suomen seksuaalirikostilastot muutamassa kuukaudessa. sivusto ei myoskaan kerro, etta oikeuspoliittisen tutkimuslaitoksen mukaan afrikassa ja lahi - idassa syntyneet miehet syyllistyvat raiskausrikoksiin 17 kertaa useammin kuin suomalaiset. ei ole lainkaan yllattavaa, etta kulttuurimarxistit yrittavat tappaa maahanmuuttokeskustelun suuntaamalla huomion epaolennaisuuksiin. kiinnostavampaa on se, keita huhumyllyn takana on. huhumylly listaa taustahenkilonsa kotisivuillaan : mikael brunila veikka lahtinen petra nyqvist johanna vehkoo dan koivulaakso aleksi lilleberg marsh norris vasemmalla lilleberg, oikealla juutalainen aarivasemmistolainen dmitry gurbanov. lahde : vastarinta. com. vakivaltavasemmiston sisapiiri sivujen mukaan huhumylly sai alkunsa, kun ylen johanna vehkoo teki uutisjutun saksalaisesta monikulttuurisuutta propagoivasta internet - projektista. vehkoo on siis suomalaisten veronmaksajien elattama yleisradion toimittaja. keita han kerasi ymparilleen saatuaan huhumyllyn syntyyn johtaneen idean? ilman pellenaamariakin pelottavan nakoinen johanna vehkoo. kuva : magneettimedia. kuten vaihtoehtomediat ovat aiemmin uutisoineet, ainakin kolme huhumyllyn taustahenkiloa kuuluu vakivaltaa avoimesti suomessa ajavaan aarivasemmistoliikehdintaan : aleksi lilleberg on aloitteellista vakivaltaa ajavan varisverkoston johtohahmoja. lilleberg on osallistunut naamioituneena aarivasemmistolaisiin mielenosoituksiin seka julistanut tukea torkeisiin vakivaltarikoksiin ja henkirikosyrityksiin syyllistyneelle revolutionara frontenille. lisaksi lilleberg on osoittanut tukea tanskalaisille aarivasemmistolaisille, jotka hyokkasivat vakivaltaisesti maahanmuuttokriittista mielenosoitusta vastaan. ( 1, 2 ) dan koivulaakso on vasemmistonuorten keskustelupalstan tietovuodon perusteella vaatinut ” taktista vakivaltaa ” ja erilaisten aseiden kayttoa maahanmuuttopoliittisia toisinajattelijoita kohtaan. koivulaakso kutsui poliiseja vasemmistonuorten salaisissa keskusteluissa ” sioiksi ” ja on todennut, etta ” pasifismi on vakava mielenhairio ”. mikael brunilan nimi tuli vaihtoehtomedioissa esiin viime elokuussa, kun julkisuuteen vuoti tietoavarisverkoston perustajasisapiirin facebook - ryhmasta. brunila oli yksi sisapiiriin kuuluvista. verkoston jasenet iloitsevat julkisesti esimerkiksi aarivasemmiston ulkomailla tekemista puukotuksista ja ovat kannustaneet vakivaltaan suomen sisua vastaan. lokakuun alussa brunila osallistui yleisradion toimittajan marko hietikon kanssa kulttuurimarxi\n",
      "Predicted kritiikki ([ 0.67029804 -1.2354856   0.11166054]) != real oma narratiivi for:\n",
      "##stiseen keskustelutilaisuuteen, jossa puhuttiin muun muassa laajemman antifasistisen rintaman rakentamisesta. kuukauden sisalla jo kaksi yleisradion toimittajaa on ollut erittain laheisissa tekemisissa suomen vakivaltavasemmiston ydinhahmojen kanssa. koko lystin kustantavat suomalaiset veronmaksajat. lahde : magneettimedia t2 / mv toimitus2mv @ gmail. com [SEP]\n",
      "Predicted oma narratiivi ([ 0.4691223 -1.4106781  0.6818678]) != real kritiikki for:\n",
      "##ukseen johtuvan osin hanen ja myos hanen kannattajiensa epaluulosta valtamediaa kohtaan. trump uskoo suurten tiedotusvalineiden toimivan hanen tavoitteitaan vastaan, joten han haluaa kontrolloida mediaa. no shit, sherlock? kai asia on aivan selva. tarvittiinko taman tajuamiseen ihan oikeasti tohtorintutkinto? huvittavaa tassakin lauseessa on se, etta suuret tiedotusvalineet eivat ainoastaan toimineet trumpin tavoitteita vastaan, vaan pyrkivat demonisoimaan miehen taydellisesti ja estamaan hanen valintansa. ja siita huolimatta asia on esitettava muodossa ” trump uskoo suurten tiedotusvalineiden toimivan hanen tavoitteitaan vastaan ”. ehka kyseinen aalto kertoi itse parhaiten sen, minka vuoksi median valtaa tulee pala palalta murtaa. suorina viesteina ihmiselta ihmiselle ilman toimittajien myrkyttavaa valiintuloa. oli sitten kyse yhdysvaltain presidentista tai tavallisesta janatuisesta jamijarvella. silla media ei ole viranomainen. se ei voi antaa kaskyja, ja jos se yrittaa, niita ei tarvitse totella. media on vain laja voodoo - pappeja. ei sen edessa tarvitse ryomia. olisi kovasti hyva, jos suomalaiset poliitikotkin taman ymmartaisivat. erityisesti tasta voisi muistuttaa perussuomalaisia. paljonkos te olette hyotyneet siita, etta olette ryomineet median edessa? viitekuva. muista, etta ylen voodoo - pappi vapaamatkustaa juuri sinun kustannuksellasi. lahde : yrjoperskeles t2 / mv toimitus2mv @ gmail. com [SEP]\n",
      "Predicted kritiikki ([ 0.8800432  -1.0444452  -0.05952604]) != real oma narratiivi for:\n",
      "[CLS] niin sanotun perskeko - hallituksen paaministeri juha ” juudas ” sipila on joutunut nolon pakolaiskohun keskelle. mtv3 : n haastattelussa vakivaltaisista uhkausviesteista tunnettu aikuinen ” sotalapsi ” valehtelee hyvauskoiselle paaministerille pain naamaa. sipilan kanssa televisioyleisolle patsastellut ouluun sijoitettu siirtolainen on sosiaalisen median mukaan fahad firas. mtv3 : n kameroiden edessa ” sotalapsi ” valehteli olevansa ” vasta 17 - vuotias, vaikka naytan vanhemmalta ”. facebookissa firas ilmoittaa kuitenkin syntyneensa jo 1995 – han siis tayttaa 20 tana vuonna! video : tata haastattelua valtamedia ja hallitus eivat halua suomalaisten enaa nakevan! mtv3 : n videolla sipila nyokyttelee ja hymistelee ” yes ” kaikkiin hanelle syotettyihin sepitteisiin. paaministeri on taysin pihalla suomen turvapaikkashoppailutodellisuudesta, ja han on jopa luvannut oman asuntonsa laittomien tunkeutujien kayttoon. kun totuus firasista tuli julki, valtamedia oli vahintaan yhta nolostunut kuin sipila itse. mtv3 onylpeillyt julkisesti aloittaneensa maahanmuuttokeskustelua koskevan poliittisen sensuurikampanjan. kaikki maahanmuuttokriittisyytta potentiaalisesti ruokkiva ” vihatieto ” sensuroidaan kansalta. olikin vain loogista, etta mtv3 poisti valittomasti firasin haastatteluvideon sivuiltaan. ikava kylla parjatut vaihtoehtomediat ehtivat tallentamaan haastattelun, joka leviaa nyt kulovalkean tavoin sosiaalisessa mediassa. firas - kohua ei ole kaytannossa lainkaan kasitelty valtamediassa. alussa kuitenkin esimerkiksi turun sanomat yritti valehdella epatoivoisesti, etta sosiaalisessa mediassa esiintynyt fahad firas on eri fahad firas kuin se, jonka sipila tapasi mtv3 : n kameroiden edessa! [UNK] siitakin huolimatta, etta firasit olivat taysin saman nakoisia. myohemmin firas kuitenkin ilmoitti sosiaalisessa mediassa tavanneensa sipilan, joten valtamedia paatti painaa hatanappia ja aloittaa tayssensuurin aiheesta. firas on ladannut facebookin tayteen kuvia itsestaan poseeraamassa aseiden kanssa lahi - idassa seka rentoutumassa lansimaisissa huippuhotelleissa ja kuntosaleilla merkkivaatteet yllaan. lisaksi han on lahettanyt omalla nimellaan tappouhkauksia ja haukkunut eurooppalaisia viranomaisia ja vastaanottokeskuksia. juutalaisen erkon suvun omistama helsingin sanomat jakaa suomalaisille vinkkeja kuinka piilottaa laittomia maahantunkeutujia omaan kotiin. lahde : http : / / magneettimedia. com / juudas - sipila - nolon - pakolaiskohun - keskella - valtamedia - suojelee / [SEP]\n",
      "Predicted kritiikki ([ 0.86992687  0.09602626 -1.0491923 ]) != real kopiointi for:\n",
      "[CLS] yle uutisoi tanaan, etta suomen kansalainen on saanut tuomion britanniassa terrorismirikoksesta, koska hanen oli tarkoitus matkustaa isiksen joukkoihin. tassa ylen uutisointi kokonaisuudessaan. jutun on kirjoittanut toimittaja pasi myohanen. miksi koko ylen juttu on nakyvissa kuvakaappauksina? sen takia, etta lukija voi itse varmistua siita, mita yle kertoo ja mita yle jattaa kertomatta. katsotaanpa, miten international business times ( ibt ) uutisoi asiasta eilen. teini, jolla oli yksityiskohtainen terroristin opas, tuomittiin vankilaan, kun han jai kiinni yrityksestaan liittya isikseen syyriassa. cubeyda jama tuomittiin old bailey - tuomioistuimessa kolmeksi ja puoleksi vuodeksi vankilaan, kuuluvat ibt : n otsikko ja ingressi. cubeyda jama. kuvakaappaus ibt - julkaisusta. ibt kertoo, etta cubeyda jama, 19, pidatettiin lontoon stanstedin lentokentalla helmikuussa. jama oli jo noussut koneeseen, kun terrorismin vastainen poliisin yksikko otti hanet kiinni koneesta. miehen repusta loytyi turkin kartta ja kannettavalta tietokoneelta e - kirja nimeltaan ” hijrah to the islamic state ”, jossa kerrotaan yksityiskohtaisesti, mita ottaa mukaan syyriaan. jamalla oli muistitikku, jossa oli yksityiskohtaiset ohjeet, miten matkustaa isiksen luokse syyriassa. hanella oli myos 13 isiksen dabiq - lehden irtonumeroa. jaman kotiin tehtiin kotietsinta, jolloin hanen puhelimestaan ja kannettavalta tietokoneeltaan loytyi laaja materiaalisto isiksen propagandaa seka video, jossa isis katkaisee uhrilta paan, ja monenlaisia hakuja isiksen luokse paasemiseksi. ibt kertoo, etta suomen kansalaisuuden omaava somali, joka oli asunut britanniassa vuodesta 2010 saakka, oli kirjoittanut arabiankielella kasin valansa tukeakseen isiksen johtajaa, abu bakr al - baghdadia. cubeyda jama. kuvakaappaus ibt - julkaisusta. jama myonsi oikeudessa aikeensa valmistautua terrori - iskuihin. yle on kayttanyt lahteenaan evening standardia, joka antaa jonkin verran erilaisen kuvan somalista, kuin ibt. kuriositeettina ja valtamedian yhteisen runkkuringin osoituksena – anteeksi kielenkaytto – yle kertoo, etta ensimmaisena tuomiosta kertoi suomessa lannen media. kun mv - lehti kertoo jotain suomessa ensimmaisena, tuo verovaroin yllapidetty matalaitos ei sita mainitse. ibt - julkaisussa metropolitanin poliisin terrorismin vastaisen yksikon johtaja dean haydon kertoo, etta ” jamalla oli yksityiskohtainen opas taisteluun isiksen joukoissa ja monia tarvikkeita, joita terroristiksi haluava olisi voinut kayttaa hyodykseen, kuten opaskirjassa oli ohjeistettu ”. ” han oli kaynyt lapi valtavat maarat terrorismimateriaalia, eika mielessani ole mitaan epailysta, mitka\n",
      "Predicted kritiikki ([ 1.8357654  -1.74548    -0.45245707]) != real kopiointi for:\n",
      "hanen aikeensa olivat, jos han olisi paassyt syyriaan saakka. ” ” koska toimimme niin tehokkaassa yhteistyossa essexin poliisin kanssa, pystyimme varmistamaan, ettei han saanut sita matkaa tehtya. ” tama juttu on yksi niista syista, miksi mv - lehtea jahdataan ja se haluttaisiin saada pois luettavista – koska me naytamme suomen valtamedian madannaisyyden. yle ei kertonut tekijan nimea eika hanen somalitaustaansakaan muuten, kuin kertomalla, etta tuomittu oli joskus asunut somaliassa. yle ei myoskaan julkaissut kuvaa tekijasta. sen sijaan yle pyrki luomaan kuvan ” suomalaisesta reppanasta ”, vaikka kyseessa oli muslimimies, joka halusi syyriaan tappamaan ihmisia islamin nimissa verisen ja julman isiksen joukoissa. miksi verovaroilla yllapidettava yle toimii nain – pimittaa totuutta? sita kannattaa jokaisen pohtia hiljaisina hetkina mielessaan. samoin kuin sita, miksi poliitikot ja poliisilaitos jahtaavat parhaillaan vimmalla espanjalaista mv - lehti - julkaisua hatarin syyttein. miksi totuus on niin vaarallista? lahteet : international business times, yle lue myos : mv - lehtea vastaan on jarjestetty ennennakematon poliittinen noitavaino t2 / mv toimitus2mv @ gmail. com [SEP]\n",
      "Predicted kritiikki ([ 1.8716868  -0.16548385 -2.0921218 ]) != real oma narratiivi for:\n",
      "[CLS] ” mahdollisia rikosnimikkeita hennalan tapauksessa voivat olla julkinen kehottaminen rikokseen, vaaran aiheuttaminen, pahoinpitely seka julkisella paikalla naamioituneena oleminen ”, sanoo poliisi. niqabiin pukeutunut henkilo, joka voi olla kuka vaan, mutta poliisi ei valita. burkiin pukeutuneita miehia, joilla voisi olla pommivyot burkien alla. mies, joka oli pukeutunut burkaan, tappoi heinakuussa 15 ihmista ja haavoitti 80 : aa itsemurhapommituksessa : http : / / www. reuters. com / article / 2015 / 07 / 11 / us - chad - violence - iduskcn0pl0a320150711 lakanaan ja pahvihattuun pukeutunut mieshenkilo mielenosoituksessa, jossa mitaan ei rikkoontunut ja kukaan ei loukkaantunut, mutta jota jahtaa koko suomen poliisi. siis oikeasti? mita tassa maassa oikein tapahtuu? [SEP]\n",
      "Predicted oma narratiivi ([ 0.08471422 -1.7081444   1.2597576 ]) != real kopiointi for:\n",
      "[CLS] helsingin sanomat kertoo vain totuudellisia asioita, se ei toimi valemedian tavoin. legatum institute on kansainvalinen ajatushautomo, jota anne applebaum johtaa. instituutti ilmoittaa, etta he keraavat monenlaista dataa tilastonsa rakentamiseksi ja esittavat varikkaita kaavioita, mutta ei ilmoita, mista tama vaitetty data on lahtoisin. suomen menestys juha sipilan ansiota legatum instituutin selvityksesa suomi sijoittui kaikilla mittareilla mitattuna kolmanneksi, mutta hallinnon osalta suomi oli jopa koko maailman paras. vertailussa oli mukana kaikkiaan 149 maata. legatum institute toteaa lausunnossaan : ” hallinto on suomen paras voimavara ”. suomen ja juha sipilan hallinnon erinomaisuus nakyy erityisesti kolmessa mittarissa, joissa suomi ja juha sipila ovat koko maailman parhaat : suomen hallinnon tehokkuudessa, suomen demokraattisuudessa ja poliittisen osallistumisen tasossa, suomen lainmukaisuuden toteutumisessa. suomi nousi kohinalla neljannelta sijalta maailman parhaaksi maan nykyisen paaministerin juha sipilan ansioilla. kansanterveydessa suomi oli sijalla 21, turvallisuudessa 18., talousnakymissa vasta 12 ja sosiaalisessa paaomassa 11. mutta onneksi suomella on upea paaministeri juha sipila, joka nostaa suomen hallinnon koko maailman parhaaksi tehokkuudellaan, demokraattisuudellaan ja ehdottomalla lainmukaisuudella. kuvassa on tutkitusti maailman paras, tehokkain ja demokraattisin paaministeri juha sipila. ehdottoman totuudellisena ja ankaran kriittisen journalismin huippuna helsingin sanomat on todennut taman. suomen paaministeri ei hairitse demokraattisten vapauksien toteutumista, toisin kuin muissa valtioissa, vaan sipila saa suunnitelmat taytantoon ja hyvaa tulosta syntyy! juha sipilan hallinto saa asioihin upean jarjestyksen, eivatka ulkomaiset maahantunkeutujat sekoita maan oloja. yksikaan resurssi ei mene hukkaan demokraattisesti ja tehokkasti johdetulta valtiolta, sellaiselta kuin juha sipilan suomi. paras ja huonoin naapureina kun vertaa suomen tilannetta isoon itanaapuriin venajaan, niin tilanne on ero kuin yolla ja paivalla. venaja sijoittui kokonaisluokittelussa sijalle 95, tippui 10 pykalaa edellisesta sijoituksesta. tama oli yksi niita jatosmaiden sijoituksia koko globaalissa vertailussa. taloudellisilta resursseiltaan venaja oli vasta 63., liiketoimintaymparistoltaan 69., mutta terveyden suhteen vasta 101, hallinnon 108., turvallisuuden 119, ihmisten valisten sosiaalisten verkostojen 116.. henkilokohtaisen yksilovapauksien suhteen venaja oli globaalissa vertailussa 141, vain egypti, iran, libya, marokko, jemen ja afganistan sallivat yksittaisille miehille ja naisille yhta vahan tai hiukan vahemman vapauksia ilmaista omaa uskoaan, epauskoaan, tyylitajuaan ja mieltymyksiaan, kuin venajan federaatio. nama kaikki naiset ovat tutkimuksen mukaan yhta alistettuja : vasemmalla orjuuteen ja naisvihamielisyyteen alistetut venalaiset naiset, oikealla jemenilaiset naiset.\n",
      "Predicted oma narratiivi ([ 0.13626255 -1.6135156   1.0980805 ]) != real kopiointi for:\n",
      "huhut applebaumista eivat pida paikkaansa amerikan juutalainen anne applebaum on ilmeisen erheellisesti vaitetty joissakin internet - juoruissa grigori zinovjevin sukulaiseksi, mutta asian puolesta ei ole mitaan dokumentteja. eras fanaattinen juutalaissivusto vaittaa toki, etta grigory zinoviev olisi apfelbaum ja olisi neuvostoliiton salaisen poliisin johtaja, joka murhautti kymmenia tuhansia ortodoksikristittyja. vaitteelle ei ole mitaan dokumentaatiota. anne applebaumin taustoista liikkuu valheellisia huhuja. zinovjev oli todellakin bolsevikkeja edustanut vallankumouksellinen poliitikko, joka toimi kommunistisen internationaalin ensimmaisena puheenjohtajana vuosina 1919 – 1926 seka neuvostoliiton kommunistisen puolueen leningradin - johtajana vuosina 1918 - 1926. han muodosti josif stalinin ja lev kamenevin kanssa puoluetta johtaneen troikan. kuitenkin stalinin vainojen kaynnistyttya jopa zinovjev tuomittiin vuonna 1936 kuolemaan. zinovjev vaitettiin osalliseksi kirovin murhaan salaisen terroristijarjeston avulla. anne applebaum onnaimisissa puolan ex - ulkoministerin radoslaw sikorskin kanssa, joka teki pitkan uran myos washingtonissa. lahteet legatum institute helsingin sanomat mv - lehden avustaja uskoo ehdottomasti helsingin sanomien totuuden juha sipilan ja koko julkaistun tutkimuksen oikeudesta, jotta ei saisi samaa kovaa kohtaloa kuin ilja janitskin. juha molari juhamolari @ gmail. ocm [SEP]\n",
      "Predicted kopiointi ([-0.64909196  1.3768864  -1.0913768 ]) != real kritiikki for:\n",
      "[CLS] britannian toiseksi luetuin sanomalehti daily mail julkaisi nayttavan raportin, kun muslimimiesryhmat raiskasivat useita naisia ruotsin ostersundissa. maahanmuuttajamiehet tekivat kahdeksan seksihyokkaysta kolmen viikon aikana. daily mail ei ole ainoa kansainvalinen media, joka kertoo tapahtuneista. suomen valtakoneiston media vaikeni heti alussa ja vaikeneminen jatkuu yha edelleen : yhtaan sanaa ei ole kerrottu ruotsin pikkukaupungissa tyttojen kokemasta helvetin piirista. kuvakaappaus daily mailin uutisoinnista. suomessa yle, helsingin sanomat, mtv, iltalehti, ilta - sanomat, turun sanomat, aamulehti seka muu suomen valtakoneiston media vaikenee jarjestelmallisesti naapurivaltion pienessa kaupungissa koetuista julmista raiskauksista ja seksihyokkayksista, joita muslimimiesryhmat ovat tehneet lahiaikoina. vaikeneminen on niin johdonmukaista ja kokonaisvaltaista, etta se muistuttaa poliittista ohjausta. brittilainen daily mail teki ison raportin ruotsalaiskaupungin pelosta ja uhrien kokemasta julmuudesta. ” kahta 10 - vuotiasta koulutyttoa oli ahdisteltu, naisen housut oli revitty pois, lukuisat tytot ja naiset ovat joutuneet hyokkaysten kohteiksi. ” ” kahdeksan seksihyokkaysta kolmen viikon aikana pienessa ostersundin 44 000 asukkaan kaupungissa ”, kuvaa daily mail karua tilannetta. daily mail kertoo, etta pikkukaupunki elaa pelossa. poliisi on varottanut naisia, etta naiden ei ole turvallista enaa kavella yksin yolla. pikkukaupunki on kaantynyt tyhjaksi aavekaupungiksi. ulkomaalaiset nuoret miesryhmat hyokkaavat julmasti naisia ja jopa lapsia vastaan. ostersundin uhrit ovat varsin nuoria. 20. helmikuuta muslimimiesten jengi uhkasi raiskata bussipysakilla kaksi kymmenvuotiasta tyttoa. 21. helmikuuta eras nainen kertoi poliisille, etta muslimimies loi voimalla hanen kasvoihinsa niin etta kulma halkesi. mies uhkasi tappaa hanet. 26. helmikuuta naiset kavelivat toihin lahella yliopistoa, jolloin toisen naisen kimppuun hyokkasi kolme muslimimiesta : miehet loivat ja tyonsivat naisen maahan seka sanoivat seksuaalisia loukkauksia naiselle. 22 - vuotias taleb moafagh pidatettiin tapahtuneen johdosta. taleb moafagh jai kiinni, kun han yritti paeta saksaan lautalla etela - ruotsista. 27. helmikuuta poliisi naki, kun muslimimiehet ymparoivat naisryhman yokerhon ulkopuolella. kun poliisi yritti puuttua tapahtumaan, seksihyokkaajat pakenivat. 2. maaliskuuta kaksi naista kaveli kotiin baarista. muslimimiesryhma pysaytti heidat ja ryhtyi ahdistelemaan naisia. 5. maaliskuuta nainen kaveli yksinaan, jolloin ohi ajanut mies alkoi uhkailla. mies huusi naiselle, etta han vie naisen ystaviensa luo raiskattavaksi ja murhattavaksi. kun nainen juoksi pois, mies jahtasi naista. nainen onnistui paasemaan kotiinsa. 6. maaliskuuta nainen kaveli yksin kotiin, kun muslimimies alkoi vislata hanelle. nainen pyysi miesta lopettamaan, jolloin\n",
      "Predicted kritiikki ([ 1.2439287 -0.3728845 -0.9463025]) != real kopiointi for:\n",
      "[CLS] kansanedustaja olli immosen ( ps. ) facebook - kirjoittelu ja sita seurannut kohu ovat aiheuttaneet piikin kansallismielisen suomen sisu - jarjeston jaseniksi pyrkivien maarassa. ” pelkastaan jasenhakemuksia on tullut ensimmaisen vuorokauden aikana toista sataa ”, jarjesto tiedottaa verkkosivuillaan. immonen on jarjeston puheenjohtaja. han jakoi jarjeston jasenhakemuslomakkeen facebook - sivuillaan sunnuntaina kohun kaynnistyttya. jarjeston mukaan immosen kirjoittelun jalkeinen tilanne muistuttaa vuoden 2006 profeetta muhammed - pilakuvien julkistamisesta seurannutta huomiota. jarjesto julkaisi alun perin tanskalaisessa jyllands posten - lehdessa julkaistut kuvat verkkosivuillaan helmikuussa 2006, mista seurasi laajaa mediahuomiota. immonen sanoi vuonna 2013 jarjeston 15 - vuotisjuhlapuheessa, etta silla on noin 1 000 jasenmaksunsa maksavaa jasenta. ” akillinen huomio iskee keskelle jarjeston pitkaaikaista kehittamistyota. suomen sisu perustaa parasta aikaa maakunnallisia piirijarjestoja ja viimeistelee tulevassa syysseminaarissaan pitkaan valmisteilla ollutta periaateohjelman uutta versiota. saantojemme mukaista tarkoitusta kaikkia kansallismielisia yhteen kokoavana jarjestona korostetaan jatkossa ”, kerrotaan sisun verkkosivulla. ” kansallismielisyys on maailmankatsomus, jonka mukaan kaikki kansat ja kulttuurit ovat oikeutettuja olemassaoloon ja itsensa hallitsemiseen seka ihmiskunnan globaali monimuotoisuus suojelemisen arvoista. kansallismielisyys ei aseta eri kansoja hierarkiseen jarjestykseen tai rajoita yksiloiden mahdollisuuksia elaa uuden kansan parissa. laajamittaiset lyhyen ajan populaatiosiirtymat se torjuu. ” ” kansallisvaltiossa toteutuvat kansanvalta ja oikeudenmukaisuus parhaiten ja sen pohjalta on mahdollista yllapitaa hyvinvointiyhteiskuntaa. monikulttuurinen yhteiskunta on jannitteinen, rajahdysherkka ja jatkuvia konflikteja tuottava, joka on yhteisollisyydessaan heikko ja kansanvallan ja hyvinvointiyhteiskunnan perustan murentava. ” tassa kavi juuri niin kuin ounastelimmekin toimituksessa, sama kaava kuin mv : n suosituksi tulemisessa toteutui. kylla suomalainen valtamedia on sitten ruudinkeksijoita taynna. ampuivat taas omaan jalkaansa. ” miljoonien ” markkinointi ilmaiseksi [UNK] ei meilla muuta. lahde : lansivayla ja suomen sisu [SEP]\n",
      "Predicted kopiointi ([ 0.440344    0.97882885 -2.264212  ]) != real oma narratiivi for:\n",
      ": / / www. iltalehti. fi / uutiset / 2014060418367757 [UNK] uu. shtml kirjoittaja : lonely tower [SEP]\n",
      "Predicted oma narratiivi ([-2.366679   -0.41575497  2.4398499 ]) != real kopiointi for:\n",
      "[CLS] kirjoitus on lyhennelma alkuperaisesta englanninkielisesta kirjoituksesta, jonka rajat kiinni on julkaissut : www. zerohedge. com / news / 2016 - 07 - 08 / how - george - soros - singlehandedly - created - european - refugee - crisis - and - why valuuttaspekuloinnit, jotka aiheuttivat britannian ja aasian talouskriisin vuonna 1990 soros aloitti todellisen sarjan valuuttaspekulointeja. ensimmainen niista tapahtui vuonna 1992, jolloin han myi omistamansa punnat ja tienasi talla kaupalla miljardi dollaria yhdessa paivassa. hanen seuraava iso valuuttakeinottelunsa tapahtui vuonna 1997. talla kertaa soros valitsi valuuttakeinottelun kohteeksi thaimaan bahtin. han onnistui aiheuttamaan bahtin irroittamisen dollarista, ja tama sai aikaan aasian talouskriisin. ” humanitaariset ” ponnistelut sorosin nettovarallisuus on talla hetkella 23 miljardia euroa. astuttuaan taka - alalle soros fund management - yrityksessaan vuonna 2000, soros on keskittynyt ” hyvantekevaisyystyohon ”. han tekee sita vuonna 1993 perustamansa open society institute - jarjestonsa kautta. kenelle han lahjoittaa rahaa ja millaisia asioita han tukee? 1980 - ja 90 - luvuilla tama poikkeuksellisen rikas miljardoori rahoitti vallankumouksia kymmenissa euroopan maissa, kuten tsekkoslovakiassa, kroatiassa ja jugoslaviassa. han saavutti taman kanavoimalla rahaa poliittisille oppositiopuolueille, kustantamoille, ja riippumattomille tiedotusvalineille naissa maissa. jos sinua mietityttaa miksi soros sekaantui naiden kansojen asioihin, osa selitysta voi olla, etta kaaoksen aikana ja sen jalkeen han investoi voimakkaasti omaisuuteen kussakin kyseisessa maassa. han kaytti hyvakseen yhdysvaltalaisen columbian yliopiston ekonomia jeffrey sachsia, jonka han sai neuvomaan tuoreita hallituksia, jotta ne yksityistaisivat kaikki julkiset yritykset valittomasti. sitten soros myi vastaperustetuilla avoimilla markkinoilla omaisuuden, jonka han oli hankkinut kuohunnan aikana. soros onnistui suunnitelmassaan euroopassa hallitusten muutosten kautta, ja tienasi samalla valtavia summia. sitten han kaansi huomionsa yhdysvaltoihin. vuonna 2004 han sanoi : ” uskon syvasti avoimeen yhteiskuntaan [ ilman rajoja ]. viimeiset 15 vuotta olen keskittynyt eurooppaan, ja nyt on yhdysvaltojen vuoro. ” yhdysvalloissa han on ostanut valtavan maaran poliittista valtaa rahoittamalla eri jarjestoja, ja tukee huomattavilla summilla myos hillary clintonia. voidaan huoletta olettaa etta soros manipuloi demokraattisen puolueen tavoitteita yhdysvalloissa. han ajaa myos yhdysvalloissa valtioiden rajattomuuden asiaa ja aiheuttaa samanlaista kaaosta kuin han on saanut aikaiseksi euroopassa. sorosilla oli myos sormensa pelissa ukrainan konfliktissa. hanen viimeisin ” saavutuksensa ” : euroopan ” pakolaiskriisi ” sorosin tavoite kansallisten rajojen eliminoiminen. tama on viime aikoina ollut selvasti nahtavissa\n",
      "Predicted kritiikki ([ 0.18987395 -0.33011922 -0.10015903]) != real kopiointi for:\n",
      "hanen tavassaan rahoittaa euroopan pakolaiskriisia. pakolaiskriisista syytetaan usein sisallissotaa syyriassa, mutta oletko koskaan miettinyt, miten kaikki nama ihmiset yhtakkia tiesivat, etta eurooppa avaisi ovensa ja paastaisi heidat sisaan? pakolaiskriisi ei ole luonnollinen ilmio. se alkoi samalla hetkella kun open society institute - jarjesto alkoi lahjoittamaan rahaa yhdysvaltalaiselle migration policy institutelle ja platform for international cooperation on undocumented migrants - jarjestolle. soros tukee molempia organisaatioita. nuo ryhmat kannattavat kehitysmaista tulevien muslimien uudelleensijoittamista eurooppaan. vuonna 2015 sky news - kanavan toimittaja loysi ” siirtolaisten kasikirjoja ” kreikan lesbos - saarelta. myohemmin paljastui etta ryhma nimelta ” tervetuloa eu : hun ” oli jakanut naita kasikirjoja pakolaisille. nuo kasikirjat on kirjoitettu muun muassa arabiaksi, ja niita oli jaettu pakolaisille ennen heidan valimeren ylitystaan. arvasit oikein : sorosin open society institute - jarjesto rahoittaa tervetuloa eu : hun - ryhmaa. soros ei ole ainoastaan tukenut ryhmia, jotka kannattavat kehitysmaista tulevien maahanmuuttajien uudelleensijoittamista eurooppaan, han on itse asiassa ” merkelin suunnitelman ” arkkitehti. merkelin suunnitelman loi european stability initiative, jonka puheenjohtaja gerald knaus on vanhempi jasen sorosin open society institutessa. suunnitelmassa ehdotetaan etta saksan pitaisi myontaa turvapaikka 500. 000 syyrian pakolaiselle. lisaksi siina todetaan etta saksan seka muiden euroopan maiden pitaisi auttaa turkkia saamaan viisumivapaus eu : hun vuodesta 2016 alkaen. turkin kansalaisista 98 % on muslimeja. lue myos : yhta maailman vaikutusvaltaisinta sukua, rothschildien pankkiirisukua, edustava miljardoori soros rahoittaa massamaahanmuuttoa aamulehden blogi 5. 10. 2015 : sorosin ja cia : n suunnitelma epavakauttaa eurooppa pakolaiskriisilla lahde : http : / / www. rajatkiinni. fi / uutisia / taloussanomienkin - lahteena - kayttama - zerohedge - kuinka - soros - yksin - aiheutti - euroopan - pakolaiskriisin - ja - miksi - han - sen - teki / - ilja j / mv [SEP]\n",
      "Predicted kopiointi ([-1.1661749  1.7211365 -0.6772143]) != real oma narratiivi for:\n",
      "[CLS] miksi turvapaikkaa ei myonneta? turvapaikan epaamisen syyt voivat olla turvapaikkaa hakeneen henkilon perattomissa tarinoissa kotimaansa oloista, selvityksen mukaan kotimaan tai lahtomaan riittavassa turvallisuustilanteessa seka naiden henkiloiden aiheuttamassa rikollisissa tai muissa turvallisuusriskeissa. osalla karkotettavissa on yhteys kansainvaliseen terrorismiin, kuten myos suojelupoliisi on todennut monista sadoista suomeen saapuneista pakolaisista. yomajoitus alkaa lauttasaaren kirkosta. kuvassa vasemmalla osama bin laden ja oikealla dokka umarov – molemmille olisi yosija myos lauttasaaren kirkossa, jos nama terroristit olisivat hengissa. evankelisluterilaisella valtiokirkolla ei ole asiantuntemusta eika toimintatapaa selvittaa majoitettavien henkiloiden todellista taustaa. viranomaiset ovat jo selvittaneet ja paatyneet arvioon naiden henkiloiden kyseenalaisesta tarkoituksesta oleskella suomessa. evankelisluterilainen kirkko avaa ovet ja kyseenalaistaa viranomaisten patevyyden arvioida oleskelun riskia. yot alkavat lauttasaaren kirkosta helsingin seurakuntien kirkot ovat avoinna kello 21 – 07, ensimmaisena avautuu lauttasaaren kirkon tilapaismajoitus 21. – 27. marraskuuta ja sitten paavalin seurakunta 28. 11. – 4. 12. valomerkki kertoo lautasaarelaisen elina ojalan auttamisen halusta avata kirkon ovet kodittomille. elina ojala ei ole kuitenkaan kirkon jasen. kirkollisveron maksajat kustantavat yolliset jarjestelyt. vaikka vapaaehtoiset osallistuvat jarjestelyihin, niin valomerkista paljastuu, etta myos kirkon viranhaltijoita velvoitetaan viettamaan yotansa karkotettujen tai muusta syysta kodittomien kanssa. valomerkki kertoo, etta kodittomien hatamajoitus on kuntien lakisaateinen tehtava. valomerkki ei kuitenkaan kerro, etta karkotettujen majoittaminen ei ole lakisaateinen tehtava. juuri pakolaistulvan seurauksena on kirkon ovet avautuneet yon ajaksi. aiemmin yosijaa on tarjottu hermannin diakoniatalon hatamajoituksessa lahinna romanian ja bulgarian romaneja, jotka eivat ole turvapaikanhakijoita. talla hetkella jarjestetty iso uusi operaatio on sita vastoin suora seuraus maahan tunkeutuneista turvapaikanhakijoista. kirkon ovet eivat avaudu kristityille helsingin kirkkojen ja seurakuntasalien halytysjarjestelmat ja palvelusuhteisen henkilokunnan tyoajat ovat olleet jo vuosikymmenet ylittamaton este, mikali raamattu - tai rukouspiirien paattymisajat venyvat minuuttiakaan liian myohaiseksi, tavallisesti halytykset tulevat kello 21 : 00 ja sen jalkeen liikkumisesta tulee iso lasku. vapaaehtoisten ei ole sallittu myoskaan hoitaa jarjestelyja ja siivouksia yms. vasta nyt ovet avautuvat – suomessa laittomasti oleskeleville karkotettaville ihmisille. muistetaan myos, etta helsingin kirkkojen ovet eivat avaudu edes paivasaikaan vanhauskoisille luterilaisille, jotka pitaytyvat naispappeuspaatosta edeltaneeseen virkakasitykseen. lahteet valomerkki helsingin uutiset t9 / mv toimitus9mv @ gmail. com [SEP]\n",
      "Predicted kopiointi ([-1.3845189   0.61320287  0.35245287]) != real oma narratiivi for:\n",
      "[CLS] mika ihmeen ttip??? erityisesti olemme huolissamme sopimuksen mahdollisista vaikutuksista demokratiaan seka tyontekijoiden oikeuksiin, kuluttajasuojaan ja ymparistonsuojeluun. nakemyksemme mukaan ttip : n kautta siirretaan suomen eduskunnalle ja viranomaisille kuuluvaa julkista valtaa suomen ulkopuolelle, pienelle kansainvaliselle juristieliitille. epailemme myos, etta ttip : n taloudellisia hyotyja suomelle on yliarvioitu. ja sitten itse juttuun [UNK] [UNK] uusimman arvion mukaan uutta kultaa loytyy 186 tonnia eli kullan nykyhinnalla 5, 6 miljardin euron potti. todellinen lottopotti olisivat 3, 7 miljoonan tonnin kupari ja 1, 8 miljoonan tonnin sinkkivarannot. nykyhinnoilla maassa makaavat 19 miljardin euron kuparit ja 3, 2 miljardin euron sinkit. kullan maaraa voi verrata suomen pankin kultavarantoon, joka on 49 tonnia. jos uudet esiintymat tulisivat suomen pankin kayttoon, pankin kultavaranto enemman kuin kolminkertaistuisi. geologian tutkimuskeskus ( gtk ) on arvioinut kolmen suomessa tarkean kupariesiintymatyypin sisaltamat kupari - ja sinkkivarannot maamme kallioperassa yhden kilometrin syvyyteen asti. arvio koskee vulkanogeenisia massiivisia sulfidimalmeja ( vms ), porfyyrikuparimalmeja ja outokumpu - tyypin malmeja. suomesta rajattiin yhteensa 42 aluetta, joilla voi olla loytamattomia edella mainitun tyyppisia esiintymia. naiden alueiden arvioidaan sisaltavan yhteensa keskimaarin 60 loytamatonta kupari - tai kupari - sinkkiesiintymaa. suomen loytamattomien vms -, porfyyrikupari - ja outokumpu - tyypin esiintymien sisaltamat kupari - sinkkivarannot ovat 50 prosentin todennakoisyydella ainakin 3, 7 miljoonaa tonnia ( mt ) kuparia ja 1, 8 miljoonia tonneja loytamatta vertailu tunnettujen malmiesiintymien sisaltamiin metallimaariin paljastaa, etta arviolta ainakin 71 prosenttia suomen vms - ja outokumpu - tyypin esiintymien kuparisisallosta ja 68 prosenttia niiden sinkkisisallosta seka ainakin 98 prosenttia suomen porfyyrikuparityypin esiintymien kuparisisallosta on heikosti tutkituissa tai kokonaan viela loytamattomissa esiintymissa. lahde : http : / / www. talouselama. fi / uutiset / kuuden + miljardin + kultapotti + odottaa + ottajaansa + + suomen + kallioperassa + riittaa + rikkauksia / a2286174 [SEP]\n",
      "Predicted kopiointi ([ 0.15272807  0.9397513  -1.2256213 ]) != real kritiikki for:\n",
      "[CLS] toimittelija tea manninen. iltasanomat. fi teki tanaan jutun, jossa on kuva - arvoitus. vanhassa kuvassa lukee selvasti, etta kyseessa on kaksintaistelutilanne. kuvassa on myos kysymys ” missa on vastustaja? ” ilta - sanomien toimittelija tea manninen kuitenkin kirjoitti juttuun, etta kyseessa olisi ” salamurhaaja ”. manninen kirjoittaa : ” [UNK] kaynnissa vaarallinen tilanne, jossa mies osoittaa aseella neljaa muuta miesta. kuvassa kuitenkin vaijyy myos salamurhaaja, kuvakaappaus iltasanomat. fi - sivulta. kun normaali ihminen nakee kuvassa kaksintaistelun, jossa ampujat osoittavat pistooleilla toisiaan, nakee ilta - sanomien toimittelja kuvassa pistoolilla neljaa miesta osoittavan miehen ja toisen pyssysankarin, joka on salamurhaaja. kuvakaappaus iltasanomat. fi - sivulta. lahde : iltasanomat. fi t3 / mv toimitus3mv @ gmail. com [SEP]\n",
      "Predicted oma narratiivi ([-3.8637695   0.12959473  3.2004545 ]) != real kopiointi for:\n",
      "[CLS] maahantunkeutujien orpo valtiovarainministeri petteri orpo tahtoo lahettaa suomalaiset tyottomat ” vapaaehtoistoihin ”. osallistumistoiminta velvoittaa tyottoman osallistumaan vapaaehtoistoimintaan tunnin tai pari paivassa pysyvasti. orpo sanoo innokkaana kokoomuksen nettisivulla verkkouutiset : ” pidan tasta ajatuksesta ”. valtiovarainministeri petteri orpo ( kok. ) pitaa ajatuksesta, etta tyomarkkinatuki sidotaan tyottoman osallistumisvelvollisuuteen vapaaehtoistyohon. orpon kasityksen mukaan nykyinen sosiaaliturva on ” byrokraattinen jarjestelma ”, jonka seurauksena tyottomat makaavat kotonaan passiivisena. orpo kiteyttaa tyottomille maarattavan paivittaisen muutaman tunnin osallistumisvelvoitteen : ” minusta se on ehdottomasti suunta, mihin sosiaaliturvaa pitaa kehittaa ”. orpo on tunnettu poliitikkona, joka sisaministerina paasti suomeen kymmenia tuhansia laittomia henkiloita. tama sisaministerin tyokyvyttomyys aiheutti satojen miljoonien eurojen kulut seka sisaisen turvallisuusriskin suomelle. ja samanaikaisesti pariskunta orpo tahkosi itselleen rahaa turvapaikanhakijoilla! petteri orvon vaimo niina kanniainen - orpo ja monet puoluepoliittiset henkilot ovat mukana vastaanottokeskuksien bisneksessa. niina tyoskentelee maahanmuuttovirastossa turun vastaanottokeskuksessa syksysta 2015 alkaen. lisaksi ministerin vaimolla on lakiverstas oy ( y : 266 2667 - 7 ), joka hommaforumin mukaan tehtailee turvapaikkavalituksia. itse firma ilmoittaa asian sievemmin : ” lakimiehen apu voi olla tarpeen myos viranomaisasioissa, jolloin omaa oikeutta haetaan esimerkiksi oikaisupyynnolla tai valituksella. ” esim. kielteisesta turvapaikkapaatoksesta valittaminen olisi sopiva toimeksianto. sellainen mainos on nahty myos spr : n oppaassa turvapaikanhakijoille. osallistumistulo ei synny ilmaiseksi hallituksen ohjelmassa on kunnianhimoinen tavoite, etta hankkeesta valmistuu tarvittavat saannosmuutokset viimeistaan syksylla 2017. vastuuministerina on jari lindstrom. perussuomalaisten ministeri jari lindstrom on vastuuministerina johtamassa osallistumistulon kehittelya. toistaiseksi tavoitteen hyvaksi on tuotettu paljon paperia ja jonkin verran juttuja mediaan. sadat tuhannet eurot ovat palaneet asiantuntijoiden palkkioihin. jo 2010 - luvun alussa on mediassa kohuttu tyottomille tulevasta tyovelvoitteesta, joka ei ole vielakaan saapunut. saaty - yhteiskunnassa muonamiehet saivat ravinnon ja yopaikan tyota vastaan, loiset olivat tilapaistyovoimana lyhytaikaisesti. kehitteilla olevan mallin on syytetty heijastavan saaty - yhteiskunnan jakautuneisuutta, mutta hanke saa aivan yhta paljon selityksensa poliittisten paattajien tarpeesta esiintya tarmokkaana – ikaan kuin jonkin asian tekijoina ja kehittelijoina. professori heikki hiilamon ja tutkimusprofessori pasi moision kehittaman mallin ajatuksena on, etta osallistumistulo korvaa tyomarkkinatuen. jos tyoton ei osallistu osallistumistoimintaan, hanen tukensa pienenee. heikki hiilamo nimeaa ongelmia heikki hiilamo on esitellyt yhteiskuntapolitiikka - julkaisussa osallistusmistuloa anthony atkinsonin malllia esitellen. siina korotetun perusturvan saaminen liitetaan yhteiskunnallisesti hyodylliseen\n",
      "Predicted oma narratiivi ([-3.258454    0.15473546  2.7440214 ]) != real kopiointi for:\n",
      "##tyohon seurataan ja edistetaan? onko sellaisesta edes nayttoa, etta harrastelu osallistumistulon tehtavissa edistaisi oikean palkkatyon saamista ja osaamista? milla tavalla viranomaisjohtoinen vapaaehtoinen osallistumistoiminta edistaa tyottoman tyokykya ja tyon loytamista paremmin, kuin taman henkilon samanaikainen omatoiminen liikunta ja tyopaikkahakemusten perusteella hakuilmoitusten tayttaminen? nykyisellaan monet tyottomat ovat osallistuneet seka oman perheensa hoitamiseen ja kasvatustehtavaan etta vapaaehtoistoimintaan mm. urheiluseuroissa. milla tavalla viranomaisten maaraama ja ohjaama vapaaehtoistoiminta on laadukkaammin kohdennettua ja tehokkaampaa, kuin tyottomien nykyinen vastuu omasta perheesta ja harrastuksista? liikennekustannukset ovat liikenneministeri anne bernerin kaavaileminen autoilun valvonta ja maksukaytantojen seka verotuspaatosten vuoksi nousemassa huomattavasti. tallaisessa tilanteessa vapaaehtoistoimintaan velvoittava toiminta tyottomalle pari tuntia paivassa saattaa aiheuttaa jopa useiden satojen tuhansien kustannukset liikkumisen johdosta. kuka korvaa tyottoman osallistuvan toiminnan matkakulut? loisvero osallistumistulo ei ole alallaan ainoakertainen yritys. suomessa vuosi sitten kauhisteltiin, kun valko - venajalla kehiteltiin ” loisvero ”. suomessa asenteet eivat ole yhtaan kauniimmat, vaikka nimet ovat kehittyneemmat. venajalla kaytiin kevaalla 2016 keskustelua valko - venajan verokaytannon ottamisesta tyottomille. jos valko - venajalla henkilo tyoskentelee alle 183 paivaa vuodessa, hanen on maksettava korvausta ” loisimisesta ”. loisveron arvioitiin vahentavan loiselamaa ja torjuvan tulojen salaamista. lahteet verkkouutiset orpo verkkouutiset ryhmajohtajat verkkouutiset peralahti hiilamo : yhteiskuntapolitiikka valtioneuvosto aif t9 / mv toimitu9mv @ gmail. com [SEP]\n",
      "Predicted kopiointi ([ 0.41117877  0.43448263 -0.89151114]) != real kritiikki for:\n",
      "[CLS] nykyinen saantelematon maahanmuutto valimeren yli aiheuttaa suuria karsimyksia. eu : n on harkittava asiaa uudelleen. kuvakaappaus : expressen. eu : n on muutettava maahanmuuttopolitiikkaa uusimpien yk : n lukujen mukaan yli 100 000 siirtolaista ja turvapaikanhakijaa on tahan mennessa tullut tana vuonna valimeren yli. naista noin 85 000 on saapunut italiaan. tilanne maassa muuttuu paivittain yha kestamattomammaksi, kirjoittaa expressen. miksi 85 000 maahanmuuttajaa puolessa vuodessa, siis 170 000 vuodessa, olisi kestamatonta maalle, jossa on hieman yli 60 miljoonaa asukasta, kun 163 000 maahanmuuttajaa ei ollut liikaa 10 miljoonan asukkaan ruotsille, sita lehti ei selita. joka tapauksessa, tama niin sanottu lehti kirjoittaa : [UNK] on aika kohdata totuus. [UNK] nykyinen maahanmuuttojarjestelma ei kesta. [UNK] ensisijainen puute ei ole tasapuolinen jako eu : ssa, joka on ongelmallinen, mita ruotsi antaa ymmartaa. [UNK] perusongelma on saantelematon muuttoliike itse. [UNK] vasta kun liikenne valimeren yli saadaan loppumaan, on mahdollista korjata nykypaivan hallitsematon tilanne. useimmat ihmiset, jotka menevat hengenvaarallisilla kumiveneilla valimeren yli eivat ole pakolaisia vaan taloudellisia siirtolaisia. he lahtevat koyhista oloista, maista kuten senegal ja nigeria, etsimaan onneaan euroopasta. ja tama maahanmuuttajien virta vain lisaantyy, kun vaesto afrikassa kasvaa, ja yha useammilla ihmisilla on varaa tehda matka. tassa ei ole siis ensisijaisesti kyse valiaikaisen pakolaiskriisin hallinnasta, vaan vaestopaineesta etelasta, joka tulee kasvamaan tulevien vuosien aikana. pettersson panee merkille, etta expressenin paakirjoitustoimitus ehdottaa samoja toimenpiteita kuin ruotsidemokraattien jimmie akesson ja mita vaihtoehtomediat ovat vuosia jankuttaneet, silloin kun expressen kutsui meita rasisteiksi, natseiksi, islamofoobikoiksi, muukalaisvihamielisiksi, ja vaikka miksi. kuvakaappaus : expressen. mutta en ole katkera, vaan sanon, etta tervetuloa natsijengiin [UNK] hauskaa, etta olette heranneet, vaikka olette jo vuosia myohassa. lahde : petterssonsblogg. se jutun mv - lehden lukijoille kaansi omega. t2 / mv toimitus2mv @ gmail. com [SEP]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "preds = trainer.predict(valid_dataset)\n",
    "print(preds.metrics['test_confusion_matrix'])\n",
    "for index, (logits, label) in enumerate(zip(preds.predictions,preds.label_ids)):\n",
    "    pred_label = logits.argmax()\n",
    "    if pred_label != label:\n",
    "        text = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(valid_snippets_encodings['input_ids'][index]))\n",
    "        text = re.sub(\"\\[PAD\\]\",\"\",text).strip()\n",
    "        print(f\"Predicted {class_labels[pred_label]} ({logits}) != real {class_labels[label]} for:\\n{text}\")\n",
    "        multi_features_embeds.append((text, class_labels[pred_label], class_labels[label]))\n",
    "        \n",
    "        \n",
    "df = pd.DataFrame.from_dict(multi_features_embeds)\n",
    "df.to_csv(\"multi_features_embeds_topics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MISC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in aboutness-bert-all_features/config.json\n",
      "Model weights saved in aboutness-bert-all_features/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(\"aboutness-bert-all_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "preds = trainer.predict(valid_dataset)\n",
    "print(preds.metrics['test_confusion_matrix'])\n",
    "for index, (logits, label) in enumerate(zip(preds.predictions,preds.label_ids)):\n",
    "    pred_label = logits.argmax()\n",
    "    if pred_label != label:\n",
    "        text = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(valid_snippets_encodings['input_ids'][index]))\n",
    "        text = re.sub(\"\\[PAD\\]\",\"\",text).strip()\n",
    "        print(f\"Predicted {class_labels[pred_label]} ({logits}) != real {class_labels[label]} for:\\n{text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## positive samples \n",
    "\n",
    "preds = trainer.predict(valid_dataset)\n",
    "print(preds.metrics['test_confusion_matrix'])\n",
    "for index, (logits, label) in enumerate(zip(preds.predictions,preds.label_ids)):\n",
    "    pred_label = logits.argmax()\n",
    "    if pred_label == label:\n",
    "        text = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(valid_snippets_encodings['input_ids'][index]))\n",
    "        text = re.sub(\"\\[PAD\\]\",\"\",text).strip()\n",
    "        print(f\"Predicted {class_labels[pred_label]} ({logits}) == real {class_labels[label]} for:\\n{text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((1/all_snippets_class_counts).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.trainer_utils import SchedulerType\n",
    "import re\n",
    "\n",
    "\n",
    "model = BertForWeightedSequenceClassification.from_pretrained(\"aboutness-bert-topics\")\n",
    "trainer = Trainer(model=model, compute_metrics=compute_metrics)\n",
    "valid_dataset = Dataset(valid_snippets_encodings, valid_snippets_labels, valid_snippets_topics)\n",
    "\n",
    "\n",
    "\n",
    "preds = trainer.predict(valid_dataset)\n",
    "print(preds.metrics['test_confusion_matrix'])\n",
    "for index, (logits, label) in enumerate(zip(preds.predictions,preds.label_ids)):\n",
    "    pred_label = logits.argmax()\n",
    "    if pred_label == label:\n",
    "        text = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(valid_snippets_encodings['input_ids'][index]))\n",
    "        text = re.sub(\"\\[PAD\\]\",\"\",text).strip()\n",
    "        print(f\"Predicted {class_labels[pred_label]} ({logits}) == real {class_labels[label]} for:\\n{text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Aboutness_BERT_Countermedia_classwise_activelearning (2).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
